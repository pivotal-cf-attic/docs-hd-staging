
<!doctype html>
<html>
<head>
  <meta charset="utf-8">

  <!-- Always force latest IE rendering engine or request Chrome Frame -->
  <meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible">

  <!-- REPLACE X WITH PRODUCT NAME -->
  <title>SQL Command Reference | Pivotal HD/PCC/ADS Documentation</title>
  <!-- Local CSS stylesheets -->
  <link href="/stylesheets/hd-master.css" media="screen,print" rel="stylesheet" type="text/css" />
  <link href="/stylesheets/breadcrumbs.css" media="screen,print" rel="stylesheet" type="text/css" />
  <link href="/stylesheets/search.css" media="screen,print" rel="stylesheet" type="text/css" />
  <link href="/stylesheets/hd-portal-style.css" media="screen,print" rel="stylesheet" type="text/css" />
  <link href="/stylesheets/hd-printable.css" media="print" rel="stylesheet" type="text/css" /> 
  <!-- Confluence HTML stylesheet -->
  <link href="/stylesheets/hd-site.css" media="screen,print" rel="stylesheet"  type="text/css" /> 
  <!-- Left-navigation code -->
  <!-- http://www.designchemical.com/lab/jquery-vertical-accordion-menu-plugin/examples/# -->
  <link href="/stylesheets/hd-dcaccordion.css" rel="stylesheet" type="text/css" />
  <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.4.2/jquery.min.js" type="text/javascript"></script>
  <script src='javascripts/jquery.cookie.js' type="text/javascript"></script>
  <script src='javascripts/jquery.hoverIntent.minified.js' type="text/javascript"></script>
  <script src='javascripts/jquery.dcjqaccordion.2.7.min.js' type="text/javascript"></script>
  <script type="text/javascript">
                    $(document).ready(function($){
					$('#accordion-1').dcAccordion({
						eventType: 'click',
						autoClose: true,
						saveState: true,
						disableLink: false,
						speed: 'fast',
						classActive: 'test',
						showCount: true
					});
					});
  </script>
  <link href="/stylesheets/hd-graphite.css" rel="stylesheet" type="text/css" />
  <link href="/stylesheets/hd-grey.css" rel="stylesheet" type="text/css" /> 
  <!-- End left-navigation code -->
  <script src="javascripts/all.js" type="text/javascript"></script>
  <link href='http://www.gopivotal.com/misc/favicon.ico' rel='shortcut icon'>
</head>

<body class="pivotalcf pivotalcf_getstarted pivotalcf_getstarted_index">
  <div class="viewport">
    <div class="mobile-navigation--wrapper mobile-only">
      <div class="navigation-drawer--container">
        <div class="navigation-item-list">
          <div class="navbar-link active">
            <a href="http://gopivotal.com">
              Home
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
          <div class="navbar-link">
            <a href="http://gopivotal.com/paas">
              PaaS
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
          <div class="navbar-link">
            <a href="http://gopivotal.com/big-data">
              Big Data
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
          <div class="navbar-link">
            <a href="http://gopivotal.com/agile">
              Agile
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
          <div class="navbar-link">
            <a href="http://gopivotal.com/support">
              Help &amp; Support
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
          <div class="navbar-link">
            <a href="http://gopivotal.com/products">
              Products
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
          <div class="navbar-link">
            <a href="http://gopivotal.com/solutions">
              Solutions
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
          <div class="navbar-link">
            <a href="http://gopivotal.com/partners">
              Partners
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
        </div>
      </div>
      <div class="mobile-nav">
        <div class="nav-icon js-open-nav-drawer">
          <i class="icon-reorder"></i>
        </div>
        <div class="header-center-icon">
          <a href="http://gopivotal.com">
            <div class="icon icon-pivotal-logo-mobile"></div>
          </a>
        </div>
      </div>
    </div>

    <div class='wrap'>
      <script src="//use.typekit.net/clb0qji.js" type="text/javascript"></script>
      <script type="text/javascript">
          try {
              Typekit.load();
          } catch (e) {
          }
      </script>
      <script type="text/javascript">
          document.domain = "gopivotal.com";
      </script>
      <div id="search-dropdown-box">
        <div class="search-dropdown--container js-search-dropdown">
          <div class="container-fluid">
            <div class="close-menu-large"><img src="http://www.gopivotal.com/sites/all/themes/gopo13/images/icon-close.png" /></div>
            <div class="search-form--container">
              <div class="form-search">
                <div class='gcse-search'></div>
                <script src="http://www.google.com/jsapi" type="text/javascript"></script>
                <script src="javascripts/cse.js" type="text/javascript"></script>
              </div>
            </div>
          </div>
        </div>
      </div>

      <header class="navbar desktop-only" id="nav">
        <div class="navbar-inner">
            <div class="container-fluid">
                <div class="pivotal-logo--container">
                    <a class="pivotal-logo" href="http://gopivotal.com"><span></span></a>
                </div>

                <ul class="nav pull-right">
                    <li class="navbar-link">
                        <a href="http://www.gopivotal.com/paas" id="paas-nav-link">PaaS</a>
                    </li>
                    <li class="navbar-link">
                        <a href="http://www.gopivotal.com/big-data" id="big-data-nav-link">BIG DATA</a>
                    </li>
                    <li class="navbar-link">
                        <a href="http://www.gopivotal.com/agile" id="agile-nav-link">AGILE</a>
                    </li>
                    <li class="navbar-link">
                        <a href="http://www.gopivotal.com/oss" id="oss-nav-link">OSS</a>
                    </li>
                    <li class="nav-search">
                        <a class="js-search-input-open" id="click-to-search"><span></span></a>
                    </li>
                </ul>
            </div>
            <a href="http://www.gopivotal.com/contact">
                <img id="get-started" src="http://www.gopivotal.com/sites/all/themes/gopo13/images/get-started.png">
            </a>
        </div>
      </header>
      <div class="main-wrap">
        <div class="container-fluid">

          <!-- Google CSE Search Box -->
          <div id='docs-search'>
              <gcse:search></gcse:search>
          </div>
          
          <div id='all-docs-link'>
            <a href="http://docs.gopivotal.com/">All Documentation</a>
          </div>
          
          <div class="container">
            <div id="sub-nav" class="nav-container">              
              
              <!-- Collapsible left-navigation-->
			  <ul class="accordion"  id="accordion-1">
				  <!-- REPLACE <li/> NODES-->

                        <li>
                <a href="index.html">Pivotal HD 1.1.1</a>

                            <ul>
                    <li>
                <a href="PHDEnterprise1.1.1ReleaseNotes.html">PHD Enterprise 1.1.1 Release Notes</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PHDServiceBrokerforPivotalCFv1.0.0.0.html">PHD Service Broker for Pivotal CF v1.0.0.0</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PHDInstallationandAdministration.html">PHD Installation and Administration</a>

                            <ul>
                    <li>
                <a href="OverviewofPHD.html">Overview of PHD</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="InstallingPHDUsingtheCLI.html">Installing PHD Using the CLI</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="UpgradingPHDUsingtheCLI.html">Upgrading PHD Using the CLI</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="AdministeringPHDUsingtheCLI.html">Administering PHD Using the CLI</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PHDFAQFrequentlyAskedQuestions.html">PHD FAQ (Frequently Asked Questions)</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PHDTroubleshooting.html">PHD Troubleshooting</a>

                    </li>
            </ul>
            </li>
            </ul>
                    <ul>
                    <li>
                <a href="StackandToolsReference.html">Stack and Tools Reference</a>

                            <ul>
                    <li>
                <a href="OverviewofApacheStackandPivotalComponents.html">Overview of Apache Stack and Pivotal Components</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PHD1.1.1Stack-RPMPackage.html">PHD 1.1.1 Stack - RPM Package</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PHD1.1.1Stack-BinaryPackage.html">PHD 1.1.1 Stack - Binary Package</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PHDMR11.1Stack-RPMPackage.html">PHD MR1 1.1 Stack - RPM Package</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PHDMR11.1Stack-BinaryPackage.html">PHD MR1 1.1 Stack - Binary Package</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PHDStack-OtherComponents.html">PHD Stack - Other Components</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="USSUnifiedStorageSystem.html">USS (Unified Storage System)</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HVEHadoopVirtualizationExtensions.html">HVE (Hadoop Virtualization Extensions)</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="Security.html">Security</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="ManuallyUpgradingPHDfrom1.1to1.1.1-RPM.html">Manually Upgrading PHD from 1.1 to 1.1.1 - RPM</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="ManuallyUpgradingPHDfrom1.1to1.1.1-Binary.html">Manually Upgrading PHD from 1.1 to 1.1.1 - Binary</a>

                    </li>
            </ul>
            </li>
            </ul>
                    <ul>
                    <li>
                <a href="DataLoaderInstallationandUsage.html">DataLoader Installation and Usage</a>

                            <ul>
                    <li>
                <a href="OverviewofDataLoader.html">Overview of DataLoader</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="InstallingandConfiguringDataLoader.html">Installing and Configuring DataLoader</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="UsingDataLoader.html">Using DataLoader</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="LoadingFilesandPushStreamsintoHAWQUsingPXF.html">Loading Files and Push Streams into HAWQ Using PXF</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="DataLoaderCommandLineInterface.html">DataLoader Command Line Interface</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="DataLoaderCopyStrategyandTransferPolicy.html">DataLoader Copy Strategy and Transfer Policy</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="JobTransferSpecification.html">Job (Transfer) Specification</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="DataStores.html">Data Stores</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="ConfiguringFlumeforDataLoaderPushStreaming.html">Configuring Flume for DataLoader Push Streaming</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="DataLoaderInstallationfromBinaries.html">DataLoader Installation from Binaries</a>

                    </li>
            </ul>
            </li>
            </ul>
            </li>
                        <li>
                <a href="PivotalCommandCenter.html">Pivotal Command Center 2.1.1</a>

                            <ul>
                    <li>
                <a href="PCC2.1.1ReleaseNotes.html">PCC 2.1.1 Release Notes</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PCCUserGuide.html">PCC User Guide</a>

                            <ul>
                    <li>
                <a href="PCCOverview.html">PCC Overview</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="InstallingPCC.html">Installing PCC</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="UsingPCC.html">Using PCC</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="CreatingaYUMEPELRepository.html">Creating a YUM EPEL Repository</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="CommandLineReference.html">Command Line Reference</a>

                    </li>
            </ul>
            </li>
            </ul>
            </li>
                        <li>
                <a href="PivotalAdvancedDatabaseServices.html">Pivotal Advanced Database Services 1.1.4</a>

                            <ul>
                    <li>
                <a href="PADS1.1.4ReleaseNotes.html">PADS 1.1.4 Release Notes</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQInstallation.html">HAWQ Installation</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQAdministration.html">HAWQ Administration</a>

                            <ul>
                    <li>
                <a href="HAWQOverview.html">HAWQ Overview</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQQueryProcessing.html">HAWQ Query Processing</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="QueryingData.html">Querying Data</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="ConfiguringClientAuthentication.html">Configuring Client Authentication</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="KerberosAuthentication.html">Kerberos Authentication</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQInputFormatforMapReduce.html">HAWQ InputFormat for MapReduce</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="SQLCommandReference.html">SQL Command Reference</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="ManagementUtilityReference.html">Management Utility Reference</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="ClientUtilityReference.html">Client Utility Reference</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="ServerConfigurationParameters.html">Server Configuration Parameters</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQEnvironmentVariables.html">HAWQ Environment Variables</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQDataTypes.html">HAWQ Data Types</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="MADlibReferences.html">MADlib References</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="hawq_toolkitReference.html">hawq_toolkit Reference</a>

                    </li>
            </ul>
            </li>
            </ul>
                    <ul>
                    <li>
                <a href="PivotalExtensionFrameworkPXF.html">Pivotal Extension Framework (PXF)</a>

                            <ul>
                    <li>
                <a href="PXFInstallationandAdministration.html">PXF Installation and Administration</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PXFExternalTableandAPIReference.html">PXF External Table and API Reference</a>

                    </li>
            </ul>
            </li>
            </ul>
            </li>
              </ul>        
              
            </div><!--end of sub-nav-->
            <div class="body-container content">

              <!-- Python script replaces main content -->
			  <div id ="main"><h1>SQL Command Reference</h1><div class="wiki-content group" id="main-content">
<p>This topic contains a description and the syntax of the following SQL commands supported by HAWQ:<style type="text/css">/*<![CDATA[*/
div.rbtoc1390012354215 {padding: 0px;}
div.rbtoc1390012354215 ul {list-style: disc;margin-left: 0px;}
div.rbtoc1390012354215 li {margin-left: 0px;padding-left: 0px;}

/*]]>*/</style><div class="toc rbtoc1390012354215">
<ul class="toc-indentation">
<li><a href="#SQLCommandReference-ABORT">ABORT</a></li>
<li><a href="#SQLCommandReference-ALTERROLE">ALTER ROLE</a></li>
<li><a href="#SQLCommandReference-ALTERTABLE">ALTER TABLE</a></li>
<li><a href="#SQLCommandReference-ALTERUSER">ALTER USER</a></li>
<li><a href="#SQLCommandReference-ANALYZE">ANALYZE </a></li>
<li><a href="#SQLCommandReference-BEGIN">BEGIN</a></li>
<li><a href="#SQLCommandReference-CHECKPOINT">CHECKPOINT</a></li>
<li><a href="#SQLCommandReference-CLOSE">CLOSE</a></li>
<li><a href="#SQLCommandReference-COMMIT">COMMIT</a></li>
<li><a href="#SQLCommandReference-COPY">COPY</a></li>
<li><a href="#SQLCommandReference-CREATEAGGREGATE">CREATE AGGREGATE</a></li>
<li><a href="#SQLCommandReference-CREATEDATABASE">CREATE DATABASE</a></li>
<li><a href="#SQLCommandReference-CREATEEXTERNALTABLE">CREATE EXTERNAL TABLE</a></li>
<li><a href="#SQLCommandReference-CREATEFUNCTION">CREATE FUNCTION</a></li>
<li><a href="#SQLCommandReference-CREATEGROUP">CREATE GROUP</a></li>
<li><a href="#SQLCommandReference-CREATELANGUAGE">CREATE LANGUAGE</a></li>
<li><a href="#SQLCommandReference-CREATERESOURCEQUEUE">CREATE RESOURCE QUEUE</a></li>
<li><a href="#SQLCommandReference-CREATEROLE"><span style="font-size: medium;"><span style="font-size: medium;"><span style="color: rgb(19,73,255);font-size: small;"> </span></span></span>CREATE ROLE</a></li>
<li><a href="#SQLCommandReference-CREATESCHEMA">CREATE SCHEMA</a></li>
<li><a href="#SQLCommandReference-CREATESEQUENCE">CREATE SEQUENCE</a></li>
<li><a href="#SQLCommandReference-CREATETABLE">CREATE TABLE</a></li>
<li><a href="#SQLCommandReference-CREATETABLEAS">CREATE TABLE AS</a></li>
<li><a href="#SQLCommandReference-CREATEUSER">CREATE USER</a></li>
<li><a href="#SQLCommandReference-CREATEVIEW">CREATE VIEW</a></li>
<li><a href="#SQLCommandReference-DEALLOCATE">DEALLOCATE</a></li>
<li><a href="#SQLCommandReference-DECLARE">DECLARE</a></li>
<li><a href="#SQLCommandReference-DROPDATABASE">DROP DATABASE</a></li>
<li><a href="#SQLCommandReference-DROPEXTERNALTABLE">DROP EXTERNAL TABLE</a></li>
<li><a href="#SQLCommandReference-DROPFILESPACE">DROP FILESPACE</a></li>
<li><a href="#SQLCommandReference-DROPGROUP">DROP GROUP</a></li>
<li><a href="#SQLCommandReference-DROPOWNED">DROP OWNED</a></li>
<li><a href="#SQLCommandReference-DROPRESOURCEQUEUE">DROP RESOURCE QUEUE</a></li>
<li><a href="#SQLCommandReference-DROPROLE">DROP ROLE</a></li>
<li><a href="#SQLCommandReference-DROPSCHEMA">DROP SCHEMA</a></li>
<li><a href="#SQLCommandReference-DROPSEQUENCE">DROP SEQUENCE</a></li>
<li><a href="#SQLCommandReference-DROPTABLE">DROP TABLE</a></li>
<li><a href="#SQLCommandReference-DROPTABLESPACE">DROP TABLESPACE</a></li>
<li><a href="#SQLCommandReference-DROPUSER">DROP USER</a></li>
<li><a href="#SQLCommandReference-DROPVIEW">DROP VIEW</a></li>
<li><a href="#SQLCommandReference-END">END</a></li>
<li><a href="#SQLCommandReference-EXECUTE">EXECUTE</a></li>
<li><a href="#SQLCommandReference-EXPLAIN">EXPLAIN</a></li>
<li><a href="#SQLCommandReference-FETCH">FETCH</a></li>
<li><a href="#SQLCommandReference-GRANT">GRANT</a></li>
<li><a href="#SQLCommandReference-INSERT">INSERT</a></li>
<li><a href="#SQLCommandReference-PREPARE">PREPARE</a></li>
<li><a href="#SQLCommandReference-REASSIGNOWNED">REASSIGN OWNED</a></li>
<li><a href="#SQLCommandReference-RELEASESAVEPOINT">RELEASE SAVEPOINT</a></li>
<li><a href="#SQLCommandReference-RESET">RESET</a></li>
<li><a href="#SQLCommandReference-REVOKE">REVOKE</a></li>
<li><a href="#SQLCommandReference-ROLLBACK">ROLLBACK</a></li>
<li><a href="#SQLCommandReference-ROLLBACKTOSAVEPOINT">ROLLBACK TO SAVEPOINT</a></li>
<li><a href="#SQLCommandReference-SAVEPOINT">SAVEPOINT</a></li>
<li><a href="#SQLCommandReference-SELECT">SELECT</a></li>
<li><a href="#SQLCommandReference-SELECTINTO">SELECT INTO</a></li>
<li><a href="#SQLCommandReference-SET">SET</a></li>
<li><a href="#SQLCommandReference-SETROLE">SET ROLE</a></li>
<li><a href="#SQLCommandReference-SETSESSIONAUTHORIZATION">SET SESSION AUTHORIZATION</a></li>
<li><a href="#SQLCommandReference-SHOW">SHOW</a></li>
<li><a href="#SQLCommandReference-TRUNCATE">TRUNCATE</a></li>
<li><a href="#SQLCommandReference-VACUUM">VACUUM</a></li>
</ul>
</div></p><h2 id="SQLCommandReference-ABORT">ABORT</h2><p align="LEFT">Aborts the current transaction.</p><h3 id="SQLCommandReference-Synopsis">Synopsis</h3><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">ABORT [WORK | TRANSACTION]</pre>
</div></div><h3 id="SQLCommandReference-Description">Description</h3><p>ABORT rolls back the current transaction and causes all the updates made by the transaction to be discarded. This command is identical in behavior to the standard SQL command ROLLBACK, and is present only for historical reasons.</p><h3 id="SQLCommandReference-Parameters">Parameters</h3><pre>WORK<br/>TRANSACTION</pre><p>Optional key words that have no effect.</p><h3 id="SQLCommandReference-Notes">Notes</h3><p>Use COMMIT to successfully terminate a transaction.</p><p align="LEFT">Issuing ABORT when not inside a transaction does no harm, but provokes a warning message.</p><h3 id="SQLCommandReference-Compatibility">Compatibility</h3><p>This command is a HAWQ extension present for historical reasons. ROLLBACK is the equivalent standard SQL command.</p><h3 id="SQLCommandReference-SeeAlso">See Also</h3><p align="LEFT">BEGIN, COMMIT, ROLLBACK</p><h2 id="SQLCommandReference-ALTERROLE">ALTER ROLE</h2><p>Changes a database role (user or group).</p><h3 id="SQLCommandReference-Synopsis.1">Synopsis</h3><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">ALTER ROLE name RENAME TO newname
ALTER ROLE name SET config_parameter {TO | =} {value | DEFAULT}
ALTER ROLE name RESET config_parameter
ALTER ROLE name RESOURCE QUEUE {queue_name | NONE}
ALTER ROLE name [ [WITH] option [ ... ] ]
 where option can be:
      SUPERUSER | NOSUPERUSER
    | CREATEDB | NOCREATEDB
    | CREATEROLE | NOCREATEROLE
    | CREATEEXTTABLE | NOCREATEEXTTABLE
      [ ( attribute='value'[, ...] ) ]
           
where attributes and values are:
           type='readable'|'writable'
           protocol='gpfdist'|'http'
    | INHERIT | NOINHERIT
    | LOGIN | NOLOGIN
    | CONNECTION LIMIT connlimit
    | [ENCRYPTED | UNENCRYPTED] PASSWORD 'password'
    | VALID UNTIL 'timestamp'
    | [ DENY deny_point ]
    | [ DENY BETWEEN deny_point AND deny_point]
    | [ DROP DENY FOR deny_point ]</pre>
</div></div><h3 id="SQLCommandReference-Description.1">Description</h3><p align="LEFT">ALTER ROLE changes the attributes of a HAWQ role. There are several variants of this command:</p><ul><li>RENAME — Changes the name of the role. Database superusers can rename any role. Roles having CREATEROLE privilege can rename non-superuser roles. The current session user cannot be renamed (connect as a different user to rename a role). Because MD5-encrypted passwords use the role name as cryptographic salt, renaming a role clears its password if the password is MD5-encrypted.</li><li>SET | RESET — changes a role’s session default for a specified configuration parameter. Whenever the role subsequently starts a new session, the specified value becomes the session default, overriding whatever setting is present in server configuration file (postgresql.conf). For a role without LOGIN privilege, session defaults have no effect. Ordinary roles can change their own session defaults. Superusers can change anyone’s session defaults. Roles having CREATEROLE privilege can change defaults for non-superuser roles. See "Server Configuration Parameters" on page 325 for more information on all user-settable configuration parameters.</li><li>RESOURCE QUEUE — Assigns the role to a workload management resource queue. The role would then be subject to the limits assigned to the resource queue when issuing queries. Specify NONE to assign the role to the default resource queue. A role can only belong to one resource queue. For a role without LOGIN privilege, resource queues have no effect. See CREATE RESOURCE QUEUE for more information.</li><li>WITH option — Changes many of the role attributes that can be specified in CREATE ROLE. Attributes not mentioned in the command retain their previous settings. Database superusers can change any of these settings for any role. Roles having CREATEROLE privilege can change any of these settings, but only for non-superuser roles. Ordinary roles can only change their own password.</li></ul><h3 id="SQLCommandReference-Parameters.1">Parameters</h3><pre>name</pre><p align="LEFT" style="margin-left: 30.0px;">The name of the role whose attributes are to be altered.</p><pre>newname</pre><p align="LEFT" style="margin-left: 30.0px;">The new name of the role.</p><pre>config_parameter=value</pre><p align="LEFT" style="margin-left: 30.0px;">Set this role’s session default for the specified configuration parameter to the given value. If value is DEFAULT or if RESET is used, the role-specific variable setting is removed, so the role will inherit the system-wide default setting in new sessions. Use RESET ALL to clear all role-specific settings. See SET and "Server Configuration Parameters" for more information about configuration parameters.</p><pre>queue_name</pre><p align="LEFT" style="margin-left: 30.0px;">The name of the resource queue to which the user-level role is to be assigned. Only roles with LOGIN privilege can be assigned to a resource queue. To unassign a role from a resource queue and put it in the default resource queue, specify NONE. A role can only belong to one resource queue.</p><pre>SUPERUSER | NOSUPERUSER<br/>CREATEDB | NOCREATEDB<br/>CREATEROLE | NOCREATEROLE<br/>CREATEEXTTABLE | NOCREATEEXTTABLE [(attribute='value')]</pre><p align="LEFT" style="margin-left: 30.0px;">If CREATEEXTTABLE is specified, the role being defined is allowed to create external tables. The default type is readable and the default protocol is gpfdist if not specified. NOCREATEEXTTABLE (the default) denies the role the ability to create external tables. Note that external tables that use the file or execute protocols can only be created by superusers.</p><pre>INHERIT | NOINHERIT<br/>LOGIN | NOLOGIN<br/>CONNECTION LIMIT connlimit<br/>PASSWORD password<br/>ENCRYPTED | UNENCRYPTED<br/>VALID UNTIL 'timestamp'</pre><p align="LEFT" style="margin-left: 30.0px;">These clauses alter role attributes originally set by CREATE ROLE.</p><pre>DENY deny_point<br/>DENY BETWEEN deny_point AND deny_point</pre><p align="LEFT" style="margin-left: 30.0px;">The DENY and DENY BETWEEN keywords set time-based constraints that are enforced at login. DENY sets a day or a day and time to deny access. DENY BETWEEN sets an interval during which access is denied. Both use the parameter deny_point that has following format:</p><pre>DAY day [ TIME 'time' ]</pre><p align="LEFT" style="margin-left: 30.0px;">The two parts of the <em>deny_point</em> parameter use the following formats:</p><p align="LEFT" style="margin-left: 30.0px;">For day:</p><pre>	{'Sunday'| 'Monday' | 'Tuesday' |'Wednesday' | 'Thursday' | 'Friday' | 'Saturday' | 0-6 }</pre><p align="LEFT" style="margin-left: 30.0px;">For time:</p><pre>	{ 00-23 : 00-59 | 01-12 : 00-59 { AM | PM }}</pre><p align="LEFT" style="margin-left: 30.0px;">The<em> DENY BETWEEN clause uses two deny_point parameters</em>.</p><pre>	DENY BETWEEN deny_point AND deny_point</pre><pre>DROP DENY FOR deny_point</pre><p align="LEFT" style="margin-left: 30.0px;">The DROP DENY FOR clause removes a time-based constraint from the role. It uses the deny_point parameter described above.</p><h3 id="SQLCommandReference-Notes.1">Notes</h3><p align="LEFT">Use GRANT and REVOKE for adding and removing role memberships.</p><p align="LEFT">Caution must be exercised when specifying an unencrypted password with this command. The password will be transmitted to the server in clear text, and it might also be logged in the client’s command history or the server log. The psql command-line client contains a meta-command \password that can be used to safely change a role’s password.</p><p align="LEFT">It is also possible to tie a session default to a specific database rather than to a role. Role-specific settings override database-specific ones if there is a conflict.</p><h3 id="SQLCommandReference-Examples">Examples</h3><p align="LEFT">Change the password for a role:</p><pre>	ALTER ROLE daria WITH PASSWORD 'passwd123';</pre><p align="LEFT">Change a password expiration date:</p><pre>	ALTER ROLE scott VALID UNTIL 'May 4 12:00:00 2015 +1';</pre><p align="LEFT">Make a password valid forever:</p><pre>	ALTER ROLE luke VALID UNTIL 'infinity';</pre><p align="LEFT">Give a role the ability to create other roles and new databases:</p><pre>	ALTER ROLE joelle CREATEROLE CREATEDB;</pre><p align="LEFT">Give a role a non-default setting of the maintenance_work_mem parameter:</p><pre>	ALTER ROLE admin SET maintenance_work_mem = 100000;</pre><p align="LEFT">Assign a role to a resource queue:</p><pre>	ALTER ROLE sammy RESOURCE QUEUE poweruser;</pre><p align="LEFT">Give a role permission to create writable external tables:</p><pre>	ALTER ROLE load CREATEEXTTABLE (type='writable');</pre><p align="LEFT">Alter a role so it does not allow login access on Sundays:</p><pre>	ALTER ROLE user3 DENY DAY 'Sunday';</pre><p align="LEFT">Alter a role to remove the constraint that does not allow login access on Sundays:</p><pre>	ALTER ROLE user3 DROP DENY FOR DAY 'Sunday';</pre><h3 id="SQLCommandReference-Compatibility.1">Compatibility</h3><p>The ALTER ROLE statement is a HAWQ extension.</p><h3 id="SQLCommandReference-SeeAlso.1">See Also</h3><p>CREATE ROLE, DROP ROLE, SET, CREATE RESOURCE QUEUE, GRANT, REVOKE </p><h2 id="SQLCommandReference-ALTERTABLE">ALTER TABLE</h2><p>Changes the definition of a table.</p><h3 id="SQLCommandReference-Synopsis.2">Synopsis</h3><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">ALTER TABLE [ONLY] name RENAME [COLUMN] column TO new_column
ALTER TABLE name RENAME TO new_name
ALTER TABLE name SET SCHEMA new_schema
ALTER TABLE [ONLY] name SET
     DISTRIBUTED BY (column, [ ... ] )
   | DISTRIBUTED RANDOMLY
   | WITH (REORGANIZE=true|false)
　
ALTER TABLE [ONLY] name action [, ... ]
ALTER TABLE name
    [ ALTER PARTITION {partition_name | FOR (RANK(number))
                     | FOR (value) } partition_action [...] ]
    partition_action
where action is one of:
  ADD [COLUMN] column_name type
       [ ENCODING ( storage_directive [,…] ) ]
      [column_constraint [ ... ]]
DROP [COLUMN] column [RESTRICT | CASCADE]
ALTER [COLUMN] column TYPE type [USING expression]
ALTER [COLUMN] column SET DEFAULT expression
ALTER [COLUMN] column DROP DEFAULT
ALTER [COLUMN] column {SET | DROP } NOT NULL
ALTER [COLUMN] column SET STATISTICS integer
ADD table_constraint
DROP CONSTRAINT constraint_name [RESTRICT | CASCADE]
SET WITHOUT OIDS
INHERIT parent_table
NO INHERIT parent_table
OWNER TO new_owner
ALTER DEFAULT PARTITION
DROP DEFAULT PARTITION [IF EXISTS]
DROP PARTITION [IF EXISTS] { partition_name |
      FOR (RANK(number)) | FOR (value) } [CASCADE]
TRUNCATE DEFAULT PARTITION
TRUNCATE PARTITION {partition_name | FOR (RANK(number)) |
      FOR (value) }
RENAME DEFAULT PARTITION TO new_partition_name
RENAME PARTITION {partition_name | FOR (RANK(number)) |
      FOR (value) } TO new_partition_name
ADD DEFAULT PARTITION name [ ( subpartition_spec ) ]
ADD PARTITION [name] partition_element
       [ ( subpartition_spec ) ]
EXCHANGE PARTITION {partition_name | FOR (RANK(number)) |
       FOR (value) } WITH TABLE table_name
         [ WITH | WITHOUT VALIDATION ]
EXCHANGE DEFAULT PARTITION WITH TABLE table_name
    [ WITH | WITHOUT VALIDATION ]
SET SUBPARTITION TEMPLATE (subpartition_spec)
SPLIT DEFAULT PARTITION
    {  AT (list_value)
     | START([datatype] range_value) [INCLUSIVE | EXCLUSIVE]
       END([datatype] range_value) [INCLUSIVE | EXCLUSIVE] }
    [ INTO ( PARTITION new_partition_name,
             PARTITION default_partition_name ) ]  
SPLIT PARTITION {partition_name | FOR (RANK(number)) |
     FOR (value) } AT (value)
    [ INTO (PARTITION partition_name, PARTITION partition_name)]
where partition_element is:
    VALUES (list_value [,...] )
  | START ([datatype] 'start_value') [INCLUSIVE | EXCLUSIVE]
     [ END ([datatype] 'end_value') [INCLUSIVE | EXCLUSIVE] ]
  | END ([datatype] 'end_value') [INCLUSIVE | EXCLUSIVE]
[ WITH ( partition_storage_parameter=value [, ... ] ) ]
[ TABLESPACE tablespace ]
where subpartition_spec is:
subpartition_element [, ...]
and subpartition_element is:
  DEFAULT SUBPARTITION subpartition_name
  | [SUBPARTITION subpartition_name] VALUES (list_value [,...] )
  | [SUBPARTITION subpartition_name]
     START ([datatype] 'start_value') [INCLUSIVE | EXCLUSIVE]
     [ END ([datatype] 'end_value') [INCLUSIVE | EXCLUSIVE] ]
     [ EVERY ( [number | datatype] 'interval_value') ]
  | [SUBPARTITION subpartition_name]
     END ([datatype] 'end_value') [INCLUSIVE | EXCLUSIVE]
     [ EVERY ( [number | datatype] 'interval_value') ]
[ WITH ( partition_storage_parameter=value [, ... ] ) ]
[ TABLESPACE tablespace ]
where storage_parameter is:
   APPENDONLY={TRUE}
   BLOCKSIZE={8192-2097152}
   ORIENTATION={COLUMN|ROW}
   COMPRESSTYPE={ZLIB|QUICKLZ|RLE_TYPE|NONE}
   COMPRESSLEVEL={0-9}
   FILLFACTOR={10-100}
   OIDS[=TRUE|FALSE]
where storage_directive is:
   COMPRESSTYPE={ZLIB | QUICKLZ | RLE_TYPE | NONE}
 | COMPRESSLEVEL={0-9}
 | BLOCKSIZE={8192-2097152}
Where column_reference_storage_directive is:
COLUMN column_name ENCODING ( storage_directive [, … ] ), …  |
DEFAULT COLUMN ENCODING ( storage_directive [, … ] )</pre>
</div></div><h3 id="SQLCommandReference-Description.2">Description</h3><p align="LEFT">ALTER TABLE changes the definition of an existing table. There are several subforms:</p><ul><li>ADD COLUMN — Adds a new column to the table, using the same syntax as CREATE TABLE.</li><li>DROP COLUMN — Drops a column from a table. Note that if you drop table columns that are being used as the HAWQ distribution key, the distribution policy for the table will be changed to DISTRIBUTED RANDOMLY. Table constraints involving the column will be automatically dropped as well. You will need to say CASCADE if anything outside the table depends on the column (such as views).</li><li>ALTER COLUMN TYPE — Changes the data type of a column of a table. Note that you cannot alter column data types that are being used as the HAWQ distribution key. Simple table constraints involving the column will be automatically converted to use the new column type by reparsing the originally supplied expression. The optional USING clause specifies how to compute the new column value from the old. If omitted, the default conversion is the same as an assignment cast from old data type to new. A USING clause must be provided if there is no implicit or assignment cast from old to new type.</li><li>SET/DROP DEFAULT — Sets or removes the default value for a column. The default values only apply to subsequent INSERT commands. They do not cause rows already in the table to change. Defaults may also be created for views, in which case they are inserted into statements on the view before the view’s ON INSERT rule is applied.</li><li>SET/DROP NOT NULL — Changes whether a column is marked to allow null values or to reject null values. You can only use SET NOT NULL when the column contains no null values.</li><li>SET STATISTICS — Sets the per-column statistics-gathering target for subsequent ANALYZE operations. The target can be set in the range 0 to 1000, or set to -1 to revert to using the system default statistics target (default_statistics_target).</li><li>ADD table_constraint — Adds a new constraint to a table (not just a partition) using the same syntax as CREATE TABLE.</li><li>DROP CONSTRAINT — Drops the specified constraint on a table.</li><li>SET WITHOUT OIDS — Removes the OID system column from the table. Note that there is no variant of ALTER TABLE that allows OIDs to be restored to a table once they have been removed.</li><li>SET DISTRIBUTED —<strong> </strong><span style="font-size: medium;"> </span>Changes the distribution policy of a table. Changes to a hash distribution policy will cause the table data to be physically redistributed on disk, which can be resource intensive.</li><li>INHERIT parent_table / NO INHERIT parent_table — Adds or removes the target table as a child of the specified parent table. Queries against the parent will include records of its child table. To be added as a child, the target table must already contain all the same columns as the parent (it could have additional columns, too). The columns must have matching data types, and if they have NOT NULL constraints in the parent then they must also have NOT NULL constraints in the child. There must also be matching child-table constraints for all CHECK constraints of the parent.</li><li>OWNER — Changes the owner of the table, sequence, or view to the specified user.</li><li>RENAME — Changes the name of a table (sequence, or view) or the name of an individual column in a table. There is no effect on the stored data. Note that HAWQ distribution key columns cannot be renamed.</li><li>SET SCHEMA — Moves the table into another schema. Associated constraints and sequences owned by table columns are moved as well.</li><li>ALTER PARTITION | DROP PARTITION | RENAME PARTITION | TRUNCATE PARTITION | ADD PARTITION | SPLIT PARTITION | EXCHANGE PARTITION | SET SUBPARTITION TEMPLATE — Changes the structure of a partitioned table. In most cases, you must go through the parent table to alter one of its child table partitions. </li></ul><p align="LEFT">You must own the table to use ALTER TABLE. To change the schema of a table, you must also have CREATE privilege on the new schema. To add the table as a new child of a parent table, you must own the parent table as well. To alter the owner, you must also be a direct or indirect member of the new owning role, and that role must have CREATE privilege on the table’s schema. A superuser has these privileges automatically.</p><p align="LEFT"><strong>Note:</strong> Memory usage increases significantly when a table has many partitions, if a table has compression, or if the blocksize for a table is large. If the number of relations associated with the table is large, this condition can force an operation on the table to use more memory. For example, if the table is a CO table and has a large number of columns, each column is a relation. An operation like ALTER TABLE ALTER COLUMN opens all the columns in the table allocates associated buffers. If a CO table has 40 columns and 100 partitions, and the columns are compressed and the blocksize is 2 MB (with a system factor of 3), the system attempts to allocate 24 GB, that is <br/>(40 ×100) × (2 ×3) MB or 24 GB.</p><h3 id="SQLCommandReference-Parameters.2">Parameters</h3><pre>ONLY</pre><p align="LEFT" style="margin-left: 30.0px;">Only perform the operation on the table name specified. If the ONLY keyword is not used, the operation will be performed on the named table and any child table partitions associated with that table.</p><pre>name</pre><p align="LEFT" style="margin-left: 30.0px;">The name (possibly schema-qualified) of an existing table to alter. If ONLY is specified, only that table is altered. If ONLY is not specified, the table and all its descendant tables (if any) are updated. Constraints can only be added to an entire table, not to a partition. Because of that restriction, the <em>name</em> parameter can only contain a table name, not a partition name.</p><pre>column</pre><p align="LEFT" style="margin-left: 30.0px;">Name of a new or existing column. Note that ?AWQ distribution key columns must be treated with special care. Altering or dropping these columns can change the distribution policy for the table.</p><pre>new_column</pre><p align="LEFT" style="margin-left: 30.0px;">New name for an existing column.</p><pre>new_name</pre><p align="LEFT" style="margin-left: 30.0px;">New name for the table.</p><pre>type</pre><p align="LEFT" style="margin-left: 30.0px;">Data type of the new column, or new data type for an existing column. If changing the data type of a ?AWQ distribution key column, you are only allowed to change it to a compatible type (for example,text to varchar is OK, but text to int is not).</p><pre>table_constraint</pre><p align="LEFT" style="margin-left: 30.0px;">New table constraint for the table. Note that foreign key constraints are currently not supported in ?AWQ. Also a table is only allowed one unique constraint and the uniqueness must be within the ?AWQ distribution key.</p><pre>constraint_name</pre><p align="LEFT" style="margin-left: 30.0px;">Name of an existing constraint to drop.</p><pre>CASCADE</pre><p align="LEFT" style="margin-left: 30.0px;">Automatically drop objects that depend on the dropped column or constraint (for example, views referencing the column).</p><pre>RESTRICT</pre><p align="LEFT" style="margin-left: 30.0px;">Refuse to drop the column or constraint if there are any dependent objects. This is the default behavior.</p><pre>ALL</pre><p align="LEFT" style="margin-left: 30.0px;">Disable or enable all triggers belonging to the table including constraint related triggers. This requires superuser privilege.</p><pre>USER</pre><p align="LEFT" style="margin-left: 30.0px;">Disable or enable all user-created triggers belonging to the table.</p><pre>DISTRIBUTED BY (column) | DISTRIBUTED RANDOMLY</pre><p align="LEFT" style="margin-left: 30.0px;">Specifies the distribution policy for a table. Changing a hash distribution policy will cause the table data to be physically redistributed on disk, which can be resource intensive. If you declare the same hash distribution policy or change from hash to random distribution, data will not be redistributed unless you declare SET WITH (REORGANIZE=true).</p><pre>REORGANIZE=true|false</pre><p align="LEFT" style="margin-left: 30.0px;">Use REORGANIZE=true when the hash distribution policy has not changed or when you have changed from a hash to a random distribution, and you want to redistribute the data anyways.</p><pre>parent_table</pre><p align="LEFT" style="margin-left: 30.0px;">A parent table to associate or de-associate with this table.</p><pre>new_owner</pre><p align="LEFT" style="margin-left: 30.0px;">The role name of the new owner of the table.</p><pre>new_schema</pre><p align="LEFT" style="margin-left: 30.0px;">The name of the schema to which the table will be moved.</p><pre>parent_table_name</pre><p align="LEFT" style="margin-left: 30.0px;">When altering a partitioned table, the name of the top-level parent table.</p><pre>ALTER [DEFAULT] PARTITION</pre><p align="LEFT" style="margin-left: 30.0px;">If altering a partition deeper than the first level of partitions, the ALTER PARTITION clause is used to specify which subpartition in the hierarchy you want to alter.</p><pre>DROP [DEFAULT] PARTITION</pre><p align="LEFT" style="margin-left: 30.0px;">Drops the specified partition. If the partition has subpartitions, the subpartitions are automatically dropped as well.</p><pre>TRUNCATE [DEFAULT] PARTITION</pre><p align="LEFT" style="margin-left: 30.0px;">Truncates the specified partition. If the partition has subpartitions, the subpartitions are automatically truncated as well.</p><pre>RENAME [DEFAULT] PARTITION</pre><p align="LEFT" style="margin-left: 30.0px;">Changes the partition name of a partition (not the relation name). Partitioned tables are created using the naming convention: &lt;<em>parentname</em>&gt;_&lt;<em>level</em>&gt;_prt_&lt;<em>partition_name</em>&gt;.</p><pre>ADD DEFAULT PARTITION</pre><p align="LEFT" style="margin-left: 30.0px;">Adds a default partition to an existing partition design. When data does not match to an existing partition, it is inserted into the default partition. Partition designs that do not have a default partition will reject incoming rows that do not match to an existing partition. Default partitions must be given a name.</p><pre>ADD PARTITION</pre><p align="LEFT" style="margin-left: 30.0px;">partition_element - Using the existing partition type of the table (range or list), defines the boundaries of new partition you are adding.</p><p align="LEFT" style="margin-left: 30.0px;">name - A name for this new partition.</p><p align="LEFT" style="margin-left: 30.0px;">VALUES - For list partitions, defines the value(s) that the partition will contain.</p><p align="LEFT" style="margin-left: 30.0px;">START - For range partitions, defines the starting range value for the partition. By default, start values are INCLUSIVE. For example, if you declared a start date of ‘2008-01-01’, then the partition would contain all dates greater than or equal to ‘2008-01-01’. Typically the data type of the START expression is the same type as the partition key column. If that is not the case, then you must explicitly cast to the intended data type.</p><p align="LEFT" style="margin-left: 30.0px;">END - For range partitions, defines the ending range value for the partition. By default, end values are EXCLUSIVE. For example, if you declared an end date of ‘2008-02-01’, then the partition would contain all dates less than but not equal to ‘2008-02-01’. Typically the data type of the END expression is the same type as the partition key column. If that is not the case, then you must explicitly cast to the intended data type.</p><p align="LEFT" style="margin-left: 30.0px;">WITH - Sets the table storage options for a partition. For example, you may want older partitions to be append-only tables and newer partitions to be regular heap tables. See "CREATE TABLE" on page 92 for a description of the storage options.</p><p align="LEFT" style="margin-left: 30.0px;">TABLESPACE - The name of the tablespace in which the partition is to be created.</p><p align="LEFT" style="margin-left: 30.0px;">subpartition_spec - Only allowed on partition designs that were created without a subpartition template. Declares a subpartition specification for the new partition you are adding. If the partitioned table was originally defined using a subpartition template, then the template will be used to generate the subpartitions automatically.</p><pre>EXCHANGE [DEFAULT] PARTITION</pre><p align="LEFT">Exchanges another table into the partition hierarchy into the place of an existing partition. In a multi-level partition design, you can only exchange the lowest level partitions (those that contain data).</p><p align="LEFT" style="margin-left: 30.0px;">WITH TABLE <strong><em>table_name</em></strong><em><span style="font-size: medium;"> </span></em><span style="font-size: medium;"> </span> - The name of the table you are swapping in to the partition design.</p><p align="LEFT" style="margin-left: 30.0px;">WITH | WITHOUT VALIDATION - Validates that the data in the table matches the CHECK constraint of the partition you are exchanging. The default is to validate the data against the CHECK constraint.</p><pre>SET SUBPARTITION TEMPLATE</pre><p align="LEFT" style="margin-left: 30.0px;">Modifies the subpartition template for an existing partition. After a new subpartition template is set, all new partitions added will have the new subpartition design (existing partitions are not modified).</p><pre>SPLIT DEFAULT PARTITION</pre><p align="LEFT" style="margin-left: 30.0px;">Splits a default partition. In a multi-level partition design, you can only split the lowest level default partitions (those that contain data). Splitting a default partition creates a new partition containing the values specified and leaves the default partition containing any values that do not match to an existing partition.</p><p align="LEFT" style="margin-left: 30.0px;">AT - For list partitioned tables, specifies a single list value that should be used as the criteria for the split.</p><p align="LEFT" style="margin-left: 30.0px;">START - For range partitioned tables, specifies a starting value for the new partition.</p><p align="LEFT" style="margin-left: 30.0px;">END - For range partitioned tables, specifies an ending value for the new partition.</p><p align="LEFT" style="margin-left: 30.0px;">INTO - Allows you to specify a name for the new partition. When using the INTO clause to split a default partition, the second partition name specified should always be that of the existing default partition. If you do not know the name of the default partition, you can look it up using the <em>pg_partitions</em> view.</p><pre>SPLIT PARTITION</pre><p align="LEFT" style="margin-left: 30.0px;">Splits an existing partition into two partitions. In a multi-level partition design, you can only split the lowest level partitions (those that contain data).</p><p align="LEFT" style="margin-left: 30.0px;">AT - Specifies a single value that should be used as the criteria for the split. The partition will be divided into two new partitions with the split value specified being the starting range for the <em>latter</em> partition.</p><p align="LEFT" style="margin-left: 30.0px;">INTO - Allows you to specify names for the two new partitions created by the split.</p><pre>partition_name</pre><p align="LEFT" style="margin-left: 30.0px;">The given name of a partition.</p><pre>FOR (RANK(number))</pre><p align="LEFT" style="margin-left: 30.0px;">For range partitions, the rank of the partition in the range.</p><pre>FOR ('value')</pre><p align="LEFT" style="margin-left: 30.0px;">Specifies a partition by declaring a value that falls within the partition boundary specification. If the value declared with FOR matches to both a partition and one of its subpartitions (for example, if the value is a date and the table is partitioned by month and then by day), then FOR will operate on the first level where a match is found (for example, the monthly partition). If your intent is to operate on a subpartition, you must declare so as follows:<br/>ALTER TABLE <em>name</em> ALTER PARTITION FOR ('2008-10-01') DROP PARTITION FOR ('2008-10-01');</p><h3 id="SQLCommandReference-Notes.2">Notes</h3><p align="LEFT">Take special care when altering or dropping columns that are part of the ?AWQ distribution key as this can change the distribution policy for the table. HAWQ does not currently support foreign key constraints. For a unique constraint to be enforced in HAWQ, the table must be hash-distributed (not DISTRIBUTED RANDOMLY), and all of the distribution key columns must be the same as the initial columns of the unique constraint columns.</p><p align="LEFT">Note: The table name specified in the ALTER TABLE command cannot be the name of a partition within a table.</p><p align="LEFT">Adding a CHECK or NOT NULL constraint requires scanning the table to verify that existing rows meet the constraint.</p><p align="LEFT">When a column is added with ADD COLUMN, all existing rows in the table are initialized with the column’s default value (NULL if no DEFAULT clause is specified). Adding a column with a non-null default or changing the type of an existing column will require the entire table to be rewritten. This may take a significant amount of time for a large table; and it will temporarily require double the disk space.</p><p align="LEFT">You can specify multiple changes in a single ALTER TABLE command, which will be done in a single pass over the table.</p><p align="LEFT">The DROP COLUMN form does not physically remove the column, but simply makes it invisible to SQL operations. Subsequent insert and update operations in the table will store a null value for the column. Thus, dropping a column is quick but it will not immediately reduce the on-disk size of your table, as the space occupied by the dropped column is not reclaimed. The space will be reclaimed over time as existing rows are updated.</p><p align="LEFT">The fact that ALTER TYPE requires rewriting the whole table is sometimes an advantage, because the rewriting process eliminates any dead space in the table. For example, to reclaim the space occupied by a dropped column immediately, the fastest way is: ALTER TABLE table ALTER COLUMN anycol TYPE sametype; Where <em>anycol</em> is any remaining table column and <em>sametype</em> is the same type that column already has. This results in no semantically-visible change in the table, but the command forces rewriting, which gets rid of no-longer-useful data.</p><p align="LEFT">If a table is partitioned or has any descendant tables, it is not permitted to add, rename, or change the type of a column in the parent table without doing the same to the descendants. This ensures that the descendants always have columns matching the parent.</p><p align="LEFT">A recursive DROP COLUMN operation will remove a descendant table’s column only if the descendant does not inherit that column from any other parents and never had an independent definition of the column. A nonrecursive DROP COLUMN (ALTER TABLE ONLY ... DROP COLUMN) never removes any descendant columns, but instead marks them as independently defined rather than inherited.</p><p align="LEFT">The OWNER action never recurse to descendant tables; that is, they always act as though ONLY were specified. Adding a constraint can recurse only for CHECK constraints.</p><p align="LEFT">Changing any part of a system catalog table is not permitted.</p><h3 id="SQLCommandReference-Examples.1">Examples</h3><p align="LEFT">Add a column to a table:</p><pre>	ALTER TABLE distributors ADD COLUMN address varchar(30);</pre><p align="LEFT">Rename an existing column:</p><pre>	ALTER TABLE distributors RENAME COLUMN address TO city;</pre><p align="LEFT">Rename an existing table:</p><pre>	ALTER TABLE distributors RENAME TO suppliers;</pre><p align="LEFT">Add a not-null constraint to a column:</p><pre>	ALTER TABLE distributors ALTER COLUMN street SET NOT NULL;</pre><p align="LEFT">Add a check constraint to a table:</p><pre>	ALTER TABLE distributors ADD CONSTRAINT zipchk CHECK (char_length(zipcode) = 5);</pre><p align="LEFT">Move a table to a different schema:</p><pre>	ALTER TABLE myschema.distributors SET SCHEMA yourschema;</pre><p align="LEFT">Add a new partition to a partitioned table:</p><pre>	ALTER TABLE sales ADD PARTITION<br/>		START (date '2009-02-01') INCLUSIVE <br/>		END (date '2009-03-01') EXCLUSIVE; </pre><p> Add a default partition to an existing partition design:</p><pre>	ALTER TABLE sales ADD DEFAULT PARTITION other;</pre><p align="LEFT">Rename a partition:</p><pre>	ALTER TABLE sales RENAME PARTITION FOR ('2008-01-01') TO jan08;</pre><p align="LEFT">Drop the first (oldest) partition in a range sequence:</p><pre>	ALTER TABLE sales DROP PARTITION FOR (RANK(1));</pre><p align="LEFT">Exchange a table into your partition design:</p><pre>	ALTER TABLE sales EXCHANGE PARTITION FOR ('2008-01-01') WITH TABLE jan08;</pre><p align="LEFT">Split the default partition (where the existing default partition’s name is ‘<em>other</em>’) to add a new monthly partition for January 2009:</p><pre>	ALTER TABLE sales SPLIT DEFAULT PARTITION<br/>	START ('2009-01-01') INCLUSIVE<br/>	END ('2009-02-01') EXCLUSIVE<br/>	INTO (PARTITION jan09, PARTITION other);</pre><p align="LEFT">Split a monthly partition into two with the first partition containing dates January 1-15 and the second partition containing dates January 16-31:</p><pre>	ALTER TABLE sales SPLIT PARTITION FOR ('2008-01-01')<br/>	AT ('2008-01-16')<br/>	INTO (PARTITION jan081to15, PARTITION jan0816to31);</pre><h3 id="SQLCommandReference-Compatibility.2">Compatibility</h3><p align="LEFT">The ADD, DROP, and SET DEFAULT forms conform with the SQL standard. The other forms are ?AWQ extensions of the SQL standard. Also, the ability to specify more than one manipulation in a single ALTER TABLE command is an extension. ALTER TABLE DROP COLUMN can be used to drop the only column of a table, leaving a zero-column table. This is an extension of SQL, which disallows zero-column tables.</p><p align="LEFT">See Also</p><p align="LEFT">CREATE TABLE, DROP TABLE</p><h2 id="SQLCommandReference-ALTERUSER">ALTER USER</h2><p align="LEFT">Changes the definition of a database role (user).</p><h3 id="SQLCommandReference-Synopsis.3">Synopsis</h3><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">ALTER USER name RENAME TO newname
ALTER USER name SET config_parameter {TO | =} {value | DEFAULT}
ALTER USER name RESET config_parameter
ALTER USER name [ [WITH] option [ ... ] ]
 where option can be:
      SUPERUSER | NOSUPERUSER
    | CREATEDB | NOCREATEDB
    | CREATEROLE | NOCREATEROLE
    | CREATEUSER | NOCREATEUSER
    | INHERIT | NOINHERIT
    | LOGIN | NOLOGIN
    | [ ENCRYPTED | UNENCRYPTED ] PASSWORD 'password'
    | VALID UNTIL 'timestamp'</pre>
</div></div><h3 id="SQLCommandReference-Description.3">Description</h3><p align="LEFT">ALTER USER is a deprecated command but is still accepted for historical reasons. It is an alias for ALTER ROLE. See ALTER ROLE for more information.</p><h3 id="SQLCommandReference-Compatibility.3">Compatibility</h3><p align="LEFT">The ALTER USER statement is a HAWQ extension. The SQL standard leaves the definition of users to the implementation.</p><h3 id="SQLCommandReference-SeeAlso.2">See Also</h3><p align="LEFT">ALTER ROLE</p><h2 id="SQLCommandReference-ANALYZE">ANALYZE </h2><p align="LEFT">Collects statistics about a database.</p><h3 id="SQLCommandReference-Synopsis.4">Synopsis</h3><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">ANALYZE [VERBOSE] [table [ (column [, ...] ) ]]</pre>
</div></div><h3 id="SQLCommandReference-Description.4">Description</h3><p align="LEFT">ANALYZE collects statistics about the contents of tables in the database, and stores the results in the system table <em>pg_statistic</em>. Subsequently, the query planner uses these statistics to help determine the most efficient execution plans for queries.</p><p align="LEFT">With no parameter, ANALYZE examines every table in the current database. With a parameter, ANALYZE examines only that table. It is further possible to give a list of column names, in which case only the statistics for those columns are collected.</p><h3 id="SQLCommandReference-Parameters.3">Parameters</h3><pre>VERBOSE</pre><p align="LEFT" style="margin-left: 30.0px;">Enables display of progress messages. When specified, ANALYZE emits progress messages to indicate which table is currently being processed. Various statistics about the tables are printed as well.</p><pre>table</pre><p align="LEFT" style="margin-left: 30.0px;">The name (possibly schema-qualified) of a specific table to analyze. Defaults to all tables in the current database.</p><pre>column</pre><p align="LEFT" style="margin-left: 30.0px;">The name of a specific column to analyze. Defaults to all columns.</p><h3 id="SQLCommandReference-Notes.3">Notes</h3><p align="LEFT">It is a good idea to run ANALYZE periodically, or just after making major changes in the contents of a table. Accurate statistics will help the query planner to choose the most appropriate query plan, and thereby improve the speed of query processing. A common strategy is to run VACUUM and ANALYZE once a day during a low-usage time of day.</p><p align="LEFT">ANALYZE requires only a read lock on the target table, so it can run in parallel with other activity on the table.</p><p align="LEFT">The statistics collected by ANALYZE usually include a list of some of the most common values in each column and a histogram showing the approximate data distribution in each column. One or both of these may be omitted if ANALYZE deems them uninteresting (for example, in a unique-key column, there are no common values) or if the column data type does not support the appropriate operators.</p><p align="LEFT">For large tables, ANALYZE takes a random sample of the table contents, rather than examining every row. This allows even very large tables to be analyzed in a small amount of time. Note, however, that the statistics are only approximate, and will change slightly each time ANALYZE is run, even if the actual table contents did not change. This may result in small changes in the planner’s estimated costs shown by EXPLAIN. In rare situations, this non-determinism will cause the query optimizer to choose a different query plan between runs of ANALYZE. To avoid this, raise the amount of statistics collected by ANALYZE by adjusting the <em>default_statistics_target</em> configuration parameter, or on a column-by-column basis by setting the per-column statistics target with ALTER TABLE ... ALTER COLUMN ... SET STATISTICS (see ALTER TABLE). The target value sets the maximum number of entries in the most-common-value list and the maximum number of bins in the histogram. The default target value is 10, but this can be adjusted up or down to trade off accuracy of planner estimates against the time taken for ANALYZE and the amount of space occupied in <em>pg_statistic</em>. In particular, setting the statistics target to zero disables collection of statistics for that column. It may be useful to do that for columns that are never used as part of the WHERE, GROUP BY, or ORDER BY clauses of queries, since the planner will have no use for statistics on such columns.</p><p align="LEFT">The largest statistics target among the columns being analyzed determines the number of table rows sampled to prepare the statistics. Increasing the target causes a proportional increase in the time and space needed to do ANALYZE.</p><p align="LEFT">There may be situations where the remote Analyzer may not be able to perform a task on a PXF table. For example, if a PXF Java component is down, the remote analyzer may not perform the task, so that the database transaction can succeed. In these cases the statistics remain with the default external table values.</p><h3 id="SQLCommandReference-Examples.2">Examples</h3><p align="LEFT">Collect statistics for the table <em>mytable</em>:</p><pre>	ANALYZE mytable;</pre><h3 id="SQLCommandReference-Compatibility.4">Compatibility</h3><p align="LEFT">There is no ANALYZE statement in the SQL standard.</p><h3 id="SQLCommandReference-SeeAlso.3">See Also</h3><pre>ALTER TABLE , EXPLAIN, VACUUM</pre><h2 id="SQLCommandReference-BEGIN">BEGIN</h2><p>Starts a transaction block.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">BEGIN [WORK | TRANSACTION] [SERIALIZABLE | REPEATABLE READ | READ COMMITTED | READ UNCOMMITTED] [READ WRITE | READ ONLY]</pre>
</div></div><h3 id="SQLCommandReference-Description.5">Description</h3><p align="LEFT">BEGIN initiates a transaction block, that is, all statements after a BEGIN command will be executed in a single transaction until an explicit COMMIT or ROLLBACK is given. By default (without BEGIN), ?AWQ executes transactions in autocommit mode, that is, each statement is executed in its own transaction and a commit is implicitly performed at the end of the statement (if execution was successful, otherwise a rollback is done).</p><p align="LEFT">Statements are executed more quickly in a transaction block, because transaction start/commit requires significant CPU and disk activity. Execution of multiple statements inside a transaction is also useful to ensure consistency when making several related changes: other sessions will be unable to see the intermediate states wherein not all the related updates have been done.</p><h3 id="SQLCommandReference-Parameters.4">Parameters</h3><pre>WORK<br/>TRANSACTION</pre><p align="LEFT" style="margin-left: 30.0px;">Optional key words. They have no effect.</p><pre>SERIALIZABLE<br/>REPEATABLE READ<br/>READ COMMITTED<br/>READ UNCOMMITTED</pre><p align="LEFT" style="margin-left: 30.0px;">The SQL standard defines four transaction isolation levels: READ COMMITTED, READ UNCOMMITTED, SERIALIZABLE, and REPEATABLE READ. The default behavior is that a statement can only see rows committed before it began (READ COMMITTED). In ?AWQ READ UNCOMMITTED is treated the same as READ COMMITTED. SERIALIZABLE is supported the same as REPEATABLE READ wherein all statements of the current transaction can only see rows committed before the first statement was executed in the transaction. SERIALIZABLE is the strictest transaction isolation. This level emulates serial transaction execution, as if transactions had been executed one after another, serially, rather than concurrently. Applications using this level must be prepared to retry transactions due to serialization failures.</p><pre>READ WRITE<br/>READ ONLY</pre><p align="LEFT" style="margin-left: 30.0px;">Determines whether the transaction is read/write or read-only. Read/write is the default. When a transaction is read-only, the following SQL commands are disallowed: INSERT, UPDATE, DELETE, and COPY FROM if the table they would write to is not a temporary table; all CREATE, ALTER, and DROP commands; GRANT, REVOKE, TRUNCATE; and EXPLAIN ANALYZE and EXECUTE if the command they would execute is among those listed.</p><h3 id="SQLCommandReference-Notes.4">Notes</h3><p align="LEFT">Use COMMIT or ROLLBACK to terminate a transaction block.</p><p align="LEFT">Issuing BEGIN when already inside a transaction block will provoke a warning message. The state of the transaction is not affected. To nest transactions within a transaction block, use savepoints (see SAVEPOINT).</p><h3 id="SQLCommandReference-Examples.3">Examples</h3><p align="LEFT">To begin a transaction block:</p><pre>	BEGIN;</pre><h3 id="SQLCommandReference-Compatibility.5">Compatibility</h3><p align="LEFT">BEGIN is a HAWQ language extension. It is equivalent to the SQL-standard command <span lang="ZH">START TRANSACTION</span><span lang="EN">.</span></p><p align="LEFT">Incidentally, the BEGIN key word is used for a different purpose in embedded SQL. You are advised to be careful about the transaction semantics when porting database applications.</p><h3 id="SQLCommandReference-SeeAlso.4">See Also</h3><pre>COMMIT, ROLLBACK, SAVEPOINT</pre><h2 id="SQLCommandReference-CHECKPOINT">CHECKPOINT</h2><p>Forces a transaction log checkpoint.</p><h3 id="SQLCommandReference-Synopsis.5">Synopsis</h3><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">CHECKPOINT</pre>
</div></div><h3 id="SQLCommandReference-Description.6">Description</h3><p align="LEFT">Write-Ahead Logging (WAL) puts a checkpoint in the transaction log every so often. The automatic checkpoint interval is set per HAWQ segment instance by the server configuration parameters <em>checkpoint_segments</em> and <em>checkpoint_timeout</em>. The CHECKPOINT command forces an immediate checkpoint when the command is issued, without waiting for a scheduled checkpoint.</p><p align="LEFT">A checkpoint is a point in the transaction log sequence at which all data files have been updated to reflect the information in the log. All data files will be flushed to disk.</p><p align="LEFT">Only superusers may call CHECKPOINT. The command is not intended for use during normal operation.</p><h3 id="SQLCommandReference-Compatibility.6">Compatibility</h3><p align="LEFT">The CHECKPOINT command is a HAWQ language extension.</p><h2 id="SQLCommandReference-CLOSE">CLOSE</h2><p>Closes a cursor.</p><h3 id="SQLCommandReference-Synopsis.6">Synopsis</h3><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">CLOSE cursor_name</pre>
</div></div><h3 id="SQLCommandReference-Description.7">Description</h3><p align="LEFT">CLOSE frees the resources associated with an open cursor. After the cursor is closed, no subsequent operations are allowed on it. A cursor should be closed when it is no longer needed.</p><p align="LEFT">Every non-holdable open cursor is implicitly closed when a transaction is terminated by COMMIT or ROLLBACK. A holdable cursor is implicitly closed if the transaction that created it aborts via ROLLBACK. If the creating transaction successfully commits, the holdable cursor remains open until an explicit CLOSE is executed, or the client disconnects.</p><h3 id="SQLCommandReference-Parameters.5">Parameters</h3><pre>cursor_name</pre><p align="LEFT" style="margin-left: 30.0px;">The name of an open cursor to close.</p><h3 id="SQLCommandReference-Notes.5">Notes</h3><p align="LEFT">HAWQ does not have an explicit OPEN cursor statement. A cursor is considered open when it is declared. Use the DECLARE statement to declare (and open) a cursor.</p><p align="LEFT">You can see all available cursors by querying the <em>pg_cursors</em> system view.</p><h3 id="SQLCommandReference-Examples.4">Examples</h3><p align="LEFT">Close the cursor <em>portala</em>:</p><pre>	CLOSE portala;</pre><h3 id="SQLCommandReference-Compatibility.7">Compatibility</h3><p align="LEFT">CLOSE is fully conforming with the SQL standard.</p><h3 id="SQLCommandReference-SeeAlso.5">See Also</h3><pre>DECLARE, FETCH</pre><h2 id="SQLCommandReference-COMMIT">COMMIT</h2><p>Commits the current transaction.</p><h3 id="SQLCommandReference-Synopsis.7">Synopsis</h3><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">COMMIT [WORK | TRANSACTION]</pre>
</div></div><h3 id="SQLCommandReference-Description.8">Description</h3><p align="LEFT">COMMIT commits the current transaction. All changes made by the transaction become visible to others and are guaranteed to be durable if a crash occurs.</p><h3 id="SQLCommandReference-Parameters.6">Parameters</h3><pre>WORK<br/>TRANSACTION</pre><p align="LEFT">Optional key words. They have no effect.</p><h3 id="SQLCommandReference-Notes.6">Notes</h3><p align="LEFT">Use ROLLBACK to abort a transaction.</p><p align="LEFT">Issuing COMMIT when not inside a transaction does no harm, but it will provoke a warning message.</p><h3 id="SQLCommandReference-Examples.5">Examples</h3><p align="LEFT">To commit the current transaction and make all changes permanent:</p><pre>	COMMIT;</pre><h3 id="SQLCommandReference-Compatibility.8">Compatibility</h3><p align="LEFT">The SQL standard only specifies the two forms COMMIT and COMMIT WORK. Otherwise, this command is fully conforming.</p><h3 id="SQLCommandReference-SeeAlso.6">See Also</h3><pre>BEGIN, END, ROLLBACK</pre><h2 id="SQLCommandReference-COPY">COPY</h2><p>Copies data between a file and a table.</p><h3 id="SQLCommandReference-Synopsis.8">Synopsis</h3><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">COPY table [(column [, ...])] FROM {'file' | STDIN}
     [ [WITH]
       [OIDS]
       [HEADER]
       [DELIMITER [ AS ] 'delimiter']
       [NULL [ AS ] 'null string']
       [ESCAPE [ AS ] 'escape' | 'OFF']
       [NEWLINE [ AS ] 'LF' | 'CR' | 'CRLF']
       [CSV [QUOTE [ AS ] 'quote']
            [FORCE NOT NULL column [, ...]]
       [FILL MISSING FIELDS]
COPY {table [(column [, ...])] | (query)} TO {'file' | STDOUT}
      [ [WITH]
        [OIDS]
        [HEADER]
        [DELIMITER [ AS ] 'delimiter']
        [NULL [ AS ] 'null string']
        [ESCAPE [ AS ] 'escape' | 'OFF']
        [CSV [QUOTE [ AS ] 'quote']
             [FORCE QUOTE column [, ...]] ]</pre>
</div></div><h3 id="SQLCommandReference-Description.9">Description</h3><p align="LEFT">COPY moves data between HAWQ tables and standard file-system files. COPY TO copies the contents of a table to a file, while COPY FROM copies data from a file to a table (appending the data to whatever is in the table already). COPY TO can also copy the results of a SELECT query.</p><p align="LEFT">If a list of columns is specified, COPY will only copy the data in the specified columns to or from the file. If there are any columns in the table that are not in the column list, COPY FROM will insert the default values for those columns.</p><p align="LEFT">COPY with a file name instructs the HAWQ master host to directly read from or write to a file. The file must be accessible to the master host and the name must be specified from the viewpoint of the master host. When STDIN or STDOUT is specified, data is transmitted via the connection between the client and the master.</p><p align="LEFT">If SEGMENT REJECT LIMIT is used, then a COPY FROM operation will operate in single row error isolation mode. In this release, single row error isolation mode only applies to rows in the input file with format errors — for example, extra or missing attributes, attributes of a wrong data type, or invalid client encoding sequences. Constraint errors such as violation of a NOT NULL, CHECK, or UNIQUE constraint will still be handled in ‘all-or-nothing’ input mode. The user can specify the number of error rows acceptable (on a per-segment basis), after which the entire COPY FROM operation will be aborted and no rows will be loaded. Note that the count of error rows is per-segment, not per entire load operation. If the per-segment reject limit is not reached, then all rows not containing an error will be loaded. If the limit is not reached, all good rows will be loaded and any error rows discarded. If you would like to keep error rows for further examination, you can optionally declare an error table using the LOG ERRORS INTO clause. Any rows containing a format error would then be logged to the specified error table.</p><h3 id="SQLCommandReference-Outputs">Outputs</h3><p align="LEFT">On successful completion, a COPY command returns a command tag of the form, where <em>count</em><span style="font-size: small;"> </span> is the number of rows copied:</p><pre>	COPY count</pre><p align="LEFT">If running a COPY FROM command in single row error isolation mode, the following notice message will be returned if any rows were not loaded due to format errors, where <em>count</em><span style="font-size: small;"> </span> is the number of rows rejected:</p><pre>	NOTICE: Rejected count badly formatted rows.</pre><h3 id="SQLCommandReference-Parameters.7">Parameters</h3><pre>table</pre><p align="LEFT" style="margin-left: 30.0px;">The name (optionally schema-qualified) of an existing table.</p><pre>column</pre><p align="LEFT" style="margin-left: 30.0px;">An optional list of columns to be copied. If no column list is specified, all columns of the table will be copied.</p><pre>query</pre><p align="LEFT" style="margin-left: 30.0px;">A SELECT or VALUES command whose results are to be copied. Note that parentheses are required around the query.</p><pre>file</pre><p align="LEFT" style="margin-left: 30.0px;">The absolute path name of the input or output file.</p><pre>STDIN</pre><p align="LEFT" style="margin-left: 30.0px;">Specifies that input comes from the client application.</p><pre>STDOUT</pre><p align="LEFT" style="margin-left: 30.0px;">Specifies that output goes to the client application.</p><pre>OIDS</pre><p align="LEFT" style="margin-left: 30.0px;">Specifies copying the OID for each row. (An error is raised if OIDS is specified for a table that does not have OIDs, or in the case of copying a query.)</p><pre>delimiter</pre><p style="margin-left: 30.0px;">The single ASCII character that separates columns within each row (line) of the file. The default is a tab character in text mode, a comma in CSV mode.</p><pre>null string</pre><p style="margin-left: 30.0px;">The string that represents a null value. The default is \N (backslash-N) in text mode, and a empty value with no quotes in CSV mode. You might prefer an empty string even in text mode for cases where you don’t want to distinguish nulls from empty strings. When using COPY FROM, any data item that matches this string will be stored as a null value, so you should make sure that you use the same string as you used with COPY TO.</p><pre>escape<span> </span><span> </span></pre><p align="LEFT" style="margin-left: 30.0px;">Specifies the single character that is used for C escape sequences (such as \n,\t,\100, and so on) and for quoting data characters that might otherwise be taken as row or column delimiters. Make sure to choose an escape character that is not used anywhere in your actual column data. The default escape character is \ (backslash) for text files or " (double quote) for CSV files, however it is possible to specify any other character to represent an escape. It is also possible to disable escaping on text-formatted files by specifying the value 'OFF' as the escape value. This is very useful for data such as web log data that has many embedded backslashes that are not intended to be escapes.</p><pre>NEWLINE</pre><p align="LEFT" style="margin-left: 30.0px;">Specifies the newline used in your data files — LF (Line feed, 0x0A), CR (Carriage return, 0x0D), or CRLF (Carriage return plus line feed, 0x0D 0x0A). If not specified, a ?AWQ segment will detect the newline type by looking at the first row of data it receives and using the first newline type encountered.</p><pre>CSV</pre><p align="LEFT" style="margin-left: 30.0px;">Selects Comma Separated Value (CSV) mode.</p><pre>HEADER</pre><p align="LEFT" style="margin-left: 30.0px;">Specifies that a file contains a header line with the names of each column in the file. On output, the first line contains the column names from the table, and on input, the first line is ignored.</p><pre>quote</pre><p align="LEFT" style="margin-left: 30.0px;">Specifies the quotation character in CSV mode. The default is double-quote.</p><pre>FORCE QUOTE</pre><p align="LEFT" style="margin-left: 30.0px;">In CSV COPY TO mode, forces quoting to be used for all non-NULL values in each specified column. NULL output is never quoted.</p><pre>FORCE NOT NULL</pre><p align="LEFT" style="margin-left: 30.0px;">In CSV COPY FROM mode, process each specified column as though it were quoted and hence not a NULL value. For the default null string in CSV mode (nothing between two delimiters), this causes missing values to be evaluated as zero-length strings.</p><pre>FILL MISSING FIELDS<span><span> </span></span></pre><p align="LEFT" style="margin-left: 30.0px;">In COPY FROM more for both TEXT and CSV, specifying FILL MISSING FIELDS will set missing trailing field values to NULL (instead of reporting an error) when a row of data has missing data fields at the end of a line or row. Blank rows, fields with a NOT NULL constraint, and trailing delimiters on a line will still report an error.<span style="font-size: medium;"> </span></p><h3 id="SQLCommandReference-Notes.7">Notes</h3><p align="LEFT">COPY can only be used with tables, not with views. However, you can write COPY (SELECT * FROM viewname) TO ....</p><p align="LEFT">The BINARY key word causes all data to be stored/read as binary format rather than as text. It is somewhat faster than the normal text mode, but a binary-format file is less portable across machine architectures and ?AWQ versions. Also, you cannot run COPY FROM in single row error isolation mode if the data is in binary format.</p><p align="LEFT">You must have SELECT privilege on the table whose values are read by COPY TO, and insert privilege on the table into which values are inserted by COPY FROM.</p><p align="LEFT">Files named in a COPY command are read or written directly by the database server, not by the client application. Therefore, they must reside on or be accessible to the HAWQ master host machine, not the client. They must be accessible to and readable or writable by the HAWQ system user (the user ID the server runs as), not the client. COPY naming a file is only allowed to database superusers, since it allows reading or writing any file that the server has privileges to access.</p><p align="LEFT">COPY FROM will invoke any triggers and check constraints on the destination table. However, it will not invoke rewrite rules. Note that in this release, violations of constraints are not evaluated for single row error isolation mode.</p><p align="LEFT">COPY input and output is affected by DateStyle. To ensure portability to other HAWQ installations that might use non-default DateStyle settings, DateStyle should be set to ISO before using COPY TO.</p><p align="LEFT">By default, COPY stops operation at the first error. This should not lead to problems in the event of a COPY TO, but the target table will already have received earlier rows in a COPY FROM. These rows will not be visible or accessible, but they still occupy disk space. This may amount to a considerable amount of wasted disk space if the failure happened well into a large COPY FROM operation. You may wish to invoke VACUUM to recover the wasted space. Another option would be to use single row error isolation mode to filter out error rows while still loading good rows.</p><h3 id="SQLCommandReference-FileFormats">File Formats</h3><h4 id="SQLCommandReference-TextFormat">Text Format</h4><p align="LEFT">When COPY is used without the BINARY or CSV options, the data read or written is a text file with one line per table row. Columns in a row are separated by the <em>delimiter</em><span style="font-size: small;"> </span> character (tab by default). The column values themselves are strings generated by the output function, or acceptable to the input function, of each attribute’s data type. The specified null string is used in place of columns that are null. COPY FROM will raise an error if any line of the input file contains more or fewer columns than are expected. If OIDS is specified, the OID is read or written as the first column, preceding the user data columns.</p><p align="LEFT">The data file has two reserved characters that have special meaning to COPY:</p><ul><li>The designated delimiter character (tab by default), which is used to separate fields in the data file.</li><li>A UNIX-style line feed ( \n or 0x0a), which is used to designate a new row in the data file. It is strongly recommended that applications generating COPY data convert data line feeds to UNIX-style line feeds rather than Microsoft Windows style carriage return line feeds (\r\n or 0x0a 0x0d).</li></ul><p align="LEFT">If your data contains either of these characters, you must escape the character so COPY treats it as data and not as a field separator or new row.</p><p align="LEFT">By default, the escape character is a \ (backslash) for text-formatted files and a " (double quote) for csv-formatted files. If you want to use a different escape character, you can do so using the ESCAPE AS clause. Make sure to choose an escape character that is not used anywhere in your data file as an actual data value. You can also disable escaping in text-formatted files by using ESCAPE 'OFF'.</p><p align="LEFT">For example, suppose you have a table with three columns and you want to load the following three fields using COPY.</p><ul><li>percentage sign = %</li><li>vertical bar = |</li><li>backslash = \</li></ul><p align="LEFT">Your designated DELIMITER character is | (pipe character), and your designated ESCAPE character is * (asterisk). The formatted row in your data file would look like this:</p><pre>percentage sign = % | vertical bar = *| | backslash = \</pre><p align="LEFT">Notice how the pipe character that is part of the data has been escaped using the asterisk character (*). Also notice that we do not need to escape the backslash since we are using an alternative escape character.</p><p align="LEFT">The following characters must be preceded by the escape character if they appear as part of a column value: the escape character itself, newline, carriage return, and the current delimiter character. You can specify a different escape character using the ESCAPE AS clause.</p><h4 id="SQLCommandReference-CSVFormat">CSV Format</h4><p align="LEFT"><span style="font-size: medium;"><span style="font-size: small;"> </span></span></p><p align="LEFT">This format is used for importing and exporting the Comma Separated Value (CSV) file format used by many other programs, such as spreadsheets. Instead of the escaping used by HAWQ standard text mode, it produces and recognizes the common CSV escaping mechanism.</p><p align="LEFT">The values in each record are separated by the DELIMITER character. If the value contains the delimiter character, the QUOTE character, the ESCAPE character (which is double quote by default), the NULL string, a carriage return, or line feed character, then the whole value is prefixed and suffixed by the QUOTE character. You can also use FORCE QUOTE to force quotes when outputting non-NULL values in specific columns.</p><p align="LEFT">The CSV format has no standard way to distinguish a NULL value from an empty string. HAWQ COPY handles this by quoting. A NULL is output as the NULL string and is not quoted, while a data value matching the NULL string is quoted. Therefore, using the default settings, a NULL is written as an unquoted empty string, while an empty string is written with double quotes (""). Reading values follows similar rules. You can use FORCE NOT NULL to prevent NULL input comparisons for specific columns.</p><p align="LEFT">Because backslash is not a special character in the CSV format, \., the end-of-data marker, could also appear as a data value. To avoid any misinterpretation, a \. data value appearing as a lone entry on a line is automatically quoted on output, and on input, if quoted, is not interpreted as the end-of-data marker. If you are loading a file created by another application that has a single unquoted column and might have a value of \., you might need to quote that value in the input file.</p><p align="LEFT">Note: In CSV mode, all characters are significant. A quoted value surrounded by white space, or any characters other than DELIMITER, will include those characters. This can cause errors if you import data from a system that pads CSV lines with white space out to some fixed width. If such a situation arises you might need to preprocess the CSV file to remove the trailing white space, before importing the data into ?AWQ.</p><p align="LEFT">Note: CSV mode will both recognize and produce CSV files with quoted values containing embedded carriage returns and line feeds. Thus the files are not strictly one line per table row like text-mode files.</p><p align="LEFT">Note: Many programs produce strange and occasionally perverse CSV files, so the file format is more a convention than a standard. Thus you might encounter some files that cannot be imported using this mechanism, and COPY might produce files that other programs cannot process.</p><h4 id="SQLCommandReference-BinaryFormat">Binary Format</h4><p align="LEFT">The BINARY format consists of a file header, zero or more tuples containing the row data, and a file trailer. Headers and data are in network byte order.</p><ul><li>File Header — The file header consists of 15 bytes of fixed fields, followed by a variable-length header extension area. The fixed fields are:</li><ul><li>Signature — 11-byte sequence PGCOPY\n\377\r\n\0 — note that the zero byte is a required part of the signature. (The signature is designed to allow easy identification of files that have been munged by a non-8-bit-clean transfer. This signature will be changed by end-of-line-translation filters, dropped zero bytes, dropped high bits, or parity changes.)</li><li>Flags field — 32-bit integer bit mask to denote important aspects of the file format. Bits are numbered from 0 (LSB) to 31 (MSB). Note that this field is stored in network byte order (most significant byte first), as are all the integer fields used in the file format. Bits 16-31 are reserved to denote critical file format issues; a reader should abort if it finds an unexpected bit set in this range. Bits 0-15 are reserved to signal backwards-compatible format issues; a reader should simply ignore any unexpected bits set in this range. Currently only one flag is defined, and the rest must be zero (Bit 16: 1 if data has OIDs, 0 if not).</li><li>Header extension area length — 32-bit integer, length in bytes of remainder of header, not including self. Currently, this is zero, and the first tuple follows immediately. Future changes to the format might allow additional data to be present in the header. A reader should silently skip over any header extension data it does not know what to do with. The header extension area is envisioned to contain a sequence of self-identifying chunks. The flags field is not intended to tell readers what is in the extension area. Specific design of header extension contents is left for a later release.</li></ul><li>Tuples — Each tuple begins with a 16-bit integer count of the number of fields in the tuple. (Presently, all tuples in a table will have the same count, but that might not always be true.) Then, repeated for each field in the tuple, there is a 32-bit length word followed by that many bytes of field data. (The length word does not include itself, and can be zero.) As a special case, -1 indicates a NULL field value. No value bytes follow in the NULL case.</li></ul><p align="LEFT" style="margin-left: 30.0px;">  There is no alignment padding or any other extra data between fields.</p><p align="LEFT" style="margin-left: 30.0px;">  Presently, all data values in a COPY BINARY file are assumed to be in binary format (format code one). It is anticipated that a future extension may add a header field <br/>  that allows per-column format codes to be specified.</p><p align="LEFT" style="margin-left: 30.0px;">  If OIDs are included in the file, the OID field immediately follows the field-count word. It is a normal field except that it's not included in the field-count. In particular it has<br/>  a length word — this will allow handling of 4-byte vs. 8-byte OIDs without too much pain, and will allow OIDs to be shown as null if that ever proves desirable.</p><ul><li>File Trailer — The file trailer consists of a 16-bit integer word containing -1. This is easily distinguished from a tuple’s field-count word. A reader should report an error if a field-count word is neither -1 nor the expected number of columns. This provides an extra check against somehow getting out of sync with the data.</li></ul><h3 id="SQLCommandReference-Examples.6">Examples</h3><p align="LEFT">Copy a table to the client using the vertical bar (|) as the field delimiter:</p><pre>	COPY country TO STDOUT WITH DELIMITER '|';</pre><p align="LEFT">Copy data from a file into the <em>country</em> table:</p><pre>	COPY country FROM '/home/usr1/sql/country_data';</pre><p align="LEFT">Copy into a file just the countries whose names start with 'A':</p><pre>	COPY (SELECT * FROM country WHERE country_name LIKE 'A%') TO '/home/usr1/sql/a_list_countries.copy';</pre><h3 id="SQLCommandReference-Compatibility.9">Compatibility</h3><p align="LEFT">There is no COPY statement in the SQL standard.</p><h3 id="SQLCommandReference-SeeAlso.7">See Also</h3><pre>CREATE EXTERNAL TABLE</pre><h2 id="SQLCommandReference-CREATEAGGREGATE">CREATE AGGREGATE</h2><p>Defines a new aggregate function.</p><h3 id="SQLCommandReference-Synopsis.9">Synopsis</h3><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">CREATE [ORDERED] AGGREGATE name (input_data_type [ , ... ]) 
	( SFUNC = sfunc, 
	  STYPE = state_data_type 
	  [, PREFUNC = prefunc] 
	  [, FINALFUNC = ffunc] 
	  [, INITCOND = initial_condition] 
	  [, SORTOP = sort_operator] )</pre>
</div></div><p><span style="font-size: medium;"> </span></p><h3 id="SQLCommandReference-Description.10">Description</h3><p>CREATE AGGREGATE defines a new aggregate function. Some basic and commonly-used aggregate functions such as count, min, max, sum, avg and so on are already provided in Greenplum Database. If one defines new types or needs an aggregate function not already provided, then CREATE AGGREGATE can be used to provide the desired features.</p><p>An aggregate function is identified by its name and input data type(s). Two aggregates in the same schema can have the same name if they operate on different input types. The name and input data type(s) of an aggregate must also be distinct from the name and input data type(s) of every ordinary function in the same schema.</p><p>An aggregate function is made from one, two or three ordinary functions (all of which must be IMMUTABLE functions):</p><ul><li>a state transition function <em>sfunc</em><span style="font-size: small;"> </span></li><li><span style="font-size: small;"> </span>an optional preliminary segment-level calculation function <em>prefunc</em><span style="font-size: small;"> </span></li><li><span style="font-size: small;"> </span>an optional final calculation function <em>ffunc</em><span style="font-size: small;"> </span></li></ul><p>These are used as follows:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">sfunc( internal-state, next-data-values ) ---&gt; next-internal-state
prefunc( internal-state, internal-state ) ---&gt; next-internal-state
ffunc( internal-state ) ---&gt; aggregate-value</pre>
</div></div><p align="LEFT">You can specify PREFUNC as method for optimizing aggregate execution. By specifying PREFUNC, the aggregate can be executed in parallel on segments first and then on the master. When a two-level execution is performed, SFUNC is executed on the segments to generate partial aggregate results, and PREFUNC is executed on the master to aggregate the partial results from segments. If single-level aggregation is performed, all the rows are sent to the master and sfunc is applied to the rows.</p><p>Single-level aggregation and two-level aggregation are equivalent execution strategies. Either type of aggregation can be implemented in a query plan. When you implement the functions prefunc and sfunc, you must ensure that the invocation of sfunc on the segment instances followed by prefunc on the master produce the same result as single-level aggregation that sends all the rows to the master and then applies only the sfunc to the rows.</p><p>HAWQ creates a temporary variable of data type <em>stype </em><span style="font-size: small;"> </span>to hold the current internal state of the aggregate function. At each input row, the aggregate argument values are calculated and the state transition function is invoked with the current state value and the new argument values to calculate a new internal state value. After all the rows have been processed, the final function is invoked once to calculate the aggregate return value. If there is no final function then the ending state value is returned as-is.</p><p>An aggregate function can provide an optional initial condition, an initial value for the internal state value. This is specified and stored in the database as a value of type text, but it must be a valid external representation of a constant of the state value data type. If it is not supplied then the state value starts out NULL.</p><p>If the state transition function is declared STRICT, then it cannot be called with NULL inputs. With such a transition function, aggregate execution behaves as follows. Rows with any null input values are ignored (the function is not called and the previous state value is retained). If the initial state value is NULL, then at the first row with all non-null input values, the first argument value replaces the state value, and the transition function is invoked at subsequent rows with all non-null input values. This is useful for implementing aggregates like max. Note that this behavior is only available when <em>state_data_type </em><span style="font-size: small;"> </span>is the same as the first <em>input_data_type</em><span style="font-size: small;"> </span>. When these types are different, you must supply a non-null initial condition or use a nonstrict transition function.</p><p>If the state transition function is not declared STRICT, then it will be called unconditionally at each input row, and must deal with NULL inputs and NULL transition values for itself. This allows the aggregate author to have full control over the aggregate handling of NULL values.</p><p>If the final function is declared STRICT, then it will not be called when the ending state value is NULL; instead a NULL result will be returned automatically. (This is the normal behavior of STRICT functions.) In any case the final function has the option of returning a NULL value. For example, the final function for avg returns NULL when it sees there were zero input rows.</p><p>Single argument aggregate functions, such as min or max, can sometimes be optimized by looking into an index instead of scanning every input row. If this aggregate can be so optimized, indicate it by specifying a sort operator. The basic requirement is that the aggregate must yield the first element in the sort ordering induced by the operator; in other words</p><p><span style="font-size: medium;"><span style="font-size: medium;"> </span></span></p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: scala; gutter: false" style="font-size:12px;">SELECT agg(col) FROM tab; </pre>
</div></div><p>must be equivalent to:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SELECT col FROM tab ORDER BY col USING sortop LIMIT 1;</pre>
</div></div><p>Further assumptions are that the aggregate ignores null inputs, and that it delivers a null result if and only if there were no non-null inputs. Ordinarily, a data type’s &lt; operator is the proper sort operator for MIN, and &gt; is the proper sort operator for MAX. Note that the optimization will never actually take effect unless the specified operator is the "less than" or "greater than" strategy member of a B-tree index operator class.</p><h4 id="SQLCommandReference-OrderedAggregates">Ordered Aggregates</h4><p>If the optional qualification ORDERED appears, the created aggregate function is an <em>ordered aggregate</em><span style="font-size: medium;"> </span>. In this case, the preliminary aggregation function, prefunc cannot be specified.</p><p>An ordered aggregate is called with the following syntax.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">name ( arg [ , ... ] [ORDER BY sortspec [ , ...]] )</pre>
</div></div><p>If the optional ORDER BY is omitted, a system-defined ordering is used. The transition function of an ordered aggregate sfunc is called on its input arguments in the specified order and on a single segment. There is a new column aggordered in the pg_aggregate table to indicate the aggregate function is defined as an ordered aggregate.<span style="font-size: medium;"> </span></p><h3 id="SQLCommandReference-Parameters.8">Parameters</h3><pre>name</pre><p style="margin-left: 30.0px;">The name (optionally schema-qualified) of the aggregate function to create.</p><pre>input_data_type</pre><p style="margin-left: 30.0px;">An input data type on which this aggregate function operates. To create a zero-argument aggregate function, write * in place of the list of input data types. An example of such an aggregate is count(*).</p><pre>sfunc</pre><p style="margin-left: 30.0px;">The name of the state transition function to be called for each input row. For an N-argument aggregate function, the <em>sfunc </em><span style="font-size: small;"> </span>must take N+1 arguments, the first being of type <em>state_data_type </em><span style="font-size: small;"> </span>and the rest matching the declared input data type(s) of the aggregate. The function must return a value of type <em>state_data_type</em><span style="font-size: small;"> </span>. This function takes the current state value and the current input data value(s), and returns the next state value.</p><pre>state_data_type</pre><p style="margin-left: 30.0px;">The data type for the aggregate’s state value.</p><pre>prefunc</pre><p style="margin-left: 30.0px;">The name of a preliminary aggregation function. This is a function of two arguments, both of type <em>state_data_type</em><span style="font-size: small;"> </span>. It must return a value of <em>state_data_type</em><span style="font-size: small;"> </span>. A preliminary function takes two transition state values and returns a new transition state value representing the combined aggregation. In HAWQ, if the result of the aggregate function is computed in a segmented fashion, the preliminary aggregation function is invoked on the individual internal states in order to combine them into an ending internal state.</p><p style="margin-left: 30.0px;">Note that this function is also called in hash aggregate mode within a segment. Therefore if you call this aggregate function without a preliminary function, hash aggregate is never chosen. Since hash aggregate is efficient, consider defining preliminary function whenever possible.</p><p style="margin-left: 30.0px;">PREFUNC is optional. If defined, it is executed on master. Input to PREFUNC is partial results from segments, and not the tuples. If PREFUNC is not defined, the aggregate cannot be executed in parallel. PREFUNC and gp_enable_multiphase_agg are used as follows:</p><ul><li style="margin-left: 30.0px;">gp_enable_multiphase_agg = off: SFUNC is executed sequentially on master. PREFUNC, even if defined, is unused.</li><li style="margin-left: 30.0px;"><p>gp_enable_multiphase_agg = on and PREFUNC is defined: SFUNC is executed in parallel, on segments. PREFUNC is invoked on master to aggregate partial results from segments. </p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">CREATE OR REPLACE FUNCTION my_avg_accum(bytea,bigint) returns bytea as 'int8_avg_accum' language internal strict immutable;  
CREATE OR REPLACE FUNCTION my_avg_merge(bytea,bytea) returns bytea as 'int8_avg_amalg' language internal strict immutable;  
CREATE OR REPLACE FUNCTION my_avg_final(bytea) returns numeric as 'int8_avg' language internal strict immutable;  
CREATE AGGREGATE my_avg(bigint) (   stype = bytea,sfunc = my_avg_accum,prefunc = my_avg_merge,finalfunc = my_avg_final,initcond = ''  );</pre>
</div></div></li></ul><pre>ffunc</pre><p style="margin-left: 30.0px;">The name of the final function called to compute the aggregate’s result after all input rows have been traversed. The function must take a single argument of type state_data_type. The return data type of the aggregate is defined as the return type of this function. If ffunc is not specified, then the ending state value is used as the aggregate's result, and the return type is state_data_type.</p><pre>initial_condition</pre><p style="margin-left: 30.0px;">The initial setting for the state value. This must be a string constant in the form accepted for the data type <em>state_data_type</em><span style="font-size: medium;"> </span>. If not specified, the state value starts out null.</p><pre>sort_operator</pre><p style="margin-left: 30.0px;">The associated sort operator for a MIN- or MAX-like aggregate. This is just an operator name (possibly schema-qualified). The operator is assumed to have the same input data types as the aggregate (which must be a single-argument aggregate).</p><h3 id="SQLCommandReference-Notes.8">Notes</h3><p>The ordinary functions used to define a new aggregate function must be defined first. Note that in this release of HAWQ, it is required that the <em>sfunc</em><span style="font-size: small;"> </span>, <em>ffunc</em><span style="font-size: small;"> </span>, and <em>prefunc </em><span style="font-size: small;"> </span>functions used to create the aggregate are defined as IMMUTABLE.</p><p>Any compiled code (shared library files) for custom functions must be placed in the same location on every host in your HAWQ array (master and all segments). This location must also be in the LD_LIBRARY_PATH so that the server can locate the files.</p><h3 id="SQLCommandReference-Examples.7">Examples</h3><p>Create a sum of cubes aggregate:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">CREATE FUNCTION scube_accum(numeric, numeric) RETURNS numeric 
	AS 'select $1 + $2 * $2 * $2' 
	LANGUAGE SQL 
	IMMUTABLE 
	RETURNS NULL ON NULL INPUT;
CREATE AGGREGATE scube(numeric) ( 
	SFUNC = scube_accum, 
	STYPE = numeric, 
	INITCOND = 0 );</pre>
</div></div><p>To test this aggregate:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: actionscript3; gutter: false" style="font-size:12px;">CREATE TABLE x(a INT);
INSERT INTO x VALUES (1),(2),(3);
SELECT scube(a) FROM x;</pre>
</div></div><p>Correct answer for reference:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SELECT sum(a*a*a) FROM x;</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.10">Compatibility</h3><p>CREATE AGGREGATE is a HAWQ language extension. The SQL standard does not provide for user-defined aggregate functions.</p><h3 id="SQLCommandReference-SeeAlso.8">See Also</h3><p>ALTER AGGREGATE, DROP AGGREGATE, CREATE FUNCTION<span style="font-size: medium;"><span style="font-size: medium;"><span style="font-size: medium;"> </span></span></span></p><h2 id="SQLCommandReference-CREATEDATABASE">CREATE DATABASE</h2><p><span style="color: rgb(112,255,0);"> </span>Creates a new database.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">CREATE DATABASE name [ [WITH] [OWNER [=] dbowner]
                     [TEMPLATE [=] template]
                     [ENCODING [=] encoding]
                     [TABLESPACE [=] tablespace]
                     [CONNECTION LIMIT [=] connlimit ] ]</pre>
</div></div><h3 id="SQLCommandReference-Description.11">Description</h3><p align="LEFT">CREATE DATABASE creates a new database. To create a database, you must be a superuser or have the special CREATEDB privilege.</p><p align="LEFT">The creator becomes the owner of the new database by default. Superusers can create databases owned by other users by using the OWNER clause. They can even create databases owned by users with no special privileges. Non-superusers with CREATEDB privilege can only create databases owned by themselves.</p><p align="LEFT">By default, the new database will be created by cloning the standard system database template1. A different template can be specified by writing TEMPLATE <em>name</em>. In particular, by writing TEMPLATE template0, you can create a clean database containing only the standard objects predefined by HAWQ. This is useful if you wish to avoid copying any installation-local objects that may have been added to <em>template1</em>.</p><h3 id="SQLCommandReference-Parameters.9">Parameters</h3><pre>name</pre><p align="LEFT" style="margin-left: 30.0px;">The name of a database to create.</p><pre>dbowner</pre><p align="LEFT" style="margin-left: 30.0px;">The name of the database user who will own the new database, or DEFAULT to use the default owner (the user executing the command).</p><pre>template</pre><p align="LEFT" style="margin-left: 30.0px;">The name of the template from which to create the new database, or DEFAULT to use the default template (<em>template1</em><span> </span>).</p><pre>encoding</pre><p align="LEFT" style="margin-left: 30.0px;">Character set encoding to use in the new database. Specify a string constant (such as 'SQL_ASCII'), an integer encoding number, or DEFAULT to use the default encoding.</p><pre>tablespace</pre><p align="LEFT" style="margin-left: 30.0px;">The name of the tablespace that will be associated with the new database, or DEFAULT to use the template database’s tablespace. This tablespace will be the default tablespace used for objects created in this database.</p><pre>connlimit</pre><p style="margin-left: 30.0px;">The maximum number of concurrent connections posible. The default of -1 means there is no limitation.</p><h3 id="SQLCommandReference-Notes.9">Notes</h3><p>CREATE DATABASE cannot be executed inside a transaction block.</p><p align="LEFT">When you copy a database by specifying its name as the template, no other sessions can be connected to the template database while it is being copied. New connections to the template database are locked out until CREATE DATABASE completes.</p><p>The CONNECTION LIMIT is not enforced against superusers.</p><h3 id="SQLCommandReference-Examples.8">Examples</h3><p>To create a new database:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE DATABASE gpdb;</pre>
</div></div><p align="LEFT">To create a database <em>sales </em><span> </span>owned by user <em>salesapp </em><span> </span>with a default tablespace of salesspace:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE DATABASE sales OWNER salesapp TABLESPACE salesspace;</pre>
</div></div><p align="LEFT">To create a database <em>music </em><span> </span>which supports the ISO-8859-1 character set:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE DATABASE music ENCODING 'LATIN1';</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.11">Compatibility</h3><p>There is no CREATE DATABASE statement in the SQL standard. Databases are equivalent to catalogs, whose creation is implementation-defined.</p><h3 id="SQLCommandReference-SeeAlso.9">See Also</h3><pre>DROP DATABASE</pre><h2 id="SQLCommandReference-CREATEEXTERNALTABLE">CREATE EXTERNAL TABLE</h2><p>Defines a new external table.</p><h3 id="SQLCommandReference-Synopsis.10">Synopsis</h3><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">CREATE [READABLE] EXTERNAL TABLE table_name
      ( column_name data_type [, ...] | LIKE other_table )
      LOCATION ('file://seghost[:port]/path/file' [, ...])
         | ('gpfdist://filehost[:port]/file_pattern[#transform]'
           [, ...])
      FORMAT 'TEXT'
            [( [HEADER]
               [DELIMITER [AS] 'delimiter' | 'OFF']
               [NULL [AS] 'null string']
               [ESCAPE [AS] 'escape' | 'OFF']
               [NEWLINE [ AS ] 'LF' | 'CR' | 'CRLF']
               [FILL MISSING FIELDS] )]
           | 'CSV'
            [( [HEADER]
               [QUOTE [AS] 'quote']
               [DELIMITER [AS] 'delimiter']
               [NULL [AS] 'null string']
               [FORCE NOT NULL column [, ...]]
               [ESCAPE [AS] 'escape']
               [NEWLINE [ AS ] 'LF' | 'CR' | 'CRLF']
               [FILL MISSING FIELDS] )]
     [ ENCODING 'encoding' ]
CREATE [READABLE] EXTERNAL WEB TABLE table_name
      ( column_name data_type [, ...] | LIKE other_table )
      LOCATION ('http://webhost[:port]/path/file' [, ...])
    | EXECUTE 'command' [ON ALL
                          | MASTER
                          | number_of_segments
                          | HOST ['segment_hostname']
                          | SEGMENT segment_id ]
      FORMAT 'TEXT'
            [( [HEADER]
               [DELIMITER [AS] 'delimiter' | 'OFF']
               [NULL [AS] 'null string']
               [ESCAPE [AS] 'escape' | 'OFF']
               [NEWLINE [ AS ] 'LF' | 'CR' | 'CRLF']
               [FILL MISSING FIELDS] )]
           | 'CSV'
            [( [HEADER]
               [QUOTE [AS] 'quote']
               [DELIMITER [AS] 'delimiter']
               [NULL [AS] 'null string']
               [FORCE NOT NULL column [, ...]]
               [ESCAPE [AS] 'escape']
               [NEWLINE [ AS ] 'LF' | 'CR' | 'CRLF']
               [FILL MISSING FIELDS] )]
     [ ENCODING 'encoding' ]
CREATE WRITABLE EXTERNAL TABLE table_name
     ( column_name data_type [, ...] | LIKE other_table )
     LOCATION('gpfdist://outputhost[:port]/filename[#transform]'
              [, ...])
      FORMAT 'TEXT'
               [( [DELIMITER [AS] 'delimiter']
               [NULL [AS] 'null string']
               [ESCAPE [AS] 'escape' | 'OFF'] )]
          | 'CSV'
               [([QUOTE [AS] 'quote']
               [DELIMITER [AS] 'delimiter']
               [NULL [AS] 'null string']
               [FORCE QUOTE column [, ...]] ]
               [ESCAPE [AS] 'escape'] )]
    [ ENCODING 'write_encoding' ]
    [ DISTRIBUTED BY (column, [ ... ] ) | DISTRIBUTED RANDOMLY ]
CREATE WRITABLE EXTERNAL WEB TABLE table_name
     ( column_name data_type [, ...] | LIKE other_table )
    EXECUTE 'command' [ON ALL]
    FORMAT 'TEXT'
               [( [DELIMITER [AS] 'delimiter']
               [NULL [AS] 'null string']
               [ESCAPE [AS] 'escape' | 'OFF'] )]
          | 'CSV'
               [([QUOTE [AS] 'quote']
               [DELIMITER [AS] 'delimiter']
               [NULL [AS] 'null string']
               [FORCE QUOTE column [, ...]] ]
               [ESCAPE [AS] 'escape'] )]
    [ ENCODING 'write_encoding' ]
    [ DISTRIBUTED BY (column, [ ... ] ) | DISTRIBUTED RANDOMLY ]</pre>
</div></div><h3 id="SQLCommandReference-Description.12">Description</h3><p align="LEFT">CREATE EXTERNAL TABLE or CREATE EXTERNAL WEB TABLE creates a new readable external table definition in HAWQ. Readable external tables are typically used for fast, parallel data loading. Once an external table is defined, you can query its data directly (and in parallel) using SQL commands. For example, you can select, join, or sort external table data. You can also create views for external tables. DML operations (UPDATE, INSERT, DELETE, or TRUNCATE) are not allowed on readable external tables.</p><p align="LEFT">CREATE WRITABLE EXTERNAL TABLE or CREATE WRITABLE EXTERNAL WEB TABLE creates a new writable external table definition in HAWQ. Writable external tables are typically used for unloading data from the database into a set of files or named pipes.</p><p align="LEFT">Writable external web tables can also be used to output data to an executable program. Once a writable external table is defined, data can be selected from database tables and inserted into the writable external table. Writable external tables only allow INSERT operations – SELECT, UPDATE, DELETE or TRUNCATE are not allowed.</p><p align="LEFT">The main difference between regular external tables and web external tables is their data sources. Regular readable external tables access static flat files, whereas web external tables access dynamic data sources – either on a web server or by executing OS commands or scripts.</p><p align="LEFT">The FORMAT clause is used to describe how the external table files are formatted. Valid file formats are delimited text (TEXT) for all protocols and comma separated values (CSV) format for gpfdist and file protocols, similar to the formatting options available with the PostgreSQL</p><p align="LEFT">COPY command. If the data in the file does not use the default column delimiter, escape character, null string and so on, you must specify the additional formatting options so that the data in the external file is read correctly by HAWQ.</p><h3 id="SQLCommandReference-Parameters.10">Parameters</h3><pre>READABLE | WRITABLE</pre><p align="LEFT" style="margin-left: 30.0px;">Specifiies the type of external table, readable being the default. Readable external tables are used for loading data into HAWQ. Writable external tables are used for unloading data.</p><pre>WEB</pre><p align="LEFT" style="margin-left: 30.0px;">Creates a readable or wrtiable web external table definition in HAWQ. There are two forms of readable web external tables – those that access files via the http:// protocol or those that access data by executing OS commands. Writable web external tables output data to an executable program that can accept an input stream of data. Web external tables are not rescannable during query execution.</p><pre>table_name</pre><p align="LEFT" style="margin-left: 30.0px;">The name of the new external table.</p><pre>column_name</pre><p align="LEFT" style="margin-left: 30.0px;">The name of a column to create in the external table definition. Unlike regular tables, external tables do not have column constraints or default values, so do not specify those.</p><pre>LIKE <em>other_table</em></pre><p align="LEFT" style="margin-left: 30.0px;">The LIKE clause specifies a table from which the new external table automatically copies all column names, data types and HAWQ distribution policy. If the original table specifies any column constraints or default column values, those will not be copied over to the new external table definition.</p><pre>data_type</pre><p align="LEFT" style="margin-left: 30.0px;">The data type of the column.</p><pre>LOCATION ('<em>protocol</em><span style="font-size: medium;"> </span>://<em>host</em><span style="font-size: medium;"> </span>[:<em>port</em><span style="font-size: medium;"> </span>]/<em>path</em><span style="font-size: medium;"> </span>/<em>file</em><span style="font-size: medium;"> </span>' [, ...])</pre><p align="LEFT" style="margin-left: 30.0px;">For readable external tables, specifies the URI of the external data source(s) to be used to populate the external table or web table. Regular readable external tables allow the gpfdist or file protocols. Web external tables allow the http protocol. If port is omitted, port 8080 is assumed for http and gpfdist protocols. If using the gpfdist protocol, the path is relative to the directory from which gpfdist is serving files (the directory specified when you started the gpfdist program). Also, gpfdist can use wildcards (or other C-style pattern matching) to denote multiple files in a directory. For example:</p><p align="LEFT" style="margin-left: 60.0px;">'gpfdist://filehost:8081/*'</p><p align="LEFT" style="margin-left: 60.0px;">'gpfdist://masterhost/my_load_file'</p><p align="LEFT" style="margin-left: 60.0px;">'file://seghost1/dbfast1/external/myfile.txt'</p><p align="LEFT" style="margin-left: 60.0px;">'http://intranet.mycompany.com/finance/expenses.csv'</p><p align="LEFT" style="margin-left: 30.0px;">For writable external tables, specifies the URI location of the gpfdist process that will collect data output from the HAWQ segments and write it to the named file. The path is relative to the directory from which gpfdist is serving files (the directory specified when you started the gpfdist program). If multiple gpfdist locations are listed, the segments sending data will be evenly divided across the available output locations. For example:</p><p align="LEFT" style="margin-left: 60.0px;">'gpfdist://outputhost:8081/data1.out',</p><p align="LEFT" style="margin-left: 60.0px;">'gpfdist://outputhost:8081/data2.out'</p><p align="LEFT" style="margin-left: 30.0px;">With two gpfdist locations listed as in the above example, half of the segments would send their output data to the data1.out file and the other half to the data2.out file.</p><pre>EXECUTE 'command<span> </span>' [ON ...]</pre><p align="LEFT" style="margin-left: 30.0px;">Allowed for readable web external tables or writable external tables only. For readable web external tables, specifies the OS command to be executed by the segment instances. The <em>command </em><span style="font-size: medium;"> </span>can be a single OS command or a script. The ON clause is used to specify which segment instances will execute the given command.</p><ul><ul><li><strong>ON ALL</strong> is the default. The command will be executed by every active (primary) segment instance on all segment hosts in the HAWQ system. If the command executes a script, that script must reside in the same location on all of the segment hosts and be executable by the HAWQ superuser (gpadmin).</li><li><strong>ON MASTER</strong> runs the command on the master host only.</li><li><strong>ON</strong> <em>number </em>means the command will be executed by the specified number of segments. The particular segments are chosen randomly at runtime by the HAWQ system. If the command executes a script, that script must reside in the same location on all of the segment hosts and be executable by the HAWQ superuser (gpadmin).</li><li><strong>HOST</strong> means the command will be executed by one segment on each segment host (once per segment host), regardless of the number of active segment instances per host.</li><li><strong>HOST</strong> <em>segment_hostname </em>means the command will be executed by all active (primary) segment instances on the specified segment host.</li><li>SEGMENT <em>segment_id </em>means the command will be executed only once by the specified segment. The <em>content </em><span style="font-size: medium;"> </span>ID of the HAWQ master is always -1.</li></ul></ul><p align="LEFT" style="margin-left: 30.0px;">For writable external tables, the <em>command </em><span style="font-size: small;"> </span>specified in the EXECUTE clause must be prepared to have data piped into it. Since all segments that have data to send will write their output to the specified command or program, the only available option for the ON clause is ON ALL.</p><pre>FORMAT 'TEXT | CSV' (<em>options</em><span style="font-size: medium;"> </span>)</pre><p align="LEFT" style="margin-left: 30.0px;">Specifies the format of the external or web table data - either plain text (TEXT) or comma separated values (CSV) format.</p><pre>DELIMITER</pre><p align="LEFT" style="margin-left: 30.0px;">Specifies a single ASCII character that separates columns within each row (line) of data. The default is a tab character in TEXT mode, a comma in CSV mode. In TEXT mode for readable external tables, the delimiter can be set to OFF for special use cases in which unstructured data is loaded into a single-column table.</p><pre>NULL</pre><p align="LEFT" style="margin-left: 30.0px;">Specifies the string that represents a null value. The default is \N (backslash-N) in TEXT mode, and an empty value with no quotations in CSV mode. You might prefer an empty string even in TEXT mode for cases where you do not want to distinguish nulls from empty strings. When using external and web tables, any data item that matches this string will be considered a null value.</p><pre>ESCAPE</pre><p align="LEFT" style="margin-left: 30.0px;">Specifies the single character that is used for C escape sequences (such as \n,\t,\100, and so on) and for escaping data characters that might otherwise be taken as row or column delimiters. Make sure to choose an escape character that is not used anywhere in your actual column data. The default escape character is a \(backslash) for text-formatted files and a " (double quote) for csv-formatted files, however it is possible to specify another character to represent an escape. It is also possible to disable escaping in text-formatted files by specifying the value 'OFF' as the escape value. This is very useful for data such as text-formatted web log data  that has many embedded backslashes that are not intended to be escapes.</p><pre>NEWLINE</pre><p align="LEFT" style="margin-left: 30.0px;">Specifies the newline used in your data files – LF (Line feed, 0x0A), CR (Carriage return, 0x0D), or CRLF (Carriage return plus line feed, 0x0D 0x0A). If not specified, a HAWQ segment will detect the newline type by looking at the first row of data it receives and using the first newline type encountered.</p><pre>HEADER</pre><p align="LEFT" style="margin-left: 30.0px;">For readable external tables, specifies that the first line in the data file(s) is a header row (contains the names of the table columns) and should not be included as data for the table. If using multiple data source files, all files must have a header row.</p><pre>QUOTE</pre><p align="LEFT" style="margin-left: 30.0px;">Specifies the quotation character for CSV mode. The default is double-quote (").</p><pre>FORCE NOT NULL</pre><p align="LEFT" style="margin-left: 30.0px;">In CSV mode, processes each specified column as though it were quoted and hence not a NULL value. For the default null string in CSV mode (nothing between two delimiters), this causes missing values to be evaluated as zero-length strings.</p><pre>FORCE QUOTE</pre><p align="LEFT" style="margin-left: 30.0px;">In CSV mode for writable external tables, forces quoting to be used for all non-NULL values in each specified column. NULL output is never quoted.</p><pre>FILL MISSING FIELDS</pre><p align="LEFT" style="margin-left: 30.0px;">In both TEXT and CSV mode for readable external tables, specifying FILL MISSING FIELDS will set missing trailing field values to NULL (instead of reporting an error) when a row of data has missing data fields at the end of a line or row. Blank rows, fields with a NOT NULL constraint, and trailing delimiters on a line will still report an error.</p><pre>ENCODING 'encoding<span> </span>'</pre><p align="LEFT" style="margin-left: 30.0px;">Character set encoding to use for the external table. Specify a string constant (such as'SQL_ASCII'), an integer encoding number, or DEFAULT to use the default client encoding.</p><pre>DISTRIBUTED BY (<em>column</em><span style="font-size: medium;"> </span>, [ ... ] )<br/>DISTRIBUTED RANDOMLY</pre><p align="LEFT" style="margin-left: 30.0px;">Used to declare the HAWQ distribution policy for a writable external table. By default, writable external tables are distributed randomly. If the source table you are exporting data from has a hash distribution policy, defining the same distribution key column(s) for the writable external table will improve unload performance by eliminating the need to move rows over the interconnect. When you issue an unload command such as INSERT INTO <em>wex_table </em><span style="font-size: small;"> </span>SELECT * FROM <em>source_table</em><span style="font-size: small;"> </span>, the rows that are unloaded can be sent directly from the segments to the output location if the two tables have the same hash distribution policy.</p><h3 id="SQLCommandReference-Examples.9">Examples</h3><p align="LEFT">Start the  gpfdist file server program in the background on port <em>8081 </em><span style="font-size: medium;"> </span>serving files from directory <em>/var/data/staging</em><span style="font-size: medium;"> </span>:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">gpfdist -p 8081 -d /var/data/staging -l /home/gpadmin/log &amp;</pre>
</div></div><p> </p><p align="LEFT">Create a readable external table named <em>ext_customer </em><span style="font-size: medium;"> </span>using the gpfdist protocol and any text formatted files (*.txt) found in the gpfdist directory. The files are formatted with a pipe (|) as the column delimiter and an empty space as null.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE EXTERNAL TABLE ext_customer
	id int, name text, sponsor text)
	LOCATION ( 'gpfdist://filehost:8081/*.txt' )
	FORMAT 'TEXT' ( DELIMITER '|' NULL ' ')</pre>
</div></div><p> </p><p align="LEFT">Create the same readable external table definition as above, but with CSV formatted files:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE EXTERNAL TABLE ext_customer(
	id int, name text, sponsor text) 
	LOCATION ( 'gpfdist://filehost:8081/*.csv' ) 
	FORMAT 'CSV' ( DELIMITER ',' );</pre>
</div></div><p align="LEFT">Create a readable external table named <em>ext_expenses </em><span style="font-size: medium;"> </span>using the file protocol and several CSV formatted files that have a header row:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE EXTERNAL TABLE ext_expenses (name text, date date, amount float4, category text, description text)
LOCATION (
'file://seghost1/dbfast/external/expenses1.csv',
'file://seghost1/dbfast/external/expenses2.csv',
'file://seghost2/dbfast/external/expenses3.csv',
'file://seghost2/dbfast/external/expenses4.csv',
'file://seghost3/dbfast/external/expenses5.csv',
'file://seghost3/dbfast/external/expenses6.csv'
)
FORMAT 'CSV' ( HEADER );</pre>
</div></div><p> Create a readable web external table that executes a script once per segment host:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE EXTERNAL WEB TABLE log_output (linenum int, message
text) EXECUTE '/var/load_scripts/get_log_data.sh' ON HOST
FORMAT 'TEXT' (DELIMITER '|');</pre>
</div></div><p align="LEFT">Create a writable external table named <em>sales_out </em><span style="font-size: medium;"> </span>that uses gpfdist to write output data to a file named <em>sales.out</em><span style="font-size: medium;"> </span>. The files are formatted with a pipe (|) as the column delimiter and an empty space as null.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE WRITABLE EXTERNAL TABLE sales_out (LIKE sales)
	LOCATION ('gpfdist://etl1:8081/sales.out')
	FORMAT 'TEXT' ( DELIMITER '|' NULL ' ')
	DISTRIBUTED BY (txn_id);</pre>
</div></div><p> Create a writable external web table that pipes output data received by the segments to an executable script named <em>to_adreport_etl.sh</em><span style="font-size: medium;"> </span>:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE WRITABLE EXTERNAL WEB TABLE campaign_out (LIKE campaign)
EXECUTE '/var/unload_scripts/to_adreport_etl.sh'
FORMAT 'TEXT' (DELIMITER '|');</pre>
</div></div><p align="LEFT">Use the writable external table defined above to unload selected data:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">INSERT INTO campaign_out SELECT * FROM campaign WHERE
customer_id=123;</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.12">Compatibility</h3><p align="LEFT">CREATE EXTERNAL TABLE is a HAWQ extension. The SQL standard makes no provisions for external tables.</p><h3 id="SQLCommandReference-SeeAlso.10">See Also</h3><p align="LEFT">CREATE TABLE AS, CREATE TABLE, COPY, SELECT INTO, INSERT</p><h2 id="SQLCommandReference-CREATEFUNCTION">CREATE FUNCTION</h2><p>Defines a new function.</p><h3 id="SQLCommandReference-Synopsis.11">Synopsis</h3><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE [OR REPLACE] FUNCTION name 
 ( [ [argmode] [argname] argtype [, ...] ] ) 
   [ RETURNS { [ SETOF ] rettype 
      | TABLE ([{ argname argtype | LIKE other table } 
        [, ...]]) 
      } ] 
 { LANGUAGE langname 
 | IMMUTABLE | STABLE | VOLATILE 
 | CALLED ON NULL INPUT | RETURNS NULL ON NULL INPUT | STRICT 
 | [EXTERNAL] SECURITY INVOKER | [EXTERNAL] SECURITY DEFINER 
 | AS 'definition' 
 | AS 'obj_file', 'link_symbol' } ... 
 [ WITH ({ DESCRIBE = describe_function 
        } [, ...] ) ]</pre>
</div></div><h3 id="SQLCommandReference-Description.13">Description</h3><p>CREATE FUNCTION defines a new function. CREATE OR REPLACE FUNCTION will either create a new function, or replace an existing definition.</p><p>The name of the new function must not match any existing function with the same argument types in the same schema. However, functions of different argument types may share a name (overloading).</p><p>To update the definition of an existing function, use CREATE OR REPLACE FUNCTION. It is not possible to change the name or argument types of a function this way (this would actually create a new, distinct function). Also, CREATE OR REPLACE FUNCTION will not let you change the return type of an existing function. To do that, you must drop and recreate the function. If you drop and then recreate a function, you will have to drop existing objects (rules, views, triggers, and so on) that refer to the old function. Use CREATE OR REPLACE FUNCTION to change a function definition without breaking objects that refer to the function.</p><p>For more information about creating functions, see the User Defined Functions section of the PostgreSQL documentation.</p><h4 id="SQLCommandReference-LimitedUseofVOLATILEandSTABLEFunctions">Limited Use of VOLATILE and STABLE Functions</h4><p>To prevent data from becoming out-of-sync across the segments in HAWQ, any function classified as STABLE or VOLATILE cannot be executed at the segment level if it contains SQL or modifies the database in any way. For example, functions such as random() or timeofday() are not allowed to execute on distributed data in HAWQ because they could potentially cause inconsistent data between the segment instances.</p><p>To ensure data consistency, VOLATILE and STABLE functions can safely be used in statements that are evaluated on and execute from the master. For example, the following statements are always executed on the master (statements without a FROM clause):</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">SELECT setval('myseq', 201);
SELECT foo();</pre>
</div></div><p>In cases where a statement has a FROM clause containing a distributed table <em>and </em><span style="font-size: medium;"> </span>the function used in the FROM clause simply returns a set of rows, execution may be allowed on the segments:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">SELECT * FROM foo();</pre>
</div></div><p>One exception to this rule are functions that return a table reference (angeFuncs) or functions that use the refCursor data type. These types of functions cannot be used at all in Greenplum Database. However, they are not very commonly used anyways.</p><h3 id="SQLCommandReference-Parameters.11">Parameters</h3><pre>name</pre><p style="margin-left: 30.0px;">The name (optionally schema-qualified) of the function to create.</p><pre>argmode</pre><p style="margin-left: 30.0px;">The mode of an argument: either IN, OUT, or INOUT. If omitted, the default is IN.</p><pre>argname</pre><p style="margin-left: 30.0px;"><span style="font-size: medium;"><span style="font-size: medium;"><span style="font-size: medium;"><span style="font-size: medium;"><span style="font-size: medium;"><em><span style="font-size: medium;"> </span></em></span></span></span></span></span>The name of an argument. Some languages (currently only PL/pgSQL) let you use the name in the function body. For other languages the name of an input argument is just extra documentation. But the name of an output argument is significant, since it defines the column name in the result row type. (If you omit the name for an output argument, the system will choose a default column name.)</p><pre>argtype</pre><p style="margin-left: 30.0px;">The data type(s) of the function's arguments (optionally schema-qualified), if any. The argument types may be base, composite, or domain types, or may reference the type of a table column.</p><p style="margin-left: 30.0px;">Depending on the implementation language it may also be allowed to specify pseudotypes such as cstring. Pseudotypes indicate that the actual argument type is either incompletely specified, or outside the set of ordinary SQL data types.</p><p style="margin-left: 30.0px;">The type of a column is referenced by writing <em>tablename</em><span style="font-size: small;"> </span>.<em>columnname</em><span style="font-size: small;"> </span>%TYPE. Using this feature can sometimes help make a function independent of changes to the definition of a table.</p><pre>rettype</pre><p style="margin-left: 30.0px;">The return data type (optionally schema-qualified). The return type can be a base, composite, or domain type, or may reference the type of a table column. Depending on the implementation language it may also be allowed to specify pseudotypes such as cstring. If the function is not supposed to return a value, specify void as the return type.</p><p align="LEFT" style="margin-left: 30.0px;">When there are OUT or INOUT parameters, the RETURNS clause may be omitted. If present, it must agree with the result type implied by the output parameters: RECORD if there are multiple output parameters, or the same type as the single output parameter.</p><p align="LEFT" style="margin-left: 30.0px;">The SETOF modifier indicates that the function will return a set of items, rather than a single item.</p><p style="margin-left: 30.0px;">The type of a column is referenced by writing <em>tablename</em><span style="font-size: small;"> </span>.<em>columnname</em><span style="font-size: small;"> </span>%TYPE.</p><pre>langname</pre><p align="LEFT" style="margin-left: 30.0px;">The name of the language that the function is implemented in. May be SQL, C, internal, or the name of a user-defined procedural language. See CREATE LANGUAGE for the procedural languages supported in Greenplum Database. For backward compatibility, the name may be enclosed by single quotes.</p><pre>IMMUTABLE<br/>STABLE<br/>VOLATILE</pre><p style="margin-left: 30.0px;">These attributes inform the query optimizer about the behavior of the function. At most one choice may be specified. If none of these appear, VOLATILE is the default assumption. Since HAWQ currently has limited use of VOLATILE functions, if a function is truly IMMUTABLE, you must declare it as so to be able to use it without restrictions.</p><p align="LEFT" style="margin-left: 30.0px;">IMMUTABLE indicates that the function cannot modify the database and always returns the same result when given the same argument values. It does not do database lookups or otherwise use information not directly present in its argument list. If this option is given, any call of the function with all-constant arguments can be immediately replaced with the function value.</p><p align="LEFT" style="margin-left: 30.0px;">STABLE indicates that the function cannot modify the database, and that within a single table scan it will consistently return the same result for the same argument values, but that its result could change across SQL statements. This is the appropriate selection for functions whose results depend on database lookups, parameter values (such as the current time zone), and so on. Also note that the <em>current_timestamp </em><span style="font-size: medium;"> </span>family of functions qualify as stable, since their values do not change within a transaction.</p><p style="margin-left: 30.0px;">VOLATILE indicates that the function value can change even within a single table scan, so no optimizations can be made. Relatively few database functions are volatile in this sense; some examples are random(), currval(), timeofday(). But note that any function that has side-effects must be classified volatile, even if its result is quite predictable, to prevent calls from being optimized away; an example is setval().</p><pre>CALLED ON NULL INPUTRETURNS NULL ON NULL INPUTSTRICT</pre><p align="LEFT" style="margin-left: 30.0px;">CALLED ON NULL INPUT (the default) indicates that the function will be called normally when some of its arguments are null. It is then the function author’s responsibility to check for null values if necessary and respond appropriately. RETURNS NULL ON NULL INPUT or STRICT indicates that the function always returns null whenever any of its arguments are null. If this parameter is specified, the function is not executed when there are null arguments; instead a null result is assumed automatically.</p><pre>[EXTERNAL] SECURITY INVOKER[EXTERNAL] SECURITY DEFINER</pre><p align="LEFT" style="margin-left: 30.0px;">SECURITY INVOKER (the default) indicates that the function is to be executed with the privileges of the user that calls it. SECURITY DEFINER specifies that the function is to be executed with the privileges of the user that created it. The key word EXTERNAL is allowed for SQL conformance, but it is optional since, unlike in SQL, this feature applies to all functions not just external ones.</p><pre>definition</pre><p align="LEFT" style="margin-left: 30.0px;">A string constant defining the function; the meaning depends on the language. It may be an internal function name, the path to an object file, an SQL command, or text in a procedural language.</p><pre>obj_file, link_symbol</pre><p align="LEFT" style="margin-left: 30.0px;">This form of the AS clause is used for dynamically loadable C language functions when the function name in the C language source code is not the same as the name of the SQL function. The string <em>obj_file </em><span style="font-size: small;"> </span>is the name of the file containing the dynamically loadable object, and <em>link_symbol </em><span style="font-size: small;"> </span>is the name of the function in the C language source code. If the link symbol is omitted, it is assumed to be the same as the name of the SQL function being defined. It is recommended to locate shared libraries either relative to $libdir (which is located at $GPHOME/lib) or through the dynamic library path (set by the dynamic_library_path server configuration parameter). This simplifies version upgrades if the new installation is at a different location.</p><pre>describe_function</pre><p align="LEFT" style="margin-left: 30.0px;">The name of a callback function to execute when a query that calls this function is parsed. The callback function returns a tuple descriptor that indicates the result type.</p><h3 id="SQLCommandReference-Notes.10">Notes</h3><p align="LEFT">Any compiled code (shared library files) for custom functions must be placed in the same location on every host in your HAWQ array (master and all segments). This location must also be in the LD_LIBRARY_PATH so that the server can locate the files. It is recommended to locate shared libraries either relative to $libdir (which is located at $GPHOME/lib) or through the dynamic library path (set by the dynamic_library_path server configuration parameter) on all master segment instances in the HAWQ array.</p><p align="LEFT">The full SQL type syntax is allowed for input arguments and return value. However, some details of the type specification (such as the precision field for type <em>numeric</em><span style="font-size: medium;"> </span>) are the responsibility of the underlying function implementation and are not recognized or enforced by the CREATE FUNCTION command.HAWQ allows function overloading. The same name can be used for several different functions so long as they have distinct argument types. However, the C names of all functions must be different, so you must give overloaded C functions different C names (for example, use the argument types as part of the C names).</p><p>Two functions are considered the same if they have the same names and input argument types, ignoring any OUT parameters. Thus for example these declarations conflict:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE FUNCTION foo(int) ...
CREATE FUNCTION foo(int, out text) ...</pre>
</div></div><p align="LEFT">When repeated CREATE FUNCTION calls refer to the same object file, the file is only loaded once. To unload and reload the file, use the LOAD command.</p><p align="LEFT">To be able to define a function, the user must have the USAGE privilege on the language.</p><p align="LEFT">It is often helpful to use dollar quoting to write the function definition string, rather than the normal single quote syntax. Without dollar quoting, any single quotes or backslashes in the function definition must be escaped by doubling them. A dollar-quoted string constant consists of a dollar sign ($), an optional tag of zero or more characters, another dollar sign, an arbitrary sequence of characters that makes up the string content, a dollar sign, the same tag that began this dollar quote, and a dollar sign. Inside the dollar-quoted string, single quotes, backslashes, or any character can be used without escaping. The string content is always written literally. For example, here are two different ways to specify the string "Dianne’s horse" using dollar quoting:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">$$Dianne's horse$$
$SomeTag$Dianne's horse$SomeTag$</pre>
</div></div><h3 id="SQLCommandReference-Examples.10">Examples</h3><p align="LEFT">A very simple addition function:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE FUNCTION add(integer, integer) RETURNS integer 
    AS 'select $1 + $2;' 
    LANGUAGE SQL 
    IMMUTABLE 
    RETURNS NULL ON NULL INPUT;</pre>
</div></div><p align="LEFT"><span style="font-size: medium;"><span style="font-size: medium;"> </span></span>Increment an integer, making use of an argument name, in PL/pgSQL:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE OR REPLACE FUNCTION increment(i integer) RETURNS integer AS $$ 
       BEGIN 
               RETURN i + 1; 

       END;
$$ LANGUAGE plpgsql;</pre>
</div></div><p align="LEFT">Return a record containing multiple output parameters:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE FUNCTION dup(in int, out f1 int, out f2 text) 
    AS $$ SELECT $1, CAST($1 AS text) || ' is text' $$ 
    LANGUAGE SQL;
SELECT * FROM dup(42);</pre>
</div></div><p align="LEFT">You can do the same thing more verbosely with an explicitly named composite type:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE TYPE dup_result AS (f1 int, f2 text);
CREATE FUNCTION dup(int) RETURNS dup_result 
    AS $$ SELECT $1, CAST($1 AS text) || ' is text' $$ 
    LANGUAGE SQL;
SELECT * FROM dup(42);</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.13">Compatibility</h3><p align="LEFT">CREATE FUNCTION is defined in SQL:1999 and later. The HAWQ version is similar but not fully compatible. The attributes are not portable, neither are the different available languages.</p><p align="LEFT">For compatibility with some other database systems, <em>argmode </em><span style="font-size: small;"> </span>can be written either before or after <em>argname</em><span style="font-size: small;"> </span>. But only the first way is standard-compliant.</p><h3 id="SQLCommandReference-SeeAlso.11">See Also</h3><p align="LEFT">ALTER FUNCTION, DROP FUNCTION, LOAD</p><p><span style="font-size: medium;"><span style="font-size: medium;"><span style="font-size: medium;"><span style="font-size: medium;"><span style="font-size: medium;"><span style="font-size: medium;"><span style="font-size: medium;"> </span></span></span></span></span></span></span></p><h2 id="SQLCommandReference-CREATEGROUP">CREATE GROUP</h2><p>Defines a new database role.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">CREATE GROUP 
name [ [WITH] option [ ... ] ]
 where option can be:
      SUPERUSER | NOSUPERUSER
    | CREATEDB | NOCREATEDB
    | CREATEROLE | NOCREATEROLE
    | CREATEUSER | NOCREATEUSER
    | INHERIT | NOINHERIT
    | LOGIN | NOLOGIN
    | [ ENCRYPTED | UNENCRYPTED ] PASSWORD 'password'
    | VALID UNTIL 'timestamp'
    | IN ROLE rolename [, ...]
    | IN GROUP rolename [, ...]
    | ROLE rolename [, ...]
    | ADMIN rolename [, ...]
    | USER rolename [, ...]
    | SYSID uid</pre>
</div></div><h3 id="SQLCommandReference-Description.14">Description</h3><p align="LEFT">As of HAWQ release 2.2, CREATE GROUP has been replaced by CREATE ROLE, although it is still accepted for backwards compatibility.</p><h3 id="SQLCommandReference-Compatibility.14">Compatibility</h3><p align="LEFT">There is no CREATE GROUP statement in the SQL standard.</p><h3 id="SQLCommandReference-SeeAlso.12">See Also</h3><p align="LEFT">CREATE ROLE</p><h2 id="SQLCommandReference-CREATELANGUAGE">CREATE LANGUAGE</h2><p align="LEFT">Defines a new procedural language.</p><h3 id="SQLCommandReference-Synopsis.12">Synopsis</h3><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">CREATE [PROCEDURAL] LANGUAGE name
CREATE [TRUSTED] [PROCEDURAL] LANGUAGE name  HANDLER call_handler [VALIDATOR valfunction]</pre>
</div></div><h3 id="SQLCommandReference-Description.15">Description</h3><p align="LEFT">CREATE LANGUAGE registers a new procedural language with a Greenplum database. Subsequently, functions and trigger procedures can be defined in this new language. You must be a superuser to register a new language. The PL/pgSQL language is already registered in all databases by default.</p><p align="LEFT">CREATE LANGUAGE effectively associates the language name with a call handler that is responsible for executing functions written in that language. For a function written in a procedural language (a language other than C or SQL), the database server has no built-in knowledge about how to interpret the function’s source code. The task is passed to a special handler that knows the details of the language. The handler could either do all the work of parsing, syntax analysis, execution, and so on or it could serve as a bridge between Pivotal HAWQ Database and an existing implementation of a programming language. The handler itself is a C language function compiled into a shared object and loaded on demand, just like any other C function. A language handler has also been added for PL/R, but the PL/R language package is not pre-installed with Greenplum Database. See the section on Procedural Languages in the PostgreSQL documentation for more information on developing functions using these procedural languages.</p><p align="LEFT">The PL/R libraries require the correct version R to be installed. Download the appropriate extensions from the EMC Download Center, then install the extensions. See the HAWQ Installation Guide for details. This ensures that all underlying dependencies are installed along with the extensions.</p><p align="LEFT">To use the PL/R procedural language you must make sure that the systems that run Pivotal HAWQ Database (master and all segments) have the R language installed and the PL/R package library (plr.so) added to their HAWQ Installation on all hosts. Pivotal provides compiled packages for R and PL/R that you can install.</p><p align="LEFT">There are two forms of the CREATE LANGUAGE command. In the first form, the user supplies just the name of the desired language, and the Pivotal HAWQ Database server consults the <em>pg_pltemplate </em><span style="font-size: medium;"> </span>system catalog to determine the correct parameters. In the second form, the user supplies the language parameters along with the language name. The second form can be used to create a language that is not defined in <em>pg_pltemplate</em><span style="font-size: medium;"> </span>.</p><p>When the server finds an entry in the <em>pg_pltemplate </em><span style="font-size: medium;"> </span>catalog for the given language name, it will use the catalog data even if the command includes language parameters. This behavior simplifies loading of old dump files, which are likely to contain out-of-date information about language support functions.</p><h3 id="SQLCommandReference-Parameters.12">Parameters</h3><pre>TRUSTED</pre><p style="margin-left: 30.0px;">Ignored if the server has an entry for the specified language name in <em>pg_pltemplate</em><span style="font-size: medium;"> </span>. Specifies that the call handler for the language is safe and does not offer an unprivileged user any functionality to bypass access restrictions. If this key word is omitted when registering the language, only users with the superuser privilege can use this language to create new functions.</p><pre>PROCEDURAL</pre><p style="margin-left: 30.0px;">This is a noise word.</p><pre>name</pre><p style="margin-left: 30.0px;">The name of the new procedural language. The language name is case insensitive. The name must be unique among the languages in the database. Built-in support is included for plpgsql, plpython, plpythonu, and plr. plpgsql is already installed by default in Greenplum Database.</p><pre>HANDLER call_handler</pre><p style="margin-left: 30.0px;">Ignored if the server has an entry for the specified language name in <em>pg_pltemplate</em><span style="font-size: medium;"> </span>. The name of a previously registered function that will be called to execute the procedural language functions. The call handler for a procedural language must be written in a compiled language such as C with version 1 call convention and registered with Greenplum Database as a function taking no arguments and returning the language_handler type, a placeholder type that is simply used to identify the function as a call handler.</p><pre>VALIDATOR valfunction</pre><p style="margin-left: 30.0px;"><span style="font-size: medium;">I</span>gnored if the server has an entry for the specified language name in <em>pg_pltemplate</em><span style="font-size: medium;"> </span>. <em>valfunction </em><span style="font-size: small;"> </span>is the name of a previously registered function that will be called when a new function in the language is created, to validate the new function. If no validator function is specified, then a new function will not be checked when it is created. The validator function must take one argument of type oid, which will be the OID of the to-be-created function, and will typically return void.</p><p style="margin-left: 30.0px;">A validator function would typically inspect the function body for syntactical correctness, but it can also look at other properties of the function, for example if the language cannot handle certain argument types. To signal an error, the validator function should use the ereport() function. The return value of the function is ignored.</p><h3 id="SQLCommandReference-Notes.11">Notes</h3><p>The PL/pgSQL language is installed by default in Greenplum Database.</p><p align="LEFT">The system catalog <em>pg_language </em><span style="font-size: medium;"> </span>records information about the currently installed languages.</p><p align="LEFT">To create functions in a procedural language, a user must have the USAGE privilege for the language. By default, USAGE is granted to PUBLIC (everyone) for trusted languages. This may be revoked if desired.</p><p align="LEFT">Procedural languages are local to individual databases. However, a language can be installed into the <em>template1 </em><span style="font-size: medium;"> </span>database, which will cause it to be available automatically in all subsequently-created databases.</p><p align="LEFT">The call handler function and the validator function (if any) must already exist if the server does not have an entry for the language in <em>pg_pltemplate</em><span style="font-size: medium;"> </span>. But when there is an entry, the functions need not already exist; they will be automatically defined if not present in the database.</p><p>Any shared library that implements a language must be located in the same LD_LIBRARY_PATH location on all segment hosts in your Greenplum Database array.</p><h3 id="SQLCommandReference-Examples.11">Examples</h3><p>The preferred way of creating any of the standard procedural languages:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">CREATE LANGUAGE plpgsql;
CREATE LANGUAGE plr; </pre>
</div></div><p align="LEFT">For a language not known in the <em>pg_pltemplate </em><span style="font-size: medium;"> </span>catalog:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">CREATE FUNCTION plsample_call_handler() RETURNS language_handler
	AS '$libdir/plsample'
	LANGUAGE C;
CREATE LANGUAGE plsample
	HANDLER plsample_call_handler;</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.15">Compatibility</h3><p>CREATE LANGUAGE is a Pivotal HAWQ Database extension.</p><h3 id="SQLCommandReference-SeeAlso.13">See Also</h3><p align="LEFT">CREATE FUNCTION</p><h2 id="SQLCommandReference-CREATERESOURCEQUEUE">CREATE RESOURCE QUEUE</h2><p><span style="color: rgb(112,255,0);font-size: small;"> </span>Defines a new resource queue.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">CREATE RESOURCE QUEUE name WITH (queue_attribute=value [, ... ])
 where queue_attribute is:
   ACTIVE_STATEMENTS=integer
        [ MAX_COST=float [COST_OVERCOMMIT={TRUE|FALSE}] ]
        [ MIN_COST=float ]
        [ PRIORITY={MIN|LOW|MEDIUM|HIGH|MAX} ]
        [ MEMORY_LIMIT='memory_units' ]
|  MAX_COST=float [ COST_OVERCOMMIT={TRUE|FALSE} ]
        [ ACTIVE_STATEMENTS=integer ]
        [ MIN_COST=float ]
        [ PRIORITY={MIN|LOW|MEDIUM|HIGH|MAX} ]
        [ MEMORY_LIMIT='memory_units' ]</pre>
</div></div><h3 id="SQLCommandReference-Description.16">Description</h3><p align="LEFT">Creates a new resource queue for HAWQ workload management. A resource queue must have either an ACTIVE_STATEMENTS or a MAX_COST value (or it can have both). Only a superuser can create a resource queue.</p><p align="LEFT">Resource queues with an ACTIVE_STATEMENTS threshold set a maximum limit on the number of queries that can be executed by roles assigned to that queue. It controls the number of active queries that are allowed to run at the same time. The value for ACTIVE_STATEMENTS should be an integer greater than 0.</p><p align="LEFT">Resource queues with a MAX_COST threshold set a maximum limit on the total cost of queries that can be executed by roles assigned to that queue. Cost is measured in the estimated total cost for the query as determined by the HAWQ query planner (as shown in the EXPLAIN output for a query). Therefore, an administrator must be familiar with the queries typically executed on the system in order to set an appropriate cost threshold for a queue. Cost is measured in units of disk page fetches;1.0 equals one sequential disk page read. The value for MAX_COST is specified as a floating point number (for example 100.0) or can also be specified as an exponent (for example 1e+2). If a resource queue is limited based on a cost threshold, then the administrator can allow COST_OVERCOMMIT=TRUE (the default). This means that a query that exceeds the allowed cost threshold will be allowed to run but only when the system is idle. If COST_OVERCOMMIT=FALSE is specified, queries that exceed the cost limit will always be rejected and never allowed to run. Specifying a value for MIN_COST allows the administrator to define a cost for small queries that will be exempt from resource queueing.</p><p align="LEFT">If a value is not defined for ACTIVE_STATEMENTS or MAX_COST, it is set to -1 by default (meaning no limit). After defining a resource queue, you must assign roles to the queue using the ALTER ROLE or CREATE ROLE command.</p><p>You can optionally assign a PRIORITY to a resource queue to control the relative share of available CPU resources used by queries associated with the queue in relation to other resource queues. If a value is not defined for PRIORITY, queries associated with the queue have a default priority of MEDIUM.</p><p>Resource queues with an optional MEMORY_LIMIT threshold set a maximum limit on the amount of memory that all queries submitted through a resource queue can consume on a segment host. This determines the total amount of memory that all worker processes of a query can consume on a segment host during query execution. Pivotal recommends that MEMORY_LIMIT be used in conjunction with ACTIVE_STATEMENTS rather than with MAX_COST. The default amount of memory allotted per query on statement-based queues is: MEMORY_LIMIT/ACTIVE_STATEMENTS. The default amount of memory allotted per query on cost-based queues is: MEMORY_LIMIT * (query_cost / MAX_COST).</p><p>The default memory allotment can be overridden on a per-query basis using the statement_mem server configuration parameter, provided that MEMORY_LIMIT or max_statement_mem is not exceeded. For example, to allocate more memory to a particular query:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">=&gt; SET statement_mem='2GB';
=&gt; SELECT * FROM my_big_table WHERE column='value' ORDER BY id;
=&gt; RESET statement_mem;</pre>
</div></div><p>As a general guideline, MEMORY_LIMIT for all of your resource queues should not exceed the amount of physical memory of a segment host.If workloads are staggered over multiple queues, memory allocations can be oversubscribed. However, queries can be cancelled during execution if the segment host memory limit specified in gp_vmem_protect_limit is exceeded.</p><h3 id="SQLCommandReference-Parameters.13">Parameters</h3><pre>name</pre><p style="margin-left: 30.0px;">The name of the resource queue.</p><pre>ACTIVE_STATEMENTS integer</pre><p style="margin-left: 30.0px;">Resource queues with an ACTIVE_STATEMENTS threshold limit the number of queries that can be executed by roles assigned to that queue. It controls the number of active queries that are allowed to run at the same time. The value for ACTIVE_STATEMENTS should be an integer greater than 0.</p><pre>MEMORY_LIMIT ' memory_units<span> </span>'</pre><p style="margin-left: 30.0px;">Sets the total memory quota for all statements submitted from users in this resource queue. Memory units can be specified in kB, MB or GB. The minimum memory quota for a resource queue is 10MB. There is no maximum, however the upper boundary at query execution time is limited by the physical memory of a segment host. The default is no limit (-1).</p><pre>MAX_COST float</pre><p style="margin-left: 30.0px;">Resource queues with a MAX_COST threshold set a maximum limit on the total cost of queries that can be executed by roles assigned to that queue. Cost is measured in the <em>estimated total cost </em><span style="font-size: medium;"> </span>for the query as determined by the HAWQ query planner (as shown in the EXPLAIN output for a query). Therefore, an administrator must be familiar with the queries typically executed on the system in order to set an appropriate cost threshold for a queue. Cost is measured in units of disk page fetches; 1.0 equals one sequential disk page read. The value for MAX_COST is specified as a floating point number (for example 100.0) or can also be specified as an exponent (for example 1e+2).</p><pre>COST_OVERCOMMIT boolean</pre><p style="margin-left: 30.0px;">If a resource queue is limited based on MAX_COST, then the administrator can allow COST_OVERCOMMIT (the default). This means that a query that exceeds the allowed cost threshold will be allowed to run but only when the system is idle. If COST_OVERCOMMIT=FALSE is specified, queries that exceed the cost limit will always be rejected and never allowed to run.</p><pre>MIN_COST float</pre><p style="margin-left: 30.0px;">The minimum query cost limit of what is considered a small query. Queries with a cost under this limit will not be queued and run immediately. Cost is measured in the estimated total cost for the query as determined by the HAWQ query planner (as shown in the EXPLAIN output for a query). Therefore, an administrator must be familiar with the queries typically executed on the system in order to set an appropriate cost for what is considered a small query. Cost is measured in units of disk page fetches; 1.0 equals one sequential disk page read. The value for MIN_COST is specified as a floating point number (for example 100.0) or can also be specified as an exponent (for example 1e+2).</p><pre>PRIORITY={MIN|LOW|MEDIUM|HIGH|MAX}</pre><p style="margin-left: 30.0px;">Sets the priority of queries associated with a resource queue. Queries or statements in queues with higher priority levels will receive a larger share of available CPU resources in case of contention. Queries in low-priority queues may be delayed while higher priority queries are executed. If no priority is specified, queries associated with the queue have a priority of MEDIUM.</p><h3 id="SQLCommandReference-Notes.12">Notes</h3><p>Use the <em>gp_toolkit.gp_resqueue_status </em><span style="font-size: medium;"> </span>system view to see the limit settings and current status of a resource queue:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">SELECT * from gp_toolkit.gp_resqueue_status WHERE
rsqname='queue_name';</pre>
</div></div><p>There is also another system view named <em>pg_stat_resqueues </em><span style="font-size: medium;"> </span>which shows statistical metrics for a resource queue over time. To use this view, however, you must enable the stats_queue_level server configuration parameter.</p><p>CREATE RESOURCE QUEUE cannot be run within a transaction.</p><h3 id="SQLCommandReference-Examples.12">Examples</h3><p>Create a resource queue with an active query limit of 20:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE RESOURCE QUEUE myqueue WITH (ACTIVE_STATEMENTS=20);</pre>
</div></div><p>Create a resource queue with an active query limit of 20 and a total memory limit of 2000MB (each query will be allocated 100MB of segment host memory at execution time):</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE RESOURCE QUEUE myqueue WITH (ACTIVE_STATEMENTS=20);
MEMORY_LIMIT='2000MB');</pre>
</div></div><p>Create a resource queue with a query cost limit of 3000.0:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE RESOURCE QUEUE myqueue WITH (MAX_COST=3000.0); </pre>
</div></div><p>Create a resource queue with a query cost limit of 3<sup>10</sup> (or 30000000000.0) and do not allow overcommit. Allow small queries with a cost under 500 to run immediately:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE RESOURCE QUEUE myqueue WITH (MAX_COST=3e+10,COST_OVERCOMMIT=FALSE, MIN_COST=500.0);</pre>
</div></div><p>Create a resource queue with both an active query limit and a query cost limit:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE RESOURCE QUEUE myqueue WITH (ACTIVE_STATEMENTS=30,
MAX_COST=5000.00);</pre>
</div></div><p>Create a resource queue with an active query limit of 5 and a maximum priority setting:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE RESOURCE QUEUE myqueue WITH (ACTIVE_STATEMENTS=5,
PRIORITY=MAX);</pre>
</div></div><p><span style="font-size: medium;"><span style="font-size: medium;"> </span></span></p><h3 id="SQLCommandReference-Compatibility.16">Compatibility</h3><p align="LEFT">CREATE RESOURCE QUEUE is a HAWQ extension. There is no provision for resource queues or workload management in the SQL standard.</p><h3 id="SQLCommandReference-SeeAlso.14">See Also</h3><p>ALTER ROLE, CREATE ROLE, DROP RESOURCE QUEUE</p><h2 id="SQLCommandReference-CREATEROLE"><span style="font-size: medium;"><span style="font-size: medium;"><span style="color: rgb(19,73,255);font-size: small;"> </span></span></span>CREATE ROLE</h2><p>Defines a new database role (user or group).</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">CREATE ROLE 
name [[WITH] option [ ... ]]
 where option can be:
      SUPERUSER | NOSUPERUSER
    | CREATEDB | NOCREATEDB
    | CREATEROLE | NOCREATEROLE
    | CREATEEXTTABLE | NOCREATEEXTTABLE
      [ ( attribute='value'[, ...] ) ]
           where attributes and values are:
           type='readable'|'writable'
           protocol='gpfdist'|'http'
    | INHERIT | NOINHERIT
    | LOGIN | NOLOGIN
    | CONNECTION LIMIT connlimit
    | [ ENCRYPTED | UNENCRYPTED ] PASSWORD 'password'
    | VALID UNTIL 'timestamp'
    | IN ROLE rolename [, ...]
    | ROLE rolename [, ...]
    | ADMIN rolename [, ...]
    | RESOURCE QUEUE queue_name
    | [ DENY deny_point ]
    | [ DENY BETWEEN deny_point AND deny_point]</pre>
</div></div><h3 id="SQLCommandReference-Description.17">Description</h3><p align="LEFT">CREATE ROLE adds a new role to a HAWQ system. A role is an entity that can own database objects and have database privileges. A role can be considered a user, a group, or both depending on how it is used. You must have</p><p align="LEFT">CREATEROLE privilege or be a database superuser to use this command.</p><p align="LEFT">Note that roles are defined at the system-level and are valid for all databases in your HAWQ system.</p><h3 id="SQLCommandReference-Parameters.14">Parameters</h3><pre>name</pre><p align="LEFT" style="margin-left: 30.0px;">The name of the new role.</p><pre>SUPERUSER<br/>NOSUPERUSER</pre><p align="LEFT" style="margin-left: 30.0px;">If SUPERUSER is specified, the role being defined will be a superuser, who can override all access restrictions within the database. Superuser status is dangerous and should be used only when really needed. You must yourself be a superuser to create a new superuser. NOSUPERUSER is the default.</p><pre>CREATEDB<br/>NOCREATEDB</pre><p align="LEFT" style="margin-left: 30.0px;">If CREATEDB is specified, the role being defined will be allowed to create new databases. NOCREATEDB (the default) will deny a role the ability to create databases.</p><pre>CREATEROLE<br/>NOCREATEROLE</pre><p align="LEFT" style="margin-left: 30.0px;">If CREATEDB is specified, the role being defined will be allowed to create new roles, alter other roles, and drop other roles. NOCREATEROLE (the default) will deny a role the ability to create roles or modify roles other than their own.</p><pre>CREATEEXTTABLE<br/>NOCREATEEXTTABLE</pre><p align="LEFT" style="margin-left: 30.0px;">If CREATEEXTTABLE is specified, the role being defined is allowed to create external tables. The default type is readable and the default protocol is gpfdist if not specified. NOCREATEEXTTABLE (the default) denies the role the ability to create external tables. Note that external tables that use the file or execute protocols can only be created by superusers.</p><pre>INHERIT<br/>NOINHERIT</pre><p align="LEFT" style="margin-left: 30.0px;">If specified, INHERIT (the default) allows the role to use whatever database privileges have been granted to all roles it is directly or indirectly a member of. With NOINHERIT, membership in another role only grants the ability to SET ROLE to that other role.</p><pre>LOGIN<br/>NOLOGIN</pre><p align="LEFT" style="margin-left: 30.0px;">If specified, LOGIN allows a role to log in to a database. A role having the LOGIN attribute can be thought of as a user. Roles with NOLOGIN (the default) are useful for managing database privileges, and can be thought of as groups.</p><pre>CONNECTION LIMIT <em>connlimit</em></pre><p align="LEFT" style="margin-left: 30.0px;">The number maximum of concurrent connections this role can make. The default of -1 means there is no limitation.</p><pre>PASSWORD password</pre><p align="LEFT" style="margin-left: 30.0px;">Sets the user password for roles with the LOGIN attribute. If you do not plan to use password authentication you can omit this option. If no password is specified, the password will be set to null and password authentication will always fail for that user. A null password can optionally be written explicitly as PASSWORD NULL.</p><pre>ENCRYPTED<br/>UNENCRYPTED</pre><p align="LEFT" style="margin-left: 30.0px;">These key words control whether the password is stored encrypted in the system catalogs. (If neither is specified, the default behavior is determined by the configuration parameter <em>password_encryption</em><span style="font-size: medium;"> </span>.) If the presented password string is already in MD5-encrypted format, then it is stored encrypted as-is, regardless of whether ENCRYPTED or UNENCRYPTED is specified (since the system cannot decrypt the specified encrypted password string). This allows reloading of encrypted passwords during dump/restore.</p><p align="LEFT" style="margin-left: 30.0px;">Note that older clients may lack support for the MD5 authentication mechanism that is needed to work with passwords that are stored encrypted.</p><pre>VALID UNTIL 'timestamp<span> </span>' </pre><p align="LEFT" style="margin-left: 30.0px;">The VALID UNTIL clause sets a date and time after which the role’s password is no longer valid. If this clause is omitted the password will never expire.</p><pre>IN ROLE rolename</pre><p align="LEFT" style="margin-left: 30.0px;">Adds the new role as a member of the named roles. Note that there is no option to add the new role as an administrator; use a separate GRANT command to do that.</p><pre>ROLE rolename</pre><p align="LEFT" style="margin-left: 30.0px;">Adds the named roles as members of this role, making this new role a group.</p><pre>ADMIN rolename</pre><p align="LEFT" style="margin-left: 30.0px;">The ADMIN clause is like ROLE, but the named roles are added to the new role WITH ADMIN OPTION, giving them the right to grant membership in this role to others.</p><pre>RESOURCE QUEUE queue_name</pre><p align="LEFT" style="margin-left: 30.0px;">The name of the resource queue to which the new user-level role is to be assigned. Only roles with LOGIN privilege can be assigned to a resource queue. The special keyword NONE means that the role is assigned to the default resource queue. A role can only belong to one resource queue.</p><pre>DENY deny_point<br/>DENY BETWEEN deny_point <span> </span>AND deny_point</pre><p align="LEFT" style="margin-left: 30.0px;">The DENY and DENY BETWEEN keywords set time-based constraints that are enforced at login. DENY sets a day or a day and time to deny access. DENY BETWEEN sets an interval during which access is denied. Both use the parameter <em>deny_point </em><span style="font-size: medium;"> </span>that has the following format:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">DAY day [ TIME 'time' ]</pre>
</div></div><p align="LEFT" style="margin-left: 30.0px;">The two parts of the deny_point parameter use the following formats:</p><p align="LEFT" style="margin-left: 30.0px;">For day:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">{'Sunday'| 'Monday' | 'Tuesday' |'Wednesday' | 'Thursday' | 'Friday' |' Saturday' | 0-6 }</pre>
</div></div><p align="LEFT" style="margin-left: 30.0px;">For time:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">{ 00-23 : 00-59 | 01-12 : 00-59 { AM | PM }}</pre>
</div></div><p align="LEFT" style="margin-left: 30.0px;">The DENY BETWEEN clause uses two <em>deny_point </em><span style="font-size: medium;"> </span>parameters.</p><p align="LEFT" style="margin-left: 30.0px;">DENY BETWEEN deny_point AND deny_point</p><h3 id="SQLCommandReference-Notes.13">Notes</h3><p align="LEFT">The preferred way to add and remove role members (manage groups) is to use GRANT and REVOKE.</p><p align="LEFT">The VALID UNTIL clause defines an expiration time for a password only, not for the role. The expiration time is not enforced when logging in using a non-password-based authentication method.</p><p align="LEFT">The INHERIT attribute governs inheritance of grantable privileges (access privileges for database objects and role memberships). It does not apply to the special role attributes set by CREATE ROLE and ALTER ROLE. For example, being a member of a role with CREATEDB privilege does not immediately grant the ability to create databases, even if INHERIT is set.</p><p align="LEFT">The INHERIT attribute is the default for reasons of backwards compatibility. In prior releases of HAWQ, users always had access to all privileges of groups they were members of. However, NOINHERIT provides a closer match to the semantics specified in the SQL standard.</p><p align="LEFT">Be careful with the CREATEROLE privilege. There is no concept of inheritance for the privileges of a CREATEROLE-role. That means that even if a role does not have a certain privilege but is allowed to create other roles, it can easily create another role with different privileges than its own (except for creating roles with superuser privileges). For example, if a role has the CREATEROLE privilege but not the CREATEDB privilege, it can create a new role with the CREATEDB privilege. Therefore, regard roles that have the CREATEROLE privilege as almost-superuser-roles.</p><p align="LEFT">The CONNECTION LIMIT option is never enforced for superusers.</p><p align="LEFT">Caution must be exercised when specifying an unencrypted password with this command. The password will be transmitted to the server in clear-text, and it might also be logged in the client’s command history or the server log. The client program createuser, however, transmits the password encrypted. Also, psql contains a command\password that can be used to safely change the password later.<span style="font-size: medium;"><span style="font-size: medium;"> </span></span></p><h3 id="SQLCommandReference-Examples.13">Examples</h3><p align="LEFT">Create a role that can log in, but don't give it a password:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE ROLE jonathan LOGIN;</pre>
</div></div><p align="LEFT">Create a role that belongs to a resource queue:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE ROLE jonathan LOGIN RESOURCE QUEUE poweruser;</pre>
</div></div><p align="LEFT">Create a role with a password that is valid until the end of 2009 (CREATE USER is the same as CREATE ROLE except that it implies LOGIN):</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;"> CREATE USER joelle WITH PASSWORD 'jw8s0F4' VALID UNTIL '2010-01-01': </pre>
</div></div><p align="LEFT">Create a role that can create databases and manage other roles:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE ROLE admin WITH CREATEDB CREATEROLE;</pre>
</div></div><p align="LEFT">Create a role that does not allow login access on Sundays:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE ROLE user3 DENY DAY 'Sunday';</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.17">Compatibility</h3><p>The SQL standard defines the concepts of users and roles, but it regards them as distinct concepts and leaves all commands defining users to be specified by the database implementation. In HAWQ users and roles are unified into a single type of object. Roles therefore have many more optional attributes than they do in the standard.</p><p align="LEFT">CREATE ROLE is in the SQL standard, but the standard only requires the syntax:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE ROLE name [WITH ADMIN rolename]</pre>
</div></div><p align="LEFT">Allowing multiple initial administrators, and all the other options of CREATE ROLE, are HAWQ extensions.</p><p align="LEFT">The behavior specified by the SQL standard is most closely approximated by giving users the NOINHERIT attribute, while roles are given the INHERIT attribute.</p><h3 id="SQLCommandReference-SeeAlso.15">See Also</h3><p>SET ROLE, ALTER ROLE, DROP ROLE, GRANT, REVOKE, CREATE RESOURCE QUEUE</p><h2 id="SQLCommandReference-CREATESCHEMA">CREATE SCHEMA</h2><p>Defines a new schema.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">CREATE SCHEMA schema_name [AUTHORIZATION username] [schema_element [ ... ]]
CREATE SCHEMA AUTHORIZATION rolename [schema_element [ ... ]]</pre>
</div></div><h3 id="SQLCommandReference-Description.18">Description</h3><p>CREATE SCHEMA enters a new schema into the current database. The schema name must be distinct from the name of any existing schema in the current database.</p><p align="LEFT">A schema is essentially a namespace: it contains named objects (tables, data types,functions, and operators) whose names may duplicate those of other objects existing in other schemas. Named objects are accessed either by qualifying their names with the schema name as a prefix, or by setting a search path that includes the desired schema(s). A CREATE command specifying an unqualified object name creates the object in the current schema (the one at the front of the search path, which can be determined with the function current_schema).</p><p align="LEFT">Optionally, CREATE SCHEMA can include subcommands to create objects within the new schema. The subcommands are treated essentially the same as separate commands issued after creating the schema, except that if the AUTHORIZATION clause is used, all the created objects will be owned by that role.</p><h3 id="SQLCommandReference-Parameters.15">Parameters</h3><pre>schema_name</pre><p align="LEFT" style="margin-left: 30.0px;">The name of a schema to be created. If this is omitted, the user name is used as the schema name. The name cannot begin with <em>pg_</em><span style="font-size: medium;"> </span>, as such names are reserved for system catalog schemas.</p><pre>rolename</pre><p align="LEFT" style="margin-left: 30.0px;">The name of the role who will own the schema. If omitted, defaults to the role executing the command. Only superusers may create schemas owned by roles other than themselves.</p><pre>schema_element</pre><p align="LEFT" style="margin-left: 30.0px;">An SQL statement defining an object to be created within the schema. Currently, only CREATE TABLE, CREATE VIEW, CREATE SEQUENCE and GRANT are accepted as clauses within CREATE SCHEMA. Other kinds of objects may be created in separate commands after the schema is created.</p><h3 id="SQLCommandReference-Notes.14">Notes</h3><p align="LEFT">To create a schema, the invoking user must have the CREATE privilege for the current database or be a superuser.</p><h3 id="SQLCommandReference-Examples.14">Examples</h3><p align="LEFT">Create a schema:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE SCHEMA myschema;</pre>
</div></div><p align="LEFT">Create a schema for role <em>joe </em><span style="font-size: medium;"> </span>(the schema will also be named <em>joe</em><span style="font-size: medium;"> </span>):</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE SCHEMA AUTHORIZATION joe;</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.18">Compatibility</h3><p>The SQL standard allows a DEFAULT CHARACTER SET clause in CREATE SCHEMA, as well as more subcommand types than are presently accepted by HAWQ.</p><p align="LEFT">The SQL standard specifies that the subcommands in CREATE SCHEMA may appear in any order. The present HAWQ implementation does not handle all cases of forward references in subcommands; it may sometimes be necessary to reorder the subcommands in order to avoid forward references.</p><p align="LEFT">According to the SQL standard, the owner of a schema always owns all objects within it. HAWQ allows schemas to contain objects owned by users other than the schema owner. This can happen only if the schema owner grants the CREATE privilege on the schema to someone else.</p><h3 id="SQLCommandReference-SeeAlso.16">See Also</h3><p align="LEFT">DROP SCHEMA</p><h2 id="SQLCommandReference-CREATESEQUENCE">CREATE SEQUENCE</h2><p>Defines a new sequence generator.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">CREATE [TEMPORARY | TEMP] SEQUENCE name
       [INCREMENT [BY] value]
       [MINVALUE minvalue | NO MINVALUE]
       [MAXVALUE maxvalue | NO MAXVALUE]
       [START [ WITH ] start]
       [CACHE cache]
       [[NO] CYCLE]
       [OWNED BY { table.column | NONE }]</pre>
</div></div><h3 id="SQLCommandReference-Description.19">Description</h3><p align="LEFT">CREATE SEQUENCE creates a new sequence number generator. This involves creating and initializing a new special single-row table. The generator will be owned by the user issuing the command.</p><p align="LEFT">If a schema name is given, then the sequence is created in the specified schema. Otherwise it is created in the current schema. Temporary sequences exist in a special schema, so a schema name may not be given when creating a temporary sequence. The sequence name must be distinct from the name of any other sequence, table, or view in the same schema.</p><p align="LEFT">After a sequence is created, you use the nextval function to operate on the sequence. For example, to insert a row into a table that gets the next value of a sequence:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">INSERT INTO distributors VALUES (nextval('myserial'), 'acme');</pre>
</div></div><p>You can also use the function setval to operate on a sequence, but only for queries that do not operate on distributed data. For example, the following query is allowed because it resets the sequence counter value for the sequence generator process on the master:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">SELECT setval('myserial', 201);</pre>
</div></div><p align="LEFT">But the following query will be rejected in HAWQ because it operates on distributed data:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">INSERT INTO product VALUES (setval('myserial', 201),'gizmo');</pre>
</div></div><p align="LEFT">In a regular (non-distributed) database, functions that operate on the sequence go to the local sequence table to get values as they are needed. In HAWQ, however, keep in mind that each segment is its own distinct database process. Therefore the segments need a single point of truth to go for sequence values so that all segments get incremented correctly and the sequence moves forward in the right order. A sequence server process runs on the master and is the point-of-truth for a sequence in a HAWQ distributed database. Segments get sequence values at runtime from the master.</p><p align="LEFT">Because of this distributed sequence design, there are some limitations on the functions that operate on a sequence in HAWQ:</p><ul><li>lastval and currval functions are not supported.</li><li>setval can only be used to set the value of the sequence generator on the master, it cannot be used in subqueries to update records on distributed table data.</li><li>nextval sometimes grabs a block of values from the master for a segment to use, depending on the query. So values may sometimes be skipped in the sequence if all of the block turns out not to be needed at the segment level. Note that a regular PostgreSQL database does this too, so this is not something unique to HAWQ.</li></ul><p align="LEFT">Although you cannot update a sequence directly, you can use a query like:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">SELECT * FROM sequence_name ;</pre>
</div></div><p align="LEFT">to examine the parameters and current state of a sequence. In particular, the <em>last_value </em>field of the sequence shows the last value allocated by any session.</p><h3 id="SQLCommandReference-Parameters.16">Parameters</h3><pre>TEMPORARY | TEMP</pre><p align="LEFT" style="margin-left: 30.0px;">If specified, the sequence object is created only for this session, and is automatically dropped on session exit. Existing permanent sequences with the same name are not visible (in this session) while the temporary sequence exists, unless they are referenced with schema-qualified names.</p><pre>name</pre><p align="LEFT" style="margin-left: 30.0px;">The name (optionally schema-qualified) of the sequence to be created.</p><pre>increment</pre><p align="LEFT" style="margin-left: 30.0px;">Specifies which value is added to the current sequence value to create a new value. A positive value will make an ascending sequence, a negative one a descending sequence. The default value is 1.</p><pre>minvalue<br/>NO MINVALUE</pre><p align="LEFT" style="margin-left: 30.0px;">Determines the minimum value a sequence can generate. If this clause is not supplied or NO MINVALUE is specified, then defaults will be used. The defaults are 1 and -263-1 for ascending and descending sequences, respectively.</p><pre>maxvalue<br/>NO MAXVALUE</pre><p align="LEFT" style="margin-left: 30.0px;">Determines the maximum value for the sequence. If this clause is not supplied or NO MAXVALUE is specified, then default values will be used. The defaults are 263-1 and -1 for ascending and descending sequences, respectively.</p><pre>start</pre><p align="LEFT" style="margin-left: 30.0px;">Allows the sequence to begin anywhere. The default starting value is <em>minvalue </em><span style="font-size: small;"> </span>for ascending sequences and <em>maxvalue </em><span style="font-size: small;"> </span>for descending ones.</p><pre>cache</pre><p align="LEFT" style="margin-left: 30.0px;">Specifies how many sequence numbers are to be preallocated and stored in memory for faster access. The minimum (and default) value is 1 (no cache).</p><pre>CYCLE<br/>NO CYCLE</pre><p align="LEFT" style="margin-left: 30.0px;">Allows the sequence to wrap around when the <em>maxvalue </em><span style="font-size: small;"> </span>(for ascending) or minvalue (for descending) has been reached. If the limit is reached, the next number generated will be the <em>minvalue </em><span style="font-size: small;"> </span>(for ascending) or <em>maxvalue </em><span style="font-size: small;"> </span>(for descending). If NO CYCLE is specified, any calls to nextval after the sequence has reached its maximum value will return an error. If not specified, NO CYCLE is the default.</p><pre>OWNED BY table.column<br/>OWNED BY NONE</pre><p align="LEFT" style="margin-left: 30.0px;">Causes the sequence to be associated with a specific table column, such that if that column (or its whole table) is dropped, the sequence will be automatically dropped as well. The specified table must have the same owner and be in the same schema as the sequence. OWNED BY NONE, the default, specifies that there is no such association.</p><h3 id="SQLCommandReference-Notes.15">Notes</h3><p align="LEFT">Sequences are based on bigint arithmetic, so the range cannot exceed the range of an eight-byte integer (-9223372036854775808 to 9223372036854775807).</p><p align="LEFT">Although multiple sessions are guaranteed to allocate distinct sequence values, the values may be generated out of sequence when all the sessions are considered. For example, session A might reserve values 1..10 and return nextval=1, then session B might reserve values 11..20 and return nextval=11 before session A has generated nextval=2. Thus, you should only assume that the nextval values are all distinct, not that they are generated purely sequentially. Also, <em>last_value </em><span style="font-size: medium;"> </span>will reflect the latest value reserved by any session, whether or not it has yet been returned by nextval.</p><h3 id="SQLCommandReference-Examples.15">Examples</h3><p align="LEFT">Create a sequence named <em>myseq</em><span style="font-size: medium;"> </span>:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE SEQUENCE myseq START 101;</pre>
</div></div><p align="LEFT">Insert a row into a table that gets the next value:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">INSERT INTO distributors VALUES (nextval('myseq'), 'acme');</pre>
</div></div><p align="LEFT">Reset the sequence counter value on the master:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">SELECT setval('myseq', 201);</pre>
</div></div><p align="LEFT">Illegal use of setval in HAWQ (setting sequence values on distributed data):</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">INSERT INTO product VALUES (setval('myseq', 201), 'gizmo');</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.19">Compatibility</h3><p align="LEFT">CREATE SEQUENCE conforms to the SQL standard, with the following exceptions:</p><ul><li>The AS <em>data_type </em><span style="font-size: small;"> </span>expression specified in the SQL standard is not supported.</li><li>Obtaining the next value is done using the nextval() function instead of the NEXT VALUE FOR expression specified in the SQL standard.</li><li>The OWNED BY clause is a HAWQ extension.</li></ul><h3 id="SQLCommandReference-SeeAlso.17">See Also</h3><p align="LEFT">DROP SEQUENCE</p><h2 id="SQLCommandReference-CREATETABLE">CREATE TABLE</h2><p>Defines a new table.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">CREATE [[GLOBAL | LOCAL] {TEMPORARY | TEMP}] TABLE table_name (
[ { column_name data_type [ DEFAULT default_expr ]    [column_constraint [ ... ]
[ ENCODING ( storage_directive [,...] ) ]]
   | table_constraint
   | LIKE other_table [{INCLUDING | EXCLUDING}
                      {DEFAULTS | CONSTRAINTS}] ...}
   [, ... ] ]
   [column_reference_storage_directive [, …] ]
   )
   [ INHERITS ( parent_table [, ... ] ) ]
   [ WITH ( storage_parameter=value [, ... ] )
   [ ON COMMIT {PRESERVE ROWS | DELETE ROWS | DROP} ]
   [ TABLESPACE tablespace ]
   [ DISTRIBUTED BY (column, [ ... ] ) | DISTRIBUTED RANDOMLY ]
   [ PARTITION BY partition_type (column)
       [ SUBPARTITION BY partition_type (column) ]
          [ SUBPARTITION TEMPLATE ( template_spec ) ]
       [...]
    ( partition_spec )
        | [ SUBPARTITION BY partition_type (column) ]
          [...]
    ( partition_spec
       [ ( subpartition_spec
            [(...)]
         ) ]
    )
where storage_parameter is:
   APPENDONLY={TRUE}
   BLOCKSIZE={8192-2097152}
   ORIENTATION={COLUMN|ROW}
   COMPRESSTYPE={ZLIB|QUICKLZ|RLE_TYPE|NONE}
   COMPRESSLEVEL={0-9}
   FILLFACTOR={10-100}
   OIDS[=TRUE|FALSE]
where column_constraint is:
   [CONSTRAINT constraint_name]
   NOT NULL | NULL
   | CHECK ( expression )
 and table_constraint is:
   [CONSTRAINT constraint_name]
   CHECK ( expression )
 where partition_type is:
    LIST
  | RANGE
where partition_specification is:
partition_element [, ...]
and partition_element is:
   DEFAULT PARTITION name
   | [PARTITION name] VALUES (list_value [,...] )
   | [PARTITION name]
     START ([datatype] 'start_value') [INCLUSIVE | EXCLUSIVE]
     [ END ([datatype] 'end_value') [INCLUSIVE | EXCLUSIVE] ]
     [ EVERY ([datatype] [number | INTERVAL] 'interval_value') ]
  | [PARTITION name]
     END ([datatype] 'end_value') [INCLUSIVE | EXCLUSIVE]
     [ EVERY ([datatype] [number | INTERVAL] 'interval_value') ]
[ WITH ( partition_storage_parameter=value [, ... ] ) ]
[column_reference_storage_directive [, …] ]
[ TABLESPACE tablespace ]
 where subpartition_spec or template_spec is:
subpartition_element [, ...]
and subpartition_element is:
   DEFAULT SUBPARTITION name
   | [SUBPARTITION name] VALUES (list_value [,...] )
   | [SUBPARTITION name]
     START ([datatype] 'start_value') [INCLUSIVE | EXCLUSIVE]
     [ END ([datatype] 'end_value') [INCLUSIVE | EXCLUSIVE] ]
     [ EVERY ([datatype] [number | INTERVAL] 'interval_value') ]
  | [SUBPARTITION name]
     END ([datatype] 'end_value') [INCLUSIVE | EXCLUSIVE]
     [ EVERY ([datatype] [number | INTERVAL] 'interval_value') ]
[ WITH ( partition_storage_parameter=value [, ... ] ) ]
[column_reference_storage_directive [, …] ]
[ TABLESPACE tablespace ]
where storage_parameter is:
   APPENDONLY={TRUE}
   BLOCKSIZE={8192-2097152}
   ORIENTATION={COLUMN|ROW}
   COMPRESSTYPE={ZLIB|QUICKLZ|RLE_TYPE|NONE}
   COMPRESSLEVEL={0-9}
   FILLFACTOR={10-100}
   OIDS[=TRUE|FALSE]
where storage_directive is:
   COMPRESSTYPE={ZLIB | QUICKLZ | RLE_TYPE | NONE}
 | COMPRESSLEVEL={0-9}
 | BLOCKSIZE={8192-2097152}
Where 
column_reference_storage_directive is:
COLUMN column_name ENCODING (storage_directive [, ... ] ), ...
 | 
DEFAULT COLUMN ENCODING (storage_directive [, ... ] )</pre>
</div></div><h3 id="SQLCommandReference-Description.20">Description</h3><p align="LEFT">CREATE TABLE will create a new, initially empty table in the current database. The table will be owned by the user issuing the command. If a schema name is given then the table is created in the specified schema. Otherwise it is created in the current schema. Temporary tables exist in a special schema, so a schema name may not be given when creating a temporary table. The name of the table must be distinct from the name of any other table, external table, sequence, or view in the same schema.</p><p align="LEFT">The optional constraint clauses specify conditions that new or updated rows must satisfy for an insert or update operation to succeed. A constraint is an SQL object thathelps define the set of valid values in the table in various ways. Constraints apply to tables, not to partitions. You cannot add a constraint to a partition or subpartition.</p><p align="LEFT">There are two ways to define constraints: table constraints and column constraints. A column constraint is defined as part of a column definition. A table constraint definition is not tied to a particular column, and it can encompass more than one column. Every column constraint can also be written as a table constraint; a column constraint is only a notational convenience for use when the constraint only affects one column.</p><p align="LEFT">When creating a table, there is an additional clause to declare the HAWQ distribution policy. If a DISTRIBUTED BY or DISTRIBUTED RANDOMLY clause is not supplied, then HAWQ assigns a hash distribution policy to the table using the first column of the table as the distribution key. Columns of geometric or user-defined data types are not eligible as HAWQ distribution key columns. If a table does not have a column of an eligible data type, the rows are distributed based on a round-robin or random distribution. To ensure an even distribution of data in your HAWQ system, you want to choose a distribution key that is unique for each record, or if that is not possible, then choose DISTRIBUTED RANDOMLY.</p><p align="LEFT">The PARTITION BY clause allows you to divide the table into multiple sub-tables (or parts) that, taken together, make up the parent table and share its schema. Though the sub-tables exist as independent tables, HAWQ restricts their use in important ways. Internally, partitioning is implemented as a special form of inheritance. Each child table partition is created with a distinct CHECK constraint which limits the data the table can contain, based on some defining criteria. The CHECK constraints are also used by the query planner to determine which table partitions to scan in order to satisfy a given query predicate. These partition constraints are managed automatically by HAWQ.</p><h3 id="SQLCommandReference-Parameters.17">Parameters</h3><pre>GLOBAL | LOCAL</pre><p align="LEFT" style="margin-left: 30.0px;">These keywords are present for SQL standard compatibility, but have no effect in HAWQ.</p><pre>TEMPORARY | TEMP</pre><p align="LEFT" style="margin-left: 30.0px;">If specified, the table is created as a temporary table. Temporary tables are automatically dropped at the end of a session, or optionally at the end of the current transaction (see ON COMMIT). Existing permanent tables with the same name are not visible to the current session while the temporary table exists, unless they are referenced with schema-qualified names.</p><pre>table_name</pre><p align="LEFT" style="margin-left: 30.0px;">The name (optionally schema-qualified) of the table to be created.</p><pre>column_name</pre><p align="LEFT" style="margin-left: 30.0px;">The name of a column to be created in the new table.</p><pre>data_type</pre><p align="LEFT" style="margin-left: 30.0px;">The data type of the column. This may include array specifiers.</p><pre>DEFAULT default_expr</pre><p align="LEFT" style="margin-left: 30.0px;">The DEFAULT clause assigns a default data value for the column whose column definition it appears within. The value is any variable-free expression (subqueries and cross-references to other columns in the current table are not allowed). The data type of the default expression must match the data type of the column. The default expression will be used in any insert operation that does not specify a value for the column. If there is no default for a column, then the default is null.</p><pre>INHERITS</pre><p align="LEFT" style="margin-left: 30.0px;">The optional INHERITS clause specifies a list of tables from which the new table automatically inherits all columns. Use of INHERITS creates a persistent relationship between the new child table and its parent table(s). Schema modifications to the parent(s) normally propagate to children as well, and by default the data of the child table is included in scans of the parent(s).</p><p align="LEFT" style="margin-left: 30.0px;">In HAWQ, the INHERITS clause is not used when creating partitioned tables. Although the concept of inheritance is used in partition hierarchies, the inheritance structure of a partitioned table is created using the PARTITION BY clause.</p><p align="LEFT" style="margin-left: 30.0px;">If the same column name exists in more than one parent table, an error is reported unless the data types of the columns match in each of the parent tables. If there is no conflict, then the duplicate columns are merged to form a single column in the new table. If the column name list of the new table contains a column name that is also inherited, the data type must likewise match the inherited column(s), and the column definitions are merged into one. However, inherited and new column declarations of the same name need not specify identical constraints: all constraints provided from any declaration are merged together and all are applied to the new table. If the new table explicitly specifies a default value for the column, this default overrides any defaults from inherited declarations of the column. Otherwise, any parents that specify default values for the column must all specify the same default, or an error will be reported.</p><pre>LIKE other_table <span style="font-size: medium;"> </span>[{INCLUDING | EXCLUDING} {DEFAULTS |CONSTRAINTS}]</pre><p align="LEFT" style="margin-left: 30.0px;">The LIKE clause specifies a table from which the new table automatically copies all column names, data types, not-null constraints, and distribution policy. Storage properties like append-only or partition structure are not copied. Unlike INHERITS, the new table and original table are completely decoupled after creation is complete.</p><p align="LEFT" style="margin-left: 30.0px;">Default expressions for the copied column definitions will only be copied if INCLUDING DEFAULTS is specified. The default behavior is to exclude default expressions, resulting in the copied columns in the new table having null defaults.</p><p align="LEFT" style="margin-left: 30.0px;">Not-null constraints are always copied to the new table. CHECK constraints will only be copied if INCLUDING CONSTRAINTS is specified; other types of constraints will never be copied. Also, no distinction is made between column constraints and table constraints — when constraints are requested, all check constraints are copied.</p><p align="LEFT" style="margin-left: 30.0px;">Note also that unlike INHERITS, copied columns and constraints are not merged with similarly named columns and constraints. If the same name is specified explicitly or in another LIKE clause an error is signalled.</p><pre>NULL | NOT NULL</pre><p align="LEFT" style="margin-left: 30.0px;">Specifies if the column is or is not allowed to contain null values. NULL is the default.</p><pre>CHECK (expression <span style="font-size: medium;"> </span>)</pre><p align="LEFT" style="margin-left: 30.0px;">The CHECK clause specifies an expression producing a Boolean result which new or updated rows must satisfy for an insert or update operation to succeed. Expressions evaluating to TRUE or UNKNOWN succeed. Should any row of an insert or update operation produce a FALSE result an error exception is raised and the insert or update does not alter the database. A check constraint specified as a column constraint should reference that column’s value only, while an expression appearing in a table constraint may reference multiple columns. CHECK expressions cannot contain subqueries nor refer to variables other than columns of the current row.</p><pre>WITH (storage_option<span style="font-size: medium;"> </span>=<em>value </em><span style="font-size: medium;"> </span>)</pre><p align="LEFT" style="margin-left: 30.0px;">The WITH clause can be used to set storage options for the table. Note that you can also set storage parameters on a particular partition or subpartition by declaring the WITH clause in the partition specification.</p><p align="LEFT" style="margin-left: 30.0px;">Note: You cannot create a table with both column encodings and compression parameters in a WITH clause. The following storage options are available:</p><p align="LEFT" style="margin-left: 30.0px;"><strong>APPENDONLY </strong>- Set to TRUE or not declared to create the table as an append-only table. If FALSE, an error message will notify that heap table does not support.</p><p align="LEFT" style="margin-left: 30.0px;"><strong>BLOCKSIZE</strong> - Set to the size, in bytes for each block in a table. The BLOCKSIZE must be between 8192 and 2097152 bytes, and be a multiple of 8192. The default is 32768.</p><p align="LEFT" style="margin-left: 30.0px;"><strong>ORIENTATION</strong> - Set to column for column-oriented storage, or row (the default) for row-oriented storage. This option is only valid if APPENDONLY=TRUE. Heap-storage tables can only be row-oriented.</p><p align="LEFT" style="margin-left: 30.0px;"><strong>COMPRESSTYPE</strong> - Set to ZLIB (the default) or QUICKLZ to specify the type of compression used. QuickLZ uses less CPU power and compresses data faster at a lower compression ratio than zlib. Conversely, zlib provides more compact compression ratios at lower speeds. This option is only valid if APPENDONLY=TRUE.</p><p align="LEFT" style="margin-left: 30.0px;"><strong>COMPRESSLEVEL</strong> - For zlib compression of append-only tables, set to a value between 1 (fastest compression) to 9 (highest compression ratio). QuickLZ compression level can only be set to 1. If not declared, the default is 1. This option is only valid if APPENDONLY=TRUE.</p><p align="LEFT" style="margin-left: 30.0px;"><strong>OIDS</strong> - Set to OIDS=FALSE (the default) so that rows do not have object identifiers assigned to them. Greenplum strongly recommends that you do not enable OIDS when creating a table. On large tables, such as those in a typical HAWQ system, using OIDs for table rows can cause wrap-around of the 32-bit OID counter. Once the counter wraps around, OIDs can no longer be assumed to be unique, which not only makes them useless to user applications, but can also cause problems in the HAWQ system catalog tables. In addition, excluding OIDs from a table reduces the space required to store the table on disk by 4 bytes per row, slightly improving performance. OIDS are not allowed on partitioned tables or append-only column-oriented tables.</p><pre>ON COMMIT</pre><p align="LEFT" style="margin-left: 30.0px;">The behavior of temporary tables at the end of a transaction block can be controlled using ON COMMIT. The three options are:</p><pre>PRESERVE ROWS</pre><p align="LEFT" style="margin-left: 30.0px;">No special action is taken at the ends of transactions for temporary tables. This is the default behavior.</p><pre>DELETE ROWS</pre><p align="LEFT" style="margin-left: 30.0px;">All rows in the temporary table will be deleted at the end of each transaction block. Essentially, an automatic TRUNCATE is done at each commit.</p><pre>DROP</pre><p align="LEFT" style="margin-left: 30.0px;">The temporary table will be dropped at the end of the current transaction block.</p><pre>TABLESPACE tablespace</pre><p align="LEFT" style="margin-left: 30.0px;">The name of the tablespace in which the new table is to be created. If not specified, the database’s default tablespace dfs_default is used. Creating table on tablespace 'pg_default' is not allowed.</p><pre>DISTRIBUTED BY (column, [ ... ] )<br/>DISTRIBUTED RANDOMLY</pre><p><span style="font-family: TimesNewRomanPSMT;font-size: medium;"><span style="font-family: TimesNewRomanPSMT;font-size: medium;">Used to declare the HAWQ distribution policy for the table. </span></span><span style="font-family: CourierNewPSMT;font-size: small;"><span style="font-family: CourierNewPSMT;font-size: small;">DISTIBUTED BY </span></span><span style="font-family: TimesNewRomanPSMT;font-size: medium;"><span style="font-family: TimesNewRomanPSMT;font-size: medium;">uses </span></span>hash distribution with one or more columns declared as the distribution key. For the most even data distribution, the distribution key should be the primary key of the table or a unique column (or set of columns). If that is not possible, then you may <span style="font-family: TimesNewRomanPSMT;font-size: medium;"><span style="font-family: TimesNewRomanPSMT;font-size: medium;">choose </span></span><span style="font-family: CourierNewPSMT;font-size: small;"><span style="font-family: CourierNewPSMT;font-size: small;">DISTRIBUTED RANDOMLY</span></span><span style="font-family: TimesNewRomanPSMT;font-size: medium;"><span style="font-family: TimesNewRomanPSMT;font-size: medium;">, which will send the data round-robin to the </span></span>segment instances. If not supplied, then hash distribution is chosen using the first eligible column of the table as the distribution key.</p><pre>PARTITION BY</pre><p align="LEFT" style="margin-left: 30.0px;">Declares one or more columns by which to partition the table.</p><pre>partition_type</pre><p style="margin-left: 30.0px;">Declares partition type: LIST (list of values) or RANGE (a numeric or date range).</p><pre>partition_specification</pre><p align="LEFT" style="margin-left: 30.0px;">Declares the individual partitions to create. Each partition can be defined individually or, for range partitions, you can use the EVERY clause (with a START and optional END clause) to define an increment pattern to use to create the individual partitions.</p><p align="LEFT" style="margin-left: 60.0px;"><strong>DEFAULT PARTITION name</strong> - Declares a default partition. When data does not match to an existing partition, it is inserted into the default partition. Partition designs that do not have a default partition will reject incoming rows that do not match to an existing partition.</p><p style="margin-left: 60.0px;"><strong>PARTITION name</strong> - Declares a name to use for the partition. Partitions are created using the following naming convention:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">parentname_level#_prt_givenname.</pre>
</div></div><p style="margin-left: 60.0px;"><strong>VALUES</strong> - For list partitions, defines the value(s) that the partition will contain.</p><p style="margin-left: 60.0px;"><strong>START</strong> - For range partitions, defines the starting range value for the partition. By default, start values are INCLUSIVE. For example, if you declared a start date of ‘2008-01-01’, then the partition would contain all dates greater than or equal to ‘2008-01-01’. Typically the data type of the START expression is the same type as the partition key column. If that is not the case, then you must explicitly cast to the intended data type.</p><p style="margin-left: 60.0px;"><strong>END</strong> - For range partitions, defines the ending range value for the partition. By default, end values are EXCLUSIVE. For example, if you declared an end date of ‘2008-02-01’, then the partition would contain all dates less than but not equal to ‘2008-02-01’. Typically the data type of the END expression is the same type as the partition key column. If that is not the case, then you must explicitly cast to the intended data type.</p><p style="margin-left: 60.0px;"><strong>EVERY</strong> - For range partitions, defines how to increment the values from START to END to create individual partitions. Typically the data type of the EVERY expression is the same type as the partition key column. If that is not the case, then you must explicitly cast to the intended data type.</p><p align="LEFT" style="margin-left: 60.0px;"><strong>WITH</strong> - Sets the table storage options for a partition. For example, you may want older partitions to be append-only tables and newer partitions to be regular heap tables.</p><p align="LEFT" style="margin-left: 60.0px;"><strong>TABLESPACE</strong> - The name of the tablespace in which the partition is to be created.</p><pre>SUBPARTITION BY</pre><p style="margin-left: 30.0px;">Declares one or more columns by which to subpartition the first-level partitions of the table. The format of the subpartition specification is similar to that of a partition specification described above.</p><pre>SUBPARTITION TEMPLATE</pre><p style="margin-left: 30.0px;">Instead of declaring each subpartition definition individually for each partition, you can optionally declare a subpartition template to be used to create the subpartitions. This subpartition specification would then apply to all parent partitions.</p><h3 id="SQLCommandReference-Notes.16">Notes</h3><p align="LEFT">Using OIDs in new applications is not recommended: where possible, using a SERIAL or other sequence generator as the table’s primary key is preferred. However, if your application does make use of OIDs to identify specific rows of a table, it is recommended to create a unique constraint on the OID column of that table, to ensure that OIDs in the table will indeed uniquely identify rows even after counter wrap-around. Avoid assuming that OIDs are unique across tables; if you need a database-wide unique identifier, use the combination of table OID and row OID for the purpose.</p><p align="LEFT">HAWQ has some special conditions for primary key and unique constraints with regards to columns that are the <em>distribution key </em><span style="font-size: medium;"> </span>in a HAWQ table. For a unique constraint to be enforced in HAWQ, the table must be hash-distributed (not DISTRIBUTED RANDOMLY), and the constraint columns must be the same as (or a superset of) the table’s distribution key columns.</p><p align="LEFT">Primary key and foreign key constraints are not supported in HAWQ. For inherited tables, table privileges <em>are not </em><span style="font-size: medium;"> </span>inherited in the current implementation.</p><h3 id="SQLCommandReference-Examples.16">Examples</h3><p align="LEFT">Create a table named rank in the schema named baby and distribute the data using the columns rank, gender, and year:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE TABLE baby.rank (id int, rank int, year smallint,gender char(1), count int ) DISTRIBUTED BY (rank, gender,year);</pre>
</div></div><p align="LEFT">Create table films and table distributors (the first column will be used as the HAWQ distribution key by default):</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE TABLE films (
code char(5),
title varchar(40) NOT NULL,
did integer NOT NULL,
date_prod date,
kind varchar(10),
len interval hour to minute
);
CREATE TABLE distributors (
did integer,
name varchar(40) NOT NULL CHECK (name &lt;&gt; '')
);</pre>
</div></div><p>Create a gzip-compressed, append-only table:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE TABLE sales (txn_id int, qty int, date date)
WITH (appendonly=true, compresslevel=5)
DISTRIBUTED BY (txn_id);</pre>
</div></div><p align="LEFT">Create a three level partitioned table using subpartition templates and default partitions at each level:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE TABLE sales (id int, year int, month int, day int,
region text)
DISTRIBUTED BY (id)
PARTITION BY RANGE (year)
SUBPARTITION BY RANGE (month)
SUBPARTITION TEMPLATE (
START (1) END (13) EVERY (1),
DEFAULT SUBPARTITION other_months )
SUBPARTITION BY LIST (region)
SUBPARTITION TEMPLATE (
SUBPARTITION usa VALUES ('usa'),
SUBPARTITION europe VALUES ('europe'),
SUBPARTITION asia VALUES ('asia'),
DEFAULT SUBPARTITION other_regions)
( START (2002) END (2010) EVERY (1),
DEFAULT PARTITION outlying_years);</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.20">Compatibility</h3><p>CREATE TABLE command conforms to the SQL standard, with the following exceptions:</p><ul><li><strong>Temporary Tables</strong> — In the SQL standard, temporary tables are defined just once and automatically exist (starting with empty contents) in every session that needs them. HAWQ instead requires each session to issue its own CREATE TEMPORARY TABLE command for each temporary table to be used. This allows different sessions to use the same temporary table name for different purposes, whereas the standard’s approach constrains all instances of a given temporary table name to have the same table structure. The standard’s distinction between global and local temporary tables is not in HAWQ. HAWQ will accept the GLOBAL and LOCAL keywords in a temporary table declaration, but they have no effect. If the ON COMMIT clause is omitted, the SQL standard specifies that the default behavior as ON COMMIT DELETE ROWS. However, the default behavior in HAWQ is ON COMMIT PRESERVE ROWS. The ON COMMIT DROP option does not exist in the SQL standard.</li><li><strong>Column Check Constraints</strong> — The SQL standard says that CHECK column constraints may only refer to the column they apply to; only CHECK table constraints may refer to multiple columns. HAWQ does not enforce this restriction; it treats column and table check constraints alike.</li><li><strong>NULL Constraint</strong><span style="font-size: medium;"> </span>— The NULL constraint is a HAWQ extension to the SQL standard that is included for compatibility with some other database systems (and for symmetry with the NOT NULL constraint). Since it is the default for any column, its presence is not required.</li><li><strong>Inheritance</strong><span style="font-size: medium;"> </span>— Multiple inheritance via the INHERITS clause is a HAWQ language extension. SQL:1999 and later define single inheritance using a different syntax and different semantics. SQL:1999-style inheritance is not yet supported by HAWQ.</li><li><strong>Partitioning</strong><span style="font-size: medium;"> </span>— Table partitioning via the PARTITION BY clause is a HAWQ language extension.</li><li><strong>Zero-column tables</strong><span style="font-size: medium;"> </span>— HAWQ allows a table of no columns to be created (for example, CREATE TABLE foo();). This is an extension from the SQL standard, which does not allow zero-column tables. Zero-column tables are not in themselves very useful, but disallowing them creates odd special cases for ALTER TABLE DROP COLUMN, so HAWQ decided to ignore this spec restriction.</li><li><strong>WITH clause</strong><span style="font-size: medium;"> </span>— The WITH clause is a HAWQ extension; neither storage parameters nor OIDs are in the standard.</li><li><strong>Tablespaces</strong><span style="font-size: medium;"> </span>— The HAWQ concept of tablespaces is not part of the SQL standard. The clauses TABLESPACE is extensions.</li><li><strong>Data Distribution</strong><span style="font-size: medium;"> </span>— The HAWQ concept of a parallel or distributed database is not part of the SQL standard. The DISTRIBUTED clauses are extensions.</li></ul><h3 id="SQLCommandReference-SeeAlso.18">See Also</h3><p align="LEFT">ALTER TABLE, DROP TABLE, CREATE EXTERNAL TABLE, CREATE TABLE AS<span style="font-size: medium;"> </span></p><h2 id="SQLCommandReference-CREATETABLEAS">CREATE TABLE AS</h2><p>Defines a new table from the results of a query.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">CREATE [ [GLOBAL | LOCAL] {TEMPORARY | TEMP} ] TABLE table_name
   [(column_name [, ...] )]
   [ WITH ( storage_parameter=value [, ... ] ) ]
   [ON COMMIT {PRESERVE ROWS | DELETE ROWS | DROP}]
   [TABLESPACE tablespace]
   AS query
   DISTRIBUTED BY (column, [ ... ] ) | DISTRIBUTED RANDOMLY]
 where storage_parameter is:
   APPENDONLY={TRUE}
   BLOCKSIZE={8192-2097152}
   ORIENTATION={COLUMN|ROW}
   COMPRESSTYPE={ZLIB|QUICKLZ}
   COMPRESSLEVEL={1-9 | 1}
   FILLFACTOR={10-100}
   OIDS[=TRUE|FALSE]</pre>
</div></div><h3 id="SQLCommandReference-Description.21">Description</h3><p>CREATE TABLE AS creates a table and fills it with data computed by a SELECT command. The table columns have the names and data types associated with the output columns of the SELECT, however you can override the column names by giving an explicit list of new column names.</p><p align="LEFT">CREATE TABLE AS creates a new table and evaluates the query just once to fill the new table initially. The new table will not track subsequent changes to the source  tables of the query.</p><h3 id="SQLCommandReference-Parameters.18">Parameters</h3><pre>GLOBAL | LOCAL</pre><p align="LEFT" style="margin-left: 30.0px;">These keywords are present for SQL standard compatibility, but have no effect in Greenplum Database.</p><pre>TEMPORARY | TEMP</pre><p align="LEFT" style="margin-left: 30.0px;">If specified, the new table is created as a temporary table. Temporary tables are automatically dropped at the end of a session, or optionally at the end of the current transaction (see ON COMMIT). Existing permanent tables with the same name are not visible to the current session while the temporary table exists, unless they are referenced with schema-qualified names.</p><pre>table_name</pre><p align="LEFT" style="margin-left: 30.0px;">The name (optionally schema-qualified) of the new table to be created.</p><pre>column_name</pre><p style="margin-left: 30.0px;">The name of a column in the new table. If column names are not provided, they are taken from the output column names of the query. If the table is created from an EXECUTE command, a column name list cannot be specified.</p><pre>WITH (<em>storage_parameter</em><span style="font-size: medium;"> </span>=<em>value </em><span style="font-size: medium;"> </span>)</pre><p style="margin-left: 30.0px;">The WITH clause can be used to set storage options for the table. Note that you can also set different storage parameters on a particular partition or subpartition by declaring the WITH clause in the partition specification. The following storage options are available:</p><p align="LEFT" style="margin-left: 60.0px;"><strong>APPENDONLY</strong> - Set to TRUE to create the table as an append-only table. If FALSE or not declared, the table will be created as a regular heap-storage table.</p><p align="LEFT" style="margin-left: 60.0px;"><strong>BLOCKSIZE</strong> - Set to the size, in bytes for each block in a table. The BLOCKSIZE must be between 8192 and 2097152 bytes, and be a multiple of 8192. The default is 32768.</p><p align="LEFT" style="margin-left: 60.0px;"><strong>ORIENTATION</strong> - Set to column for column-oriented storage, or row (the default) for row-oriented storage. This option is only valid if APPENDONLY=TRUE. Heap-storage tables can only be row-oriented.</p><p align="LEFT" style="margin-left: 60.0px;"><strong>COMPRESSTYPE</strong> - Set to ZLIB (the default) or QUICKLZ to specify the type of compression used. QuickLZ uses less CPU power and compresses data faster at a lower compression ratio than zlib. Conversely, zlib provides more compact compression ratios at lower speeds. This option is only valid if APPENDONLY=TRUE</p><p align="LEFT" style="margin-left: 60.0px;"><strong>COMPRESSLEVEL</strong> - For zlib compression of append-only tables, set to a value between 1 (fastest compression) to 9 (highest compression ratio). QuickLZ compression level can only be set to 1. If not declared, the default is 1. This option is only valid if APPENDONLY=TRUE.</p><p align="LEFT" style="margin-left: 60.0px;"><strong>OIDS</strong> - Set to OIDS=FALSE (the default) so that rows do not have object identifiers assigned to them. Greenplum strongly recommends that you do not enable OIDS when creating a table. On large tables, such as those in a typical Greenplum Database system, using OIDs for table rows can cause wrap-around of the 32-bit OID counter. Once the counter wraps around, OIDs can no longer be assumed to be unique, which not only makes them useless to user applications, but can also cause problems in the Greenplum Database system catalog tables. In addition, excluding OIDs from a table reduces the space required to store the table on disk by 4 bytes per row, slightly improving performance. OIDS are not allowed on column-oriented tables.</p><pre>ON COMMIT</pre><p align="LEFT" style="margin-left: 30.0px;">The behavior of temporary tables at the end of a transaction block can be controlled using ON COMMIT. The three options are:</p><pre>PRESERVE ROWS</pre><p style="margin-left: 30.0px;">No special action is taken at the ends of transactions for temporary tables. This is the default behavior.</p><pre>DELETE ROWS</pre><p style="margin-left: 30.0px;">All rows in the temporary table will be deleted at the end of each transaction block. Essentially, an automatic TRUNCATE is done at each commit.</p><pre>DROP</pre><p style="margin-left: 30.0px;">The temporary table will be dropped at the end of the current transaction block.</p><pre>TABLESPACE tablespace</pre><p style="margin-left: 30.0px;"><span style="font-size: medium;"><em><span style="font-size: medium;"> </span></em></span>The tablespace is the name of the tablespace in which the new table is to be created. If not specified, the database’s default tablespace is used.</p><pre>AS query</pre><p style="margin-left: 30.0px;">A SELECT command, or an EXECUTE command that runs a prepared SELECT query.</p><pre>DISTRIBUTED BY (column<span> </span>, [ ... ] )<br/>DISTRIBUTED RANDOMLY</pre><p style="margin-left: 30.0px;">Used to declare the Greenplum Database distribution policy for the table. One or more columns can be used as the distribution key, meaning those columns are used by the hashing algorithm to divide the data evenly across all of the segments. The distribution key should be the primary key of the table or a unique column (or set of columns). If that is not possible, then you may choose to distribute randomly, which will send the data round-robin to the segment instances. If not supplied, then either the PRIMARY KEY (if the table has one) or the first eligible column of the table will be used.<span style="font-size: medium;"> </span></p><h3 id="SQLCommandReference-Notes.17">Notes</h3><p>This command is functionally similar to SELECT INTO, but it is preferred since it is less likely to be confused with other uses of the SELECT INTO syntax. Furthermore, CREATE TABLE AS offers a superset of the functionality offered by SELECT INTO.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE TABLE AS can be used for fast data loading from external table data sources. See CREATE EXTERNAL TABLE.</pre>
</div></div><h3 id="SQLCommandReference-Examples.17">Examples</h3><p>Create a new table <em>films_recent </em><span style="font-size: medium;"> </span>consisting of only recent entries from the table <em>films</em><span style="font-size: medium;"> </span>:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE TABLE films_recent AS SELECT * FROM films WHERE date_prod &gt;= '2007-01-01';</pre>
</div></div><p align="LEFT">Create a new temporary table <em>films_recent</em><span style="font-size: medium;"> </span>, consisting of only recent entries from the table films, using a prepared statement. The new table has OIDs and will be dropped at commit:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">PREPARE recentfilms(date) AS SELECT * FROM films WHERE date_prod &gt; $1;
CREATE TEMP TABLE films_recent WITH (OIDS) ON COMMIT DROP AS
EXECUTE recentfilms('2007-01-01');</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.21">Compatibility</h3><p align="LEFT">CREATE TABLE AS conforms to the SQL standard, with the following exceptions:</p><ul><li>The standard requires parentheses around the subquery clause; in Greenplum Database, these parentheses are optional.</li><li>The standard defines a WITH [NO] DATA clause; this is not currently implemented by Greenplum Database. The behavior provided by Greenplum Database is equivalent to the standard’s WITH DATA case. WITH NO DATA can be simulated by appending LIMIT 0 to the query.</li><li>Greenplum Database handles temporary tables differently from the standard; see CREATE TABLE for details.</li><li>The WITH clause is a Greenplum Database extension; neither storage parameters nor OIDs are in the standard.</li><li>The Greenplum Database concept of tablespaces is not part of the standard. The TABLESPACE clause is an extension.</li></ul><h3 id="SQLCommandReference-SeeAlso.19"><span style="font-size: medium;"> </span>See Also</h3><p align="LEFT">CREATE EXTERNAL TABLE, EXECUTE, SELECT, SELECT INTO</p><h2 id="SQLCommandReference-CREATEUSER">CREATE USER</h2><p>Defines a new database role with the LOGIN privilege by default.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">CREATE USER 
name [ [WITH] option [ ... ] ]
 where option can be:
      SUPERUSER | NOSUPERUSER
    | CREATEDB | NOCREATEDB
    | CREATEROLE | NOCREATEROLE
    | CREATEUSER | NOCREATEUSER
    | INHERIT | NOINHERIT
    | LOGIN | NOLOGIN
    | [ ENCRYPTED | UNENCRYPTED ] PASSWORD 'password'
    | VALID UNTIL 'timestamp'
    | IN ROLE rolename [, ...]
    | IN GROUP rolename [, ...]
    | ROLE rolename [, ...]
    | ADMIN rolename [, ...]
    | USER rolename [, ...]
    | SYSID uid
    | RESOURCE QUEUE queue_name</pre>
</div></div><h3 id="SQLCommandReference-Description.22">Description</h3><p><span style="font-size: medium;"> </span>As of HAWQ release 2.2, CREATE USER has been replaced by CREATE ROLE, although it is still accepted for backwards compatibility.</p><p align="LEFT">The only difference between CREATE ROLE and CREATE USER is that LOGIN is assumed by default with CREATE USER, whereas NOLOGIN is assumed by default with CREATE ROLE.</p><h3 id="SQLCommandReference-Compatibility.22">Compatibility</h3><p align="LEFT">There is no CREATE USER statement in the SQL standard.</p><h3 id="SQLCommandReference-SeeAlso.20">See Also</h3><p align="LEFT">CREATE ROLE</p><h2 id="SQLCommandReference-CREATEVIEW">CREATE VIEW</h2><p>Defines a new view.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">CREATE [OR REPLACE] [TEMP | TEMPORARY] VIEW name
       [ ( column_name [, ...] ) ]
       AS query</pre>
</div></div><h3 id="SQLCommandReference-Description.23">Description</h3><p>CREATE VIEW defines a view of a query. The view is not physically materialized. Instead, the query is run every time the view is referenced in a query.</p><p align="LEFT">CREATE OR REPLACE VIEW is similar, but if a view of the same name already exists, it is replaced. You can only replace a view with a new query that generates the identical set of columns (same column names and data types).</p><p align="LEFT">If a schema name is given then the view is created in the specified schema. Otherwise it is created in the current schema. Temporary views exist in a special schema, so a schema name may not be given when creating a temporary view. The name of the view must be distinct from the name of any other view, table, or sequence in the same schema.</p><h3 id="SQLCommandReference-Parameters.19">Parameters</h3><pre>TEMPORARY | TEMP</pre><p align="LEFT" style="margin-left: 30.0px;">If specified, the view is created as a temporary view. Temporary views are automatically dropped at the end of the current session. Existing permanent relations with the same name are not visible to the current session while the temporary view exists, unless they are referenced with schema-qualified names. If any of the tables referenced by the view are temporary, the view is created as a temporary view (whether TEMPORARY is specified or not).</p><pre>name</pre><p align="LEFT" style="margin-left: 30.0px;">The name (optionally schema-qualified) of a view to be created.</p><pre>column_name</pre><p align="LEFT" style="margin-left: 30.0px;">An optional list of names to be used for columns of the view. If not given, the column names are deduced from the query.</p><pre>query</pre><p align="LEFT" style="margin-left: 30.0px;">A SELECT command which will provide the columns and rows of the view.</p><h3 id="SQLCommandReference-Notes.18">Notes</h3><p align="LEFT">Views in Greenplum Database are read only. The system will not allow an insert, update, or delete on a view. You can get the effect of an updatable view by creating rewrite rules on the view into appropriate actions on other tables. For more information see CREATE RULE.</p><p align="LEFT">Be careful that the names and data types of the view’s columns will be assigned the way you want. For example:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE VIEW vista AS SELECT 'Hello World';</pre>
</div></div><p align="LEFT">is bad form in two ways: the column name defaults to ?column?, and the column data type defaults to unknown. If you want a string literal in a view’s result, use something like:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE VIEW vista AS SELECT text 'Hello World' AS hello;</pre>
</div></div><p align="LEFT">Access to tables referenced in the view is determined by permissions of the view owner not the current user (even if the current user is a superuser). This can be confusing in the case of superusers, since superusers typically have access to all objects. In the case of a view, even superusers must be explicitly granted access to tables referenced in the view if they are not the owner of the view.</p><p align="LEFT">However, functions called in the view are treated the same as if they had been called directly from the query using the view. Therefore the user of a view must have permissions to call any functions used by the view.</p><p align="LEFT">If you create a view with an ORDER BY clause, the ORDER BY clause is ignored when you do a SELECT from the view.</p><h3 id="SQLCommandReference-Examples.18">Examples</h3><p align="LEFT">Create a view consisting of all comedy films:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE VIEW comedies AS SELECT * FROM films WHERE kind =
'comedy';</pre>
</div></div><p align="LEFT"><span style="font-size: medium;"><span style="font-size: medium;"> </span></span>Create a view that gets the top ten ranked baby names:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">CREATE VIEW topten AS SELECT name, rank, gender, year FROM
names, rank WHERE rank &lt; '11' AND names.id=rank.id;</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.23">Compatibility</h3><p align="LEFT">The SQL standard specifies some additional capabilities for the CREATE VIEW statement that are not in Greenplum Database. The optional clauses for the full SQL command in the standard are:</p><ul><li>CHECK OPTION — This option has to do with updatable views. All INSERT and UPDATE commands on the view will be checked to ensure data satisfy the view-defining condition (that is, the new data would be visible through the view). If they do not, the update will be rejected.</li><li>LOCAL — Check for integrity on this view.</li><li>CASCADED — Check for integrity on this view and on any dependent view. CASCADED is assumed if neither CASCADED nor LOCAL is specified.</li></ul><p align="LEFT">CREATE OR REPLACE VIEW is a Greenplum Database language extension. So is the concept of a temporary view.</p><h2 id="SQLCommandReference-DEALLOCATE">DEALLOCATE</h2><p>Deallocates a prepared statement.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">DEALLOCATE [PREPARE] name</pre>
</div></div><h3 id="SQLCommandReference-Description.24">Description</h3><p>DEALLOCATE is used to deallocate a previously prepared SQL statement. If you do not explicitly deallocate a prepared statement, it is deallocated when the session ends. For more information on prepared statements, see PREPARE.</p><h3 id="SQLCommandReference-Parameters.20">Parameters</h3><pre>PREPARE</pre><p style="margin-left: 30.0px;">Optional key word which is ignored.</p><pre>name</pre><p style="margin-left: 30.0px;">The name of the prepared statement to deallocate.</p><h3 id="SQLCommandReference-Examples.19">Examples</h3><p>Deallocated the previously prepared statement named<em>insert_names</em><span style="font-size: medium;"> </span>:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">DEALLOCATE insert_names;</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.24">Compatibility</h3><p>The SQL standard includes a DEALLOCATE statement, but it is only for use in embedded SQL.</p><h3 id="SQLCommandReference-SeeAlso.21">See Also</h3><p>EXECUTE, PREPARE</p><h2 id="SQLCommandReference-DECLARE">DECLARE</h2><p>Defines a cursor.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">DECLARE name [BINARY] [INSENSITIVE] [NO SCROLL] CURSOR
             [{WITH | WITHOUT} HOLD]
             FOR query [FOR READ ONLY]</pre>
</div></div><h3 id="SQLCommandReference-Description.25">Description</h3><p>DECLARE allows a user to create cursors, which can be used to retrieve a small number of rows at a time out of a larger query. Cursors can return data either in text or in binary format using FETCH.</p><p align="LEFT">Normal cursors return data in text format, the same as a SELECT would produce. Since data is stored natively in binary format, the system must do a conversion to produce the text format. Once the information comes back in text form, the client application may need to convert it to a binary format to manipulate it. In addition, data in the text format is often larger in size than in the binary format. Binary cursors return the data in a binary representation that may be more easily manipulated. Nevertheless, if you intend to display the data as text anyway, retrieving it in text form will save you some effort on the client side.</p><p align="LEFT">As an example, if a query returns a value of one from an integer column, you would get a string of 1 with a default cursor whereas with a binary cursor you would get a 4-byte field containing the internal representation of the value (in big-endian byte order).</p><p align="LEFT">Binary cursors should be used carefully. Many applications, including psql, are not prepared to handle binary cursors and expect data to come back in the text format.</p><p align="LEFT"><strong>Note</strong>: When the client application uses the ‘extended query’ protocol to issue a FETCH command, the Bind protocol message specifies whether data is to be retrieved in text or binary format. This choice overrides the way that the cursor is defined. The concept of a binary cursor as such is thus obsolete when using extended query protocol — any cursor can be treated as either text or binary.</p><h3 id="SQLCommandReference-Parameters.21">Parameters</h3><pre>name</pre><p style="margin-left: 30.0px;">The name of the cursor to be created.</p><pre>BINARY</pre><p style="margin-left: 30.0px;">Causes the cursor to return data in binary rather than in text format.</p><pre>INSENSITIVE</pre><p style="margin-left: 30.0px;">Indicates that data retrieved from the cursor should be unaffected by updates to the tables underlying the cursor while the cursor exists. In Greenplum Database, all cursors are insensitive. This key word currently has no effect and is present for compatibility with the SQL standard.</p><pre>NO SCROLL</pre><p style="margin-left: 30.0px;">A cursor cannot be used to retrieve rows in a nonsequential fashion. This is the default behavior in Greenplum Database, since scrollable cursors (SCROLL) are not supported.</p><pre>WITH HOLD<br/>WITHOUT HOLD</pre><p style="margin-left: 30.0px;">WITH HOLD specifies that the cursor may continue to be used after the transaction that created it successfully commits. WITHOUT HOLD specifies that the cursor cannot be used outside of the transaction that created it. WITHOUT HOLD is the default.</p><pre>query</pre><p style="margin-left: 30.0px;">A SELECT command which will provide the rows to be returned by the cursor.</p><pre>FOR READ ONLY</pre><p style="margin-left: 30.0px;">Cursors can only be used in a read-only mode in Greenplum Database. Greenplum Database does not support updatable cursors (FOR UPDATE), so this is the default behavior.</p><h3 id="SQLCommandReference-Notes.19">Notes</h3><p>Unless WITH HOLD is specified, the cursor created by this command can only be used within the current transaction. Thus, DECLARE without WITH HOLD is useless outside a transaction block: the cursor would survive only to the completion of the statement. Therefore Greenplum Database reports an error if this command is used outside atransaction block. Use BEGIN, COMMIT and ROLLBACK to define a transaction block.</p><p align="LEFT">If WITH HOLD is specified and the transaction that created the cursor successfully commits, the cursor can continue to be accessed by subsequent transactions in the same session. (But if the creating transaction is aborted, the cursor is removed.) A cursor created with WITH HOLD is closed when an explicit CLOSE command is issued on it, or the session ends. In the current implementation, the rows represented by a held cursor are copied into a temporary file or memory area so that they remain available for subsequent transactions.</p><p align="LEFT">Scrollable cursors are not currently supported in Greenplum Database. You can only use FETCH to move the cursor position forward, not backwards.</p><p>You can see all available cursors by querying the <em>pg_cursors </em><span style="font-size: medium;"> </span>system view.</p><h3 id="SQLCommandReference-Examples.20">Examples</h3><p>Declare a cursor:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">DECLARE mycursor CURSOR FOR SELECT * FROM mytable;</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.25">Compatibility</h3><p>SQL standard allows cursors only in embedded SQL and in modules. Greenplum Database permits cursors to be used interactively.</p><p>Greenplum Database does not implement an OPEN statement for cursors. A cursor is considered to be open when it is declared.</p><p>The SQL standard allows cursors to update table data. All Greenplum Database cursors are read only.</p><p>The SQL standard allows cursors to move both forward and backward. All Greenplum Database cursors are forward moving only (not scrollable).</p><p>Binary cursors are a Greenplum Database extension.</p><h3 id="SQLCommandReference-SeeAlso.22">See Also</h3><p>CLOSE, FETCH, SELECT</p><h2 id="SQLCommandReference-DROPDATABASE">DROP DATABASE</h2><p>Removes a database.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">DROP DATABASE [IF EXISTS] name</pre>
</div></div><h3 id="SQLCommandReference-Description.26">Description</h3><p>DROP DATABASE drops a database. It removes the catalog entries for the database and deletes the directory containing the data. It can only be executed by the database owner. Also, it cannot be executed while you or anyone else are connected to the target database. (Connect to <em>template1 </em><span style="font-size: medium;"> </span>or any other database to issue this command.)</p><p>DROP DATABASE cannot be undone. Use it with care!</p><h3 id="SQLCommandReference-Parameters.22">Parameters</h3><pre>IF EXISTS</pre><p style="margin-left: 30.0px;">Do not throw an error if the database does not exist. A notice is issued in this case.</p><pre>name</pre><p style="margin-left: 30.0px;">The name of the database to remove.</p><h3 id="SQLCommandReference-Notes.20">Notes</h3><p>DROP DATABASE cannot be executed inside a transaction block.</p><p>This command cannot be executed while connected to the target database. Thus, it might be more convenient to use the program dropdb instead, which is a wrapper around this command.</p><h3 id="SQLCommandReference-Examples.21">Examples</h3><p>Drop the database named <em>testdb:</em></p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">DROP DATABASE testdb;</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.26">Compatibility</h3><p>There is no DROP DATABASE statement in the SQL standard.</p><h3 id="SQLCommandReference-SeeAlso.23">See Also</h3><p>CREATE DATABASE</p><h2 id="SQLCommandReference-DROPEXTERNALTABLE">DROP EXTERNAL TABLE</h2><p><span style="font-size: medium;"><span style="color: rgb(112,255,0);font-size: small;"> </span></span>Removes an external table definition.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">DROP EXTERNAL [WEB] TABLE [IF EXISTS] name [CASCADE | RESTRICT]</pre>
</div></div><h3 id="SQLCommandReference-Description.27">Description</h3><p>DROP EXTERNAL TABLE drops an existing external table definition from the database system. The external data sources or files are not deleted. To execute this command you must be the owner of the external table.</p><h3 id="SQLCommandReference-Parameters.23">Parameters</h3><pre>WEB</pre><p style="margin-left: 30.0px;">Optional keyword for dropping external web tables.</p><pre>IF EXISTS</pre><p style="margin-left: 30.0px;">Do not throw an error if the external table does not exist. A notice is issued in this case.</p><pre>name</pre><p style="margin-left: 30.0px;">The name (optionally schema-qualified) of an existing external table.</p><pre>CASCADE</pre><p style="margin-left: 30.0px;">Automatically drop objects that depend on the external table (such as views).</p><pre>RESTRICT</pre><p style="margin-left: 30.0px;">Refuse to drop the external table if any objects depend on it. This is the default.</p><h3 id="SQLCommandReference-Examples.22">Examples</h3><p>Remove the external table named <em>staging </em><span style="font-size: medium;"> </span>if it exists:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">DROP EXTERNAL TABLE IF EXISTS staging;</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.27">Compatibility</h3><p>There is no DROP EXTERNAL TABLE statement in the SQL standard.</p><h3 id="SQLCommandReference-SeeAlso.24">See Also</h3><p>CREATE EXTERNAL TABLE</p><h2 id="SQLCommandReference-DROPFILESPACE">DROP FILESPACE</h2><p>Removes a filespace.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">DROP FILESPACE [IF EXISTS] filespacename</pre>
</div></div><h3 id="SQLCommandReference-Description.28">Description</h3><p>DROP FILESPACE removes a filespace definition and its system-generated data directories from the system.</p><p align="LEFT">A filespace can only be dropped by its owner or a superuser. The filespace must be empty of all tablespace objects before it can be dropped. It is possible that tablespaces in other databases may still be using a filespace even if no tablespaces in the current database are using the filespace.</p><h3 id="SQLCommandReference-Parameters.24">Parameters</h3><pre>IF EXISTS</pre><p style="margin-left: 30.0px;">Do not throw an error if the filespace does not exist. A notice is issued in this case.</p><pre>tablespacename</pre><p style="margin-left: 30.0px;">The name of the filespace to remove.</p><h3 id="SQLCommandReference-Examples.23">Examples</h3><p>Remove the tablespace <em>myfs</em><span style="font-size: medium;"> </span>:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">DROP FILESPACE myfs;</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.28">Compatibility</h3><p>There is no DROP FILESPACE statement in the SQL standard or in PostgreSQL.</p><h3 id="SQLCommandReference-SeeAlso.25">See Also</h3><p>gpfilespace , DROP TABLESPACE</p><h2 id="SQLCommandReference-DROPGROUP">DROP GROUP</h2><p>Removes a database role.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">DROP Group [IF EXISTS] name [,...]</pre>
</div></div><h3 id="SQLCommandReference-Description.29">Description</h3><p>DROP GROUP is an obsolete command, though still accepted for backwards compatibility. Groups (and users) have been superseded by the more general concept of roles. See DROP ROLE for more information.</p><h3 id="SQLCommandReference-Parameters.25">Parameters</h3><pre>IF EXISTS</pre><p style="margin-left: 30.0px;">Do not throw an error if the role does not exist. A notice is issued in this case.</p><pre>name</pre><p style="margin-left: 30.0px;">The name of an existing role.</p><h3 id="SQLCommandReference-Compatibility.29">Compatibility</h3><p>There is no DROP GROUP statement in the SQL standard.</p><h3 id="SQLCommandReference-SeeAlso.26">See Also</h3><p>DROP ROLE</p><h2 id="SQLCommandReference-DROPOWNED">DROP OWNED</h2><p>Removes database objects owned by a database role.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">DROP OWNED BY name [, ...] [CASCADE | RESTRICT]</pre>
</div></div><h3 id="SQLCommandReference-Description.30">Description</h3><p>DROP OWNED drops all the objects in the current database that are owned by one of the specified roles. Any privileges granted to the given roles on objects in the current database will also be revoked.</p><h3 id="SQLCommandReference-Parameters.26">Parameters</h3><pre>name</pre><p style="margin-left: 30.0px;">The name of a role whose objects will be dropped, and whose privileges will be revoked.</p><pre>CASCADE</pre><p style="margin-left: 30.0px;">Automatically drop objects that depend on the affected objects.</p><pre>RESTRICT</pre><p style="margin-left: 30.0px;">Refuse to drop the objects owned by a role if any other database objects depend on one of the affected objects. This is the default.</p><h3 id="SQLCommandReference-Notes.21">Notes</h3><p>DROP OWNED is often used to prepare for the removal of one or more roles. Because DROP OWNED only affects the objects in the current database, it is usually necessary to execute this command in each database that contains objects owned by a role that is to be removed.</p><p align="LEFT">Using the CASCADE option may make the command recurse to objects owned by other users.</p><p align="LEFT">The REASSIGN OWNED command is an alternative that reassigns the ownership of all the database objects owned by one or more roles.</p><h3 id="SQLCommandReference-Examples.24">Examples</h3><p>Remove any database objects owned by the role named <em>sally</em><span style="font-size: medium;"> </span>:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">DROP OWNED BY sally;</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.30">Compatibility</h3><p>The DROP OWNED statement is a HAWQ extension.</p><h3 id="SQLCommandReference-SeeAlso.27">See Also</h3><p>REASSIGN OWNED, DROP ROLE</p><h2 id="SQLCommandReference-DROPRESOURCEQUEUE">DROP RESOURCE QUEUE</h2><p>Removes a resource queue.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">DROP RESOURCE QUEUE queue_name</pre>
</div></div><h3 id="SQLCommandReference-Description.31">Description</h3><p>This command removes a workload management resource queue from HAWQ. To drop a resource queue, the queue cannot have any roles assigned to it, nor can it have any statements waiting in the queue. Only a superuser can drop a resource queue.</p><h3 id="SQLCommandReference-Parameters.27">Parameters</h3><pre>queue_name</pre><p style="margin-left: 30.0px;">The name of a resource queue to remove.</p><h3 id="SQLCommandReference-Notes.22">Notes</h3><p>Use ALTER ROLE to remove a user from a resource queue.</p><p align="LEFT">To see all the currently active queries for all resource queues, perform the following query of thepg_locks table joined with the pg_roles and pg_resqueue tables:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SELECT rolname, rsqname, locktype, objid, transaction, pid, mode, granted FROM pg_roles, pg_resqueue, pg_locks WHERE pg_roles.rolresqueue=pg_locks.objid AND pg_locks.objid=pg_resqueue.oid; </pre>
</div></div><p align="LEFT">To see the roles assigned to a resource queue, perform the following query of the pg_roles and pg_resqueue system catalog tables:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SELECT rolname, rsqname FROM pg_roles, pg_resqueue WHERE
pg_roles.rolresqueue=pg_resqueue.oid;</pre>
</div></div><h3 id="SQLCommandReference-Examples.25">Examples</h3><p align="LEFT">Remove a role from a resource queue (and move the role to the default resource queue, pg_default):</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">ALTER ROLE bob RESOURCE QUEUE NONE;</pre>
</div></div><p align="LEFT">Remove the resource queue named <em>adhoc</em><span style="font-size: medium;"> </span>:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">DROP RESOURCE QUEUE adhoc;</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.31">Compatibility</h3><p>The DROP RESOURCE QUEUE statement is a HAWQ extension.</p><h3 id="SQLCommandReference-SeeAlso.28">See Also</h3><p>CREATE RESOURCE QUEUE, ALTER ROLE</p><h2 id="SQLCommandReference-DROPROLE">DROP ROLE</h2><p>Removes a database role.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">DROP ROLE [IF EXISTS] name [, ...]</pre>
</div></div><h3 id="SQLCommandReference-Description.32">Description</h3><p>DROP ROLE removes the specified role(s). To drop a superuser role, you must be a superuser yourself. To drop non-superuser roles, you must have CREATEROLE privilege.</p><p align="LEFT">A role cannot be removed if it is still referenced in any database; an error will be raised if so. Before dropping the role, you must drop all the objects it owns (or reassign their ownership) and revoke any privileges the role has been granted. The REASSIGN OWNED and DROP OWNED commands can be useful for this purpose.</p><p align="LEFT">However, it is not necessary to remove role memberships involving the role; DROP ROLE automatically revokes any memberships of the target role in other roles, and of other roles in the target role. The other roles are not dropped nor otherwise affected.</p><h3 id="SQLCommandReference-Parameters.28">Parameters</h3><pre>IF EXISTS</pre><p style="margin-left: 30.0px;">Do not throw an error if the role does not exist. A notice is issued in this case.</p><pre>name</pre><p style="margin-left: 30.0px;">The name of the role to remove.</p><h3 id="SQLCommandReference-Examples.26">Examples</h3><p>Remove the roles named <em>sally </em><span style="font-size: medium;"> </span>and <em>bob</em><span style="font-size: medium;"> </span>:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">DROP ROLE sally, bob;</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.32">Compatibility</h3><p>The SQL standard defines DROP ROLE, but it allows only one role to be dropped at a time, and it specifies different privilege requirements than HAWQ uses.</p><h3 id="SQLCommandReference-SeeAlso.29">See Also</h3><p>REASSIGN OWNED, DROP OWNED, CREATE ROLE, ALTER ROLE, SET ROLE</p><h2 id="SQLCommandReference-DROPSCHEMA">DROP SCHEMA</h2><p>Removes a schema.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">DROP SCHEMA [IF EXISTS] name [, ...][CASCADE | RESTRICT]</pre>
</div></div><h3 id="SQLCommandReference-Description.33">Description</h3><p>DROP SCHEMA removes schemas from the database. A schema can only be dropped by its owner or a superuser. Note that the owner can drop the schema (and thereby all contained objects) even if he does not own some of the objects within the schema.</p><h3 id="SQLCommandReference-Parameters.29">Parameters</h3><pre>IF EXISTS</pre><p style="margin-left: 30.0px;">Do not throw an error if the schema does not exist. A notice is issued in this case.</p><pre>name</pre><p style="margin-left: 30.0px;">The name of the schema to remove.</p><pre>CASCADE</pre><p style="margin-left: 30.0px;">Automatically drops any objects contained in the schema (tables, functions, etc.).</p><pre>RESTRICT</pre><p style="margin-left: 30.0px;">Refuse to drop the schema if it contains any objects. This is the default.</p><h3 id="SQLCommandReference-Examples.27">Examples</h3><p>Remove the schema <em>mystuff </em><span style="font-size: medium;"> </span>from the database, along with everything it contains:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">DROP SCHEMA mystuff CASCADE;</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.33">Compatibility</h3><p>DROP SCHEMA is fully conforming with the SQL standard, except that the standard only allows one schema to be dropped per command. Also, the IF EXISTS option is a HAWQ extension.</p><h3 id="SQLCommandReference-SeeAlso.30">See Also</h3><p>CREATE SCHEMA</p><h2 id="SQLCommandReference-DROPSEQUENCE">DROP SEQUENCE</h2><p>Removes a sequence.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">DROP SEQUENCE [IF EXISTS] name [, ...][CASCADE | RESTRICT]</pre>
</div></div><h3 id="SQLCommandReference-Description.34">Description</h3><p>DROP SEQUENCE removes a sequence generator table. You must own the sequence to drop it (or be a superuser).</p><h3 id="SQLCommandReference-Parameters.30">Parameters</h3><pre>IF EXISTS</pre><p style="margin-left: 30.0px;">Do not throw an error if the sequence does not exist. A notice is issued in this case.</p><pre>name</pre><p style="margin-left: 30.0px;">The name (optionally schema-qualified) of the sequence to remove.</p><pre>CASCADE</pre><p style="margin-left: 30.0px;">Automatically drop objects that depend on the sequence.</p><pre>RESTRICT</pre><p style="margin-left: 30.0px;">Refuse to drop the sequence if any objects depend on it. This is the default.</p><h3 id="SQLCommandReference-Examples.28">Examples</h3><p>Remove the sequence <em>myserial</em><span style="font-size: medium;"> </span>:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">DROP SEQUENCE myserial;</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.34">Compatibility</h3><p>DROP SEQUENCE is fully conforming with the SQL standard, except that the standard only allows one sequence to be dropped per command. Also, the IF EXISTS option is a HAWQ extension.</p><h3 id="SQLCommandReference-SeeAlso.31">See Also</h3><p>CREATE SEQUENCE</p><h2 id="SQLCommandReference-DROPTABLE">DROP TABLE</h2><p>Removes a table.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">DROP TABLE [IF EXISTS] name [, ...]</pre>
</div></div><h3 id="SQLCommandReference-Description.35">Description</h3><p>DROP TABLE removes tables from the database. Only its owner may drop a table. To empty a table of rows without removing the table definition, use DELETE or TRUNCATE.</p><p align="LEFT">DROP TABLE always removes any rules and constraints that exist for the target table. However, to drop a table that is referenced by a view, CASCADE must be specified. CASCADE will remove a dependent view entirely.</p><h3 id="SQLCommandReference-Parameters.31">Parameters</h3><pre>IF EXISTS</pre><p style="margin-left: 30.0px;">Do not throw an error if the table does not exist. A notice is issued in this case.</p><pre>name</pre><p style="margin-left: 30.0px;">The name (optionally schema-qualified) of the table to remove.</p><pre>CASCADE</pre><p align="LEFT" style="margin-left: 30.0px;">Automatically drop objects that depend on the table (such as views).</p><pre>RESTRICT</pre><p style="margin-left: 30.0px;">Refuse to drop the table if any objects depend on it. This is the default.</p><h3 id="SQLCommandReference-Examples.29">Examples</h3><p>Remove the table <em>mytable</em>:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">DROP TABLE mytable;</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.35">Compatibility</h3><p align="LEFT">DROP TABLE is fully conforming with the SQL standard, except that the standard only allows one table to be dropped per command. Also, the IF EXISTS option is a HAWQ extension.</p><h3 id="SQLCommandReference-SeeAlso.32">See Also</h3><p>CREATE TABLE, ALTER TABLE, TRUNCATE</p><h2 id="SQLCommandReference-DROPTABLESPACE">DROP TABLESPACE</h2><p>Removes a tablespace.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">DROP TABLESPACE [IF EXISTS] name [, ...] tablespacename</pre>
</div></div><h3 id="SQLCommandReference-Description.36">Description</h3><p>DROP TABLESPACE removes a tablespace from the system.</p><p align="LEFT">A tablespace can only be dropped by its owner or a superuser. The tablespace must be empty of all database objects before it can be dropped. It is possible that objects in other databases may still reside in the tablespace even if no objects in the current database are using the tablespace.</p><h3 id="SQLCommandReference-Parameters.32">Parameters</h3><pre>IF EXISTS</pre><p style="margin-left: 30.0px;">Do not throw an error if the tablespace does not exist. A notice is issued in this case.</p><pre>tablespacename</pre><p align="LEFT" style="margin-left: 30.0px;">The name of the tablespace to remove.</p><h3 id="SQLCommandReference-Examples.30">Examples</h3><p>Remove the tablespace <em>mystuff</em><span style="font-size: medium;"> </span>:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">DROP TABLESPACE mystuff;</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.36">Compatibility</h3><p>DROP TABLESPACE is a HAWQ extension.</p><h2 id="SQLCommandReference-DROPUSER">DROP USER</h2><p>Removes a database role.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">DROP USER [IF EXISTS] name [, ...]</pre>
</div></div><h3 id="SQLCommandReference-Description.37">Description</h3><p>DROP USER is an obsolete command, though still accepted for backwards compatibility. Groups (and users) have been superseded by the more general concept of roles. See DROP ROLE for more information.</p><h3 id="SQLCommandReference-Parameters.33">Parameters</h3><pre>IF EXISTS</pre><p align="LEFT" style="margin-left: 30.0px;">Do not throw an error if the role does not exist. A notice is issued in this case.</p><pre>name</pre><p style="margin-left: 30.0px;">The name of an existing role.</p><h3 id="SQLCommandReference-Compatibility.37">Compatibility</h3><p>There is no DROP USER statement in the SQL standard. The SQL standard leaves the definition of users to the implementation.</p><p>See Also</p><p>DROP ROLE</p><h2 id="SQLCommandReference-DROPVIEW">DROP VIEW</h2><p>Removes a view.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">DROP VIEW [IF EXISTS] name [, ...][CASCADE | RESTRICT]</pre>
</div></div><h3 id="SQLCommandReference-Description.38">Description</h3><p>DROP VIEW.will remove an existing view. Only the owner of a view can remove it.</p><h3 id="SQLCommandReference-Parameters.34">Parameters</h3><pre>IF EXISTS</pre><p align="LEFT" style="margin-left: 30.0px;">Do not throw an error if the view does not exist. A notice is issued in this case.</p><pre>name</pre><p style="margin-left: 30.0px;">The name (optionally schema-qualified) of the view to remove.</p><pre>CASCADE</pre><p style="margin-left: 30.0px;">Automatically drop objects that depend on the view (such as other views).</p><pre>RESTRICT</pre><p style="margin-left: 30.0px;">Refuse to drop the view if any objects depend on it. This is the default.</p><h3 id="SQLCommandReference-Examples.31">Examples</h3><p>Remove the view t<em>opten</em><span style="font-size: medium;"> </span>;</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">DROP VIEW topten;</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.38">Compatibility</h3><p>DROP VIEW is fully conforming with the SQL standard, except that the standard only allows one view to be dropped per command. Also, the IF EXISTS option is a HAWQ extension.</p><h3 id="SQLCommandReference-SeeAlso.33">See Also</h3><p>CREATE VIEW</p><h2 id="SQLCommandReference-END">END</h2><p>Commits a current transaction. </p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">END [WORK | TRANSACTION]</pre>
</div></div><h3 id="SQLCommandReference-Description.39">Description</h3><p>END commits the current transaction. All changes made by the transaction become visible to others and are guaranteed to be durable if a crash occurs. This command is a HAWQ extension that is equivalent to COMMIT.</p><h3 id="SQLCommandReference-Parameters.35">Parameters</h3><pre>WORK<br/>TRANSACTION</pre><p style="margin-left: 30.0px;">Optional keywords. They have no effect.</p><h3 id="SQLCommandReference-Examples.32">Examples</h3><p align="LEFT">Commit the current transaction:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">END;</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.39">Compatibility</h3><p>END is a HAWQ extension that provides functionality equivalent to COMMIT, which is specified in the SQL standard.</p><h3 id="SQLCommandReference-SeeAlso.34">See Also</h3><p>BEGIN, ROLLBACK, COMMIT<span style="font-size: medium;"> </span></p><h2 id="SQLCommandReference-EXECUTE">EXECUTE</h2><p>Executes a prepared SQL statement.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">EXECUTE name [  (parameter [, ...]  )  ]</pre>
</div></div><h3 id="SQLCommandReference-Description.40">Description</h3><p align="LEFT">EXECUTE is used to execute a previously prepared statement. Since prepared statements only exist for the duration of a session, the prepared statement must have been created by a PREPARE statement executed earlier in the current session.</p><p align="LEFT">If the PREPARE statement that created the statement specified some parameters, a compatible set of parameters must be passed to the EXECUTE statement, or else an error is raised. Note that (unlike functions) prepared statements are not overloaded based on the type or number of their parameters; the name of a prepared statement must be unique within a database session.</p><p>For more information on the creation and usage of prepared statements, see PREPARE.</p><h3 id="SQLCommandReference-Parameters.36">Parameters</h3><pre>name</pre><p style="margin-left: 30.0px;">The name of the prepared statement to execute.</p><pre>parameter</pre><p style="margin-left: 30.0px;">The actual value of a parameter to the prepared statement. This must be an expression yielding a value that is compatible with the data type of this parameter, as was determined when the prepared statement was created.</p><h3 id="SQLCommandReference-Examples.33">Examples</h3><p>Create a prepared statement for an INSERT statement, and then execute it:<span style="font-size: medium;"> </span></p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">PREPARE fooplan (int, text, bool, numeric) AS INSERT INTO
foo VALUES($1, $2, $3, $4);
EXECUTE fooplan(1, 'Hunter Valley', 't', 200.00);</pre>
</div></div><p> </p><h3 id="SQLCommandReference-Compatibility.40">Compatibility</h3><p>The SQL standard includes an EXECUTE statement, but it is only for use in embedded SQL. This version of the EXECUTE statement also uses a somewhat different syntax.</p><h3 id="SQLCommandReference-SeeAlso.35">See Also</h3><p>DEALLOCATE, PREPARE<span style="font-size: medium;"><span style="font-size: medium;"><span style="font-size: medium;"> </span></span></span></p><h2 id="SQLCommandReference-EXPLAIN">EXPLAIN</h2><p><span style="color: rgb(112,255,0);font-size: small;"> </span>Shows the query plan of a statement.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">EXPLAIN [ANALYZE] [VERBOSE] statement</pre>
</div></div><h3 id="SQLCommandReference-Description.41">Description</h3><p>EXPLAIN displays the query plan that the HAWQ planner generates for the supplied statement. Query plans are a tree plan of nodes. Each node in the plan represents a single operation, such as table scan, join, aggregation or a sort.</p><p>Plans should be read from the bottom up as each node feeds rows into the node directly above it. The bottom nodes of a plan are usually sequential table scan operations. If the query requires joins, aggregations, or sorts (or other operations on the raw rows) then there will be additional nodes above the scan nodes to perform these operations. The topmost plan nodes are usually the HAWQ motion nodes (redistribute, explicit redistribute, broadcast, or gather motions). These are the operations responsible for moving rows between the segment instances during query processing.</p><p align="LEFT">The output of EXPLAIN has one line for each node in the plan tree, showing the basic node type plus the following cost estimates that the planner made for the execution of that plan node:</p><ul><li>cost<span style="font-size: medium;"> </span>- measured in units of disk page fetches; that is, 1.0 equals one sequential disk page read. The first estimate is the start-up cost (cost of getting to the first row) and the second is the total cost (cost of getting all rows). Note that the total cost assumes that all rows will be retrieved, which may not always be the case (if using LIMIT for example).</li><li>rows<span style="font-size: medium;"> </span>- the total number of rows output by this plan node. This is usually less than the actual number of rows processed or scanned by the plan node, reflecting the estimated selectivity of any WHERE clause conditions. Ideally the top-level nodes estimate will approximate the number of rows actually returned, updated, or deleted by the query.</li><li>width<span style="font-size: medium;"> </span>- total bytes of all the rows output by this plan node.</li></ul><p align="LEFT">It is important to note that the cost of an upper-level node includes the cost of all its child nodes. The topmost node of the plan has the estimated total execution cost for the plan. This is this number that the planner seeks to minimize. It is also important to realize that the cost only reflects things that the query planner cares about. In particular, the cost does not consider the time spent transmitting result rows to the client.</p><p align="LEFT">EXPLAIN ANALYZE causes the statement to be actually executed, not only planned. The EXPLAIN ANALYZE plan shows the actual results along with the planner’s estimates. This is useful for seeing whether the planner’s estimates are close to reality. In addition to the information shown in the EXPLAIN plan, EXPLAIN ANALYZE will show the following additional information:</p><ul><li>The total elapsed time (in milliseconds) that it took to run the query.</li><li>The number of <em>workers </em><span style="font-size: medium;"> </span>(segments) involved in a plan node operation. Only segments that return rows are counted.</li><li>The maximum number of rows returned by the segment that produced the most rows for an operation. If multiple segments produce an equal number of rows, the one with the longest <em>time to end </em><span style="font-size: medium;"> </span>is the one chosen.</li><li>The segment id number of the segment that produced the most rows for an operation.</li><li><p>For relevant operations, the <em>work_mem </em><span style="font-size: medium;"> </span>used by the operation. If work_mem was not sufficient to perform the operation in memory, the plan will show how much data was spilled to disk and how many passes over the data were required for the lowest performing segment. For example:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">Work_mem used: 64K bytes avg, 64K bytes max (seg0).
Work_mem wanted: 90K bytes avg, 90K bytes max (seg0) to abate workfile
I/O affecting 2 workers.
[seg0] pass 0: 488 groups made from 488 rows; 263 rows written to
workfile
[seg0] pass 1: 263 groups made from 263 rows</pre>
</div></div></li><li>The time (in milliseconds) it took to retrieve the first row from the segment that produced the most rows, and the total time taken to retrieve all rows from that segment. The <em>&lt;time&gt; to first row </em><span style="font-size: medium;"> </span>may be omitted if it is the same as the <em>&lt;time&gt; to </em>end.</li></ul><p align="LEFT"><strong>Important</strong>: Keep in mind that the statement is actually executed when EXPLAIN ANALYZE is used. Although EXPLAIN ANALYZE will discard any output that a SELECT would return, other side effects of the statement will happen as usual. If you wish to use EXPLAIN ANALYZE on a DML statement without letting the command affect your data, use this approach:</p><h3 id="SQLCommandReference-Parameters.37">Parameters</h3><pre>name</pre><p align="LEFT" style="margin-left: 30.0px;">The name of the prepared statement to execute.</p><pre>parameter</pre><p style="margin-left: 30.0px;">The actual value of a parameter to the prepared statement. This must be an expression yielding a value that is compatible with the data type of this parameter, as was determined when the prepared statement was created.</p><h3 id="SQLCommandReference-Notes.23">Notes</h3><p>In order to allow the query planner to make reasonably informed decisions when optimizing queries, the ANALYZE statement should be run to record statistics about the distribution of data within the table. If you have not done this (or if the statistical distribution of the data in the table has changed significantly since the last time ANALYZE was run), the estimated costs are unlikely to conform to the real properties of the query, and consequently an inferior query plan may be chosen.</p><h3 id="SQLCommandReference-Examples.34">Examples</h3><p align="LEFT">To illustrate how to read an EXPLAIN query plan, consider the following example for a very simple query:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">EXPLAIN SELECT * FROM names WHERE name = 'Joelle';
QUERY PLAN
------------------------------------------------------------
Gather Motion 2:1 (slice1) (cost=0.00..20.88 rows=1 width=13)
-&gt; Seq Scan on 'names' (cost=0.00..20.88 rows=1 width=13)
Filter: name::text ~~ 'Joelle'::text</pre>
</div></div><p align="LEFT">If we read the plan from the bottom up, the query planner starts by doing a sequential scan of the <em>names </em><span style="font-size: medium;"> </span>table. Notice that the WHERE clause is being applied as a <em>filter </em>condition. This means that the scan operation checks the condition for each row it scans, and outputs only the ones that pass the condition.</p><p align="LEFT">The results of the scan operation are passed up to a <em>gather motion </em><span style="font-size: medium;"> </span>operation. In HAWQ, a gather motion is when segments send rows up to the master. In this case we have 2 segment instances sending to 1 master instance (2:1). This operation is working on <em>slice1 </em><span style="font-size: medium;"> </span>of the parallel query execution plan. In HAWQ a query plan is divided into slices so that portions of the query plan can be worked on in parallel by the segments.</p><p align="LEFT">The estimated startup cost for this plan is 00.00 (no cost) and a total cost of 20.88 disk page fetches. The planner is estimating that this query will return one row.</p><h3 id="SQLCommandReference-Compatibility.41">Compatibility</h3><p>There is no EXPLAIN statement defined in the SQL standard.</p><h3 id="SQLCommandReference-SeeAlso.36">See Also</h3><p>ANALYZE</p><h2 id="SQLCommandReference-FETCH">FETCH</h2><p>Retrieves rows from a query using a cursor.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">FETCH [ forward_direction { FROM | IN } ] cursorname
where forward_direction can be empty or one of:
    NEXT
    FIRST
    LAST
    ABSOLUTE count
    RELATIVE count
    count
    ALL
    FORWARD
    FORWARD count
    FORWARD ALL</pre>
</div></div><h3 id="SQLCommandReference-Description.42">Description</h3><p>FETCH retrieves rows using a previously-created cursor.</p><p align="LEFT">A cursor has an associated position, which is used by FETCH. The cursor position can be before the first row of the query result, on any particular row of the result, or after the last row of the result. When created, a cursor is positioned before the first row. After fetching some rows, the cursor is positioned on the row most recently retrieved. If FETCH runs off the end of the available rows then the cursor is left positioned after the last row. FETCH ALL will always leave the cursor positioned after the last row.</p><p align="LEFT">The forms NEXT, FIRST, LAST, ABSOLUTE, RELATIVE fetch a single row after moving the cursor appropriately. If there is no such row, an empty result is returned, and the cursor is left positioned before the first row or after the last row as appropriate.</p><p align="LEFT">The forms using FORWARD retrieve the indicated number of rows moving in the forward direction, leaving the cursor positioned on the last-returned row (or after all rows, if the count exceeds the number of rows available). Note that it is not possible to  move a cursor position backwards in HAWQ, since scrollable cursors are not supported. You can only move a cursor forward in position using FETCH.</p><p align="LEFT">RELATIVE 0 and FORWARD 0 request fetching the current row without moving the cursor, that is, re-fetching the most recently fetched row. This will succeed unless the cursor is positioned before the first row or after the last row, in which case no row is returned.</p><h3 id="SQLCommandReference-Outputs.1">Outputs</h3><p>On successful completion, a FETCH command returns a command tag of the form:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">FETCH count</pre>
</div></div><p>The count is the number of rows fetched (possibly zero). Note that in psql, the command tag will not actually be displayed, since psql displays the fetched rows instead.</p><h3 id="SQLCommandReference-Parameters.38">Parameters</h3><pre>forward_direction</pre><p style="margin-left: 30.0px;">Defines the fetch direction and number of rows to fetch. Only forward fetches are allowed in HAWQ. It can be one of the following:</p><pre>NEXT</pre><p style="margin-left: 30.0px;">Fetch the next row. This is the default if direction is omitted.</p><pre>FIRST</pre><p style="margin-left: 30.0px;">Fetch the first row of the query (same as ABSOLUTE 1). Only allowed if it is the first FETCH operation using this cursor.</p><pre>LAST</pre><p style="margin-left: 30.0px;">Fetch the last row of the query (same as ABSOLUTE -1).</p><pre>ABSOLUTE count</pre><p style="margin-left: 30.0px;">Fetch the specified row of the query. Position after last row if count is out of range. Only allowed if the row specified by <em>count </em><span style="font-size: small;"> </span>moves the cursor position forward.</p><pre>RELATIVE count </pre><p align="LEFT" style="margin-left: 30.0px;">Fetch the specified row of the query <em>count </em><span style="font-size: small;"> </span>rows ahead of the current cursor position. RELATIVE 0 re-fetches the current row, if any. Only allowed if <em>count </em>moves the cursor position forward.</p><pre>count</pre><p style="margin-left: 30.0px;">Fetch the next <em>count </em><span style="font-size: small;"> </span>number of rows (same as FORWARD <em>count</em><span style="font-size: small;"> </span>).</p><pre>ALL</pre><p style="margin-left: 30.0px;">Fetch all remaining rows (same as FORWARD ALL).</p><pre>FORWARD</pre><p style="margin-left: 30.0px;">Fetch the next row (same as NEXT).</p><pre>FORWARD count</pre><p style="margin-left: 30.0px;">Fetch the next <em>count </em><span style="font-size: small;"> </span>number of rows. FORWARD 0 re-fetches the current row.</p><pre>FORWARD ALL</pre><p style="margin-left: 30.0px;">Fetch all remaining rows.</p><pre>cursorname</pre><p style="margin-left: 30.0px;">The name of an open cursor.</p><h3 id="SQLCommandReference-Notes.24">Notes</h3><p>HAWQ does not support scrollable cursors, so you can only use FETCH to move the cursor position forward.</p><p>ABSOLUTE fetches are not any faster than navigating to the desired row with a relative move: the underlying implementation must traverse all the intermediate rows anyway.</p><p>Updating data via a cursor is currently not supported by HAWQ.</p><p>DECLARE is used to define a cursor. Use MOVE to change cursor position without retrieving data.</p><h3 id="SQLCommandReference-Examples.35">Examples</h3><p>Start the transaction:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">BEGIN;</pre>
</div></div><p align="LEFT">Set up a cursor:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">DECLARE mycursor CURSOR FOR SELECT * FROM films;</pre>
</div></div><p>Fetch the first 5 rows in the cursor  <em>mycursor</em><span style="font-size: medium;"> </span>:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">FETCH FORWARD 5 FROM mycursor;
code | title | did | date_prod | kind | len
-------+-------------------------+-----+------------+----------+------
-
BL101 | The Third Man | 101 | 1949-12-23 | Drama | 01:44
BL102 | The African Queen | 101 | 1951-08-11 | Romantic | 01:43
JL201 | Une Femme est une Femme | 102 | 1961-03-12 | Romantic | 01:25
P_301 | Vertigo | 103 | 1958-11-14 | Action | 02:08
P_302 | Becket | 103 | 1964-02-03 | Drama | 02:28</pre>
</div></div><p>  Close the cursor and end the transaction:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">CLOSE mycursor;
COMMIT;</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.42">Compatibility</h3><p>SQL standard allows cursors only in embedded SQL and in modules. HAWQ permits cursors to be used interactively.</p><p align="LEFT">The variant of FETCH described here returns the data as if it were a SELECT result rather than placing it in host variables. Other than this point, FETCH is fully upward-compatible with the SQL standard.</p><p>The FETCH forms involving FORWARD, as well as the forms FETCH count and FETCH ALL, in which FORWARD is implicit, are HAWQ extensions. BACKWARD is not supported.</p><p align="LEFT">The SQL standard allows only FROM preceding the cursor name; the option to use IN is an extension.</p><h3 id="SQLCommandReference-SeeAlso.37">See Also</h3><p>DECLARE, CLOSE<em><span style="font-size: small;"> </span></em><span style="font-size: small;"> </span></p><h2 id="SQLCommandReference-GRANT">GRANT</h2><p><span style="color: rgb(112,255,0);font-size: small;"> </span>Defines access privileges.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">GRANT { {SELECT | INSERT | UPDATE | DELETE | REFERENCES | TRIGGER} [,...] | ALL [PRIVILEGES] }
    ON [TABLE] tablename [, ...]
    TO {rolename | PUBLIC} [, ...] [WITH GRANT OPTION]
GRANT { {USAGE | SELECT | UPDATE} [,...] | ALL [PRIVILEGES] }
    ON SEQUENCE sequencename [, ...]
    TO { rolename | PUBLIC } [, ...] [WITH GRANT OPTION]
GRANT { {CREATE | CONNECT | TEMPORARY | TEMP} [,...] | ALL [PRIVILEGES] }
    ON DATABASE dbname [, ...]
    TO {rolename | PUBLIC} [, ...] [WITH GRANT OPTION]
GRANT { EXECUTE | ALL [PRIVILEGES] }
    ON FUNCTION funcname ( [ [argmode] [argname] argtype [, ...] ] ) [, ...]
    TO {rolename | PUBLIC} [, ...] [WITH GRANT OPTION]
GRANT { USAGE | ALL [PRIVILEGES] }
    ON LANGUAGE langname [, ...]
    TO rolename | PUBLIC} [, ...] [WITH GRANT OPTION]
GRANT { {CREATE | USAGE} [,...] | ALL [PRIVILEGES] }
    ON SCHEMA schemaname [, ...]
    TO {rolename | PUBLIC} [, ...] [WITH GRANT OPTION]
GRANT { CREATE | ALL [PRIVILEGES] }
    ON TABLESPACE tablespacename [, ...]
    TO {rolename | PUBLIC} [, ...] [WITH GRANT OPTION]
GRANT parent_role [, ...]
    TO member_role [, ...] [WITH ADMIN OPTION]
GRANT { SELECT | INSERT | ALL [PRIVILEGES] }
    ON PROTOCOL protocolname
    TO username</pre>
</div></div><h3 id="SQLCommandReference-Description.43">Description</h3><p>The GRANT command has two basic variants: one that grants privileges on a database object (table, view, sequence, database, function, procedural language, schema, or tablespace), and one that grants membership in a role.</p><h4 id="SQLCommandReference-GRANTonDatabaseObjects">GRANT on Database Objects</h4><p>This variant of the GRANT command gives specific privileges on a database object to one or more roles. These privileges are added to those already granted, if any.</p><p align="LEFT">The key word PUBLIC indicates that the privileges are to be granted to all roles, including those that may be created later. PUBLIC may be thought of as an implicitly defined group-level role that always includes all roles. Any particular role will have the sum of privileges granted directly to it, privileges granted to any role it is presently a member of, and privileges granted to PUBLIC.</p><p align="LEFT">If WITH GRANT OPTION is specified, the recipient of the privilege may in turn grant it to others. Without a grant option, the recipient cannot do that. Grant options cannot be granted to PUBLIC.</p><p align="LEFT">There is no need to grant privileges to the owner of an object (usually the role that created it), as the owner has all privileges by default. The right to drop an object, or to alter its definition in any way is not described by a grantable privilege; it is inherent in the owner, and cannot be granted or revoked. The owner implicitly has all grant options for the object, too.</p><p align="LEFT">Depending on the type of object, the initial default privileges may include granting some privileges to PUBLIC. The default is no public access for tables, schemas, and tablespaces; CONNECT privilege and TEMP table creation privilege for databases; EXECUTE privilege for functions; and USAGE privilege for languages. The object owner may of course revoke these privileges.</p><h4 id="SQLCommandReference-GrantonRoles">Grant on Roles</h4><p>This variant of the GRANT command grants membership in a role to one or more other roles. Membership in a role is significant because it conveys the privileges granted to a role to each of its members.</p><p align="LEFT">If WITH ADMIN OPTION is specified, the member may in turn grant membership in the role to others, and revoke membership in the role as well. Database superusers can grant or revoke membership in any role to anyone. Roles having CREATEROLE privilege can grant or revoke membership in any role that is not a superuser.</p><p align="LEFT">Unlike the case with privileges, membership in a role cannot be granted to PUBLIC.</p><h4 id="SQLCommandReference-GrantonProtocols">Grant on Protocols</h4><p>After creating a custom protocol, specify CREATE TRUSTED PROTOCOL to be able to allowing any user besides the owner to access it. If the protocol is not trusted, you cannot give any other user permission to use it to read or write data. After a TRUSTED protocol is created, you can specify which other users can access it with the GRANT command.</p><p>To allow a user to create a readable external table with a trusted protocol</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">GRANT SELECT ON PROTOCOL protocolname  TO username</pre>
</div></div><p align="LEFT">To allow a user to create a writable external table with a trusted protocol</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">GRANT INSERT ON PROTOCOL protocolname  TO username</pre>
</div></div><p align="LEFT">To allow a user to create both readable and writable external table with a trusted protocol</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">GRANT ALL ON PROTOCOL protocolname  TO username</pre>
</div></div><h3 id="SQLCommandReference-Parameters.39">Parameters</h3><pre>SELECT</pre><p style="margin-left: 30.0px;">Allows SELECT from any column of the specified table, view, or sequence. Also allows the use of COPY TO. For sequences, this privilege also allows the use of the currval function.</p><pre>INSERT</pre><p style="margin-left: 30.0px;">Allows INSERT of a new row into the specified table. Also allows COPY FROM.</p><pre>UPDATE</pre><p style="margin-left: 30.0px;">Allows UPDATE of any column of the specified table. SELECT ... FOR UPDATE and SELECT ... FOR SHARE also require this privilege (as well as the SELECT privilege). For sequences, this privilege allows the use of the nextval and setval functions.</p><pre>DELETE</pre><p style="margin-left: 30.0px;">Allows DELETE of a row from the specified table.</p><pre>REFERENCES</pre><p style="margin-left: 30.0px;">This keyword is accepted, although foreign key constraints are currently not supported in HAWQ. To create a foreign key constraint, it is necessary to have this privilege on both the referencing and referenced tables.</p><pre>TRIGGER</pre><p style="margin-left: 30.0px;">Allows the creation of a trigger on the specified table.</p><pre>CREATE</pre><p style="margin-left: 30.0px;">For databases, allows new schemas to be created within the database.</p><p style="margin-left: 30.0px;">For schemas, allows new objects to be created within the schema. To rename an existing object, you must own the object and have this privilege for the containing schema.</p><p style="margin-left: 30.0px;">For tablespaces, allows tables to be created within the tablespace, and allows databases to be created that have the tablespace as their default tablespace. (Note that revoking this privilege will not alter the placement of existing objects.)</p><pre>CONNECT</pre><p style="margin-left: 30.0px;">Allows the user to connect to the specified database. This privilege is checked at connection startup (in addition to checking any restrictions imposed by pg_hba.conf).</p><pre>TEMPORARY<br/>TEMP</pre><p style="margin-left: 30.0px;">Allows temporary tables to be created while using the database.</p><pre>EXECUTE</pre><p style="margin-left: 30.0px;">Allows the use of the specified function and the use of any operators that are implemented on top of the function. This is the only type of privilege that is applicable to functions. (This syntax works for aggregate functions, as well.)</p><pre>USAGE</pre><p style="margin-left: 30.0px;">For procedural languages, allows the use of the specified language for the creation of functions in that language. This is the only type of privilege that is applicable to procedural languages.</p><p align="LEFT" style="margin-left: 30.0px;">For schemas, allows access to objects contained in the specified schema (assuming that the objects’ own privilege requirements are also met). Essentially this allows the grantee to look up objects within the schema.</p><p align="LEFT" style="margin-left: 30.0px;">For sequences, this privilege allows the use of the currval and nextval functions.</p><pre>ALL PRIVILEGES</pre><p align="LEFT" style="margin-left: 30.0px;">Grant all of the available privileges at once. The PRIVILEGES key word is optional in HAWQ, though it is required by strict SQL.</p><pre>PUBLIC</pre><p style="margin-left: 30.0px;">A special group-level role that denotes that the privileges are to be granted to all roles, including those that may be created later.</p><pre>WITH GRANT OPTION</pre><p style="margin-left: 30.0px;">The recipient of the privilege may in turn grant it to others.</p><pre>WITH ADMIN OPTION</pre><p style="margin-left: 30.0px;">The member of a role may in turn grant membership in the role to others.</p><h3 id="SQLCommandReference-Notes.25">Notes</h3><p>Database superusers can access all objects regardless of object privilege settings. One exception to this rule is view objects. Access to tables referenced in the view is determined by permissions of the view owner not the current user (even if the current user is a superuser).</p><p align="LEFT">If a superuser chooses to issue a GRANT or REVOKE command, the command is performed as though it were issued by the owner of the affected object. In particular, privileges granted via such a command will appear to have been granted by the object owner. For role membership, the membership appears to have been granted by the containing role itself.</p><p align="LEFT">GRANT and REVOKE can also be done by a role that is not the owner of the affected object, but is a member of the role that owns the object, or is a member of a role that holds privileges WITH GRANT OPTION on the object. In this case the privileges will be recorded as having been granted by the role that actually owns the object or holds the privileges WITH GRANT OPTION.</p><p>Granting permission on a table does not automatically extend permissions to any sequences used by the table, including sequences tied to SERIAL columns. Permissions on a sequence must be set separately. HAWQ does not support granting or revoking privileges for individual columns of a table. One possible workaround is to create a view having just the desired columns and then grant privileges to that view.</p><p align="LEFT">Use psql’s\z meta-command to obtain information about existing privileges for an object.</p><h3 id="SQLCommandReference-Examples.36">Examples</h3><p>Grant insert privilege to all roles on table <em>mytable</em><span style="font-size: medium;"> </span>:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">GRANT INSERT ON mytable TO PUBLIC;</pre>
</div></div><p align="LEFT">Grant all available privileges to role <em>sally </em><span style="font-size: medium;"> </span>on the view <em>topten</em><span style="font-size: medium;"> </span>. Note that while the above will indeed grant all privileges if executed by a superuser or the owner of topten, when executed by someone else it will only grant those permissions for which the granting role has grant options.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">GRANT ALL PRIVILEGES ON topten TO sally;</pre>
</div></div><p align="LEFT">Grant membership in role <em>admins </em><span style="font-size: medium;"> </span>to user <em>joe</em><span style="font-size: medium;"> </span>:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">GRANT admins TO joe;</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.43">Compatibility</h3><p>The PRIVILEGES key word in is required in the SQL standard, but optional in HAWQ. The SQL standard does not support setting the privileges on more than one object per command.</p><p align="LEFT">HAWQ allows an object owner to revoke his own ordinary privileges: for example, a table owner can make the table read-only to himself by revoking his own INSERT, UPDATE, and DELETE privileges. This is not possible according to the SQL standard. HAWQ treats the owner’s privileges as having been granted by the owner to himself; therefore he can revoke them too. In the SQL standard, the owner’s privileges are granted by an assumed <em>system </em><span style="font-size: medium;"> </span>entity.</p><p align="LEFT">The SQL standard allows setting privileges for individual columns within a table.</p><p align="LEFT">The SQL standard provides for a USAGE privilege on other kinds of objects: character sets, collations, translations, domains.</p><p>Privileges on databases, tablespaces, schemas, and languages are HAWQ extensions.</p><h3 id="SQLCommandReference-SeeAlso.38">See Also</h3><p>REVOKE</p><h2 id="SQLCommandReference-INSERT">INSERT</h2><p>Creates new rows in a table.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">INSERT INTO table [( column [, ...] )]
   {DEFAULT VALUES | VALUES ( {expression | DEFAULT} [, ...] ) [, ...] | query}</pre>
</div></div><h3 id="SQLCommandReference-Description.44">Description</h3><p>INSERT inserts new rows into a table. One can insert one or more rows specified by value expressions, or zero or more rows resulting from a query.</p><p align="LEFT">The target column names may be listed in any order. If no list of column names is given at all, the default is the columns of the table in their declared order. The values supplied by the VALUES clause or query are associated with the explicit or implicit column list left-to-right.</p><p align="LEFT">Each column not present in the explicit or implicit column list will be filled with a default value, either its declared default value or null if there is no default. If the expression for any column is not of the correct data type, automatic type conversion will be attempted.</p><p align="LEFT">You must have INSERT privilege on a table in order to insert into it.</p><p align="LEFT">Note. Greenplum supports 127 concurrent inserts currently.</p><h4 id="SQLCommandReference-Outputs.2">Outputs</h4><p>On successful completion, an INSERT command returns a command tag of the form:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">INSERT oid count</pre>
</div></div><p align="LEFT">The <em>count </em><span style="font-size: small;"> </span>is the number of rows inserted. If count is exactly one, and the target table has OIDs, then <em>oid </em><span style="font-size: small;"> </span>is the OID assigned to the inserted row. Otherwise <em>oid </em><span style="font-size: small;"> </span>is zero.</p><h3 id="SQLCommandReference-Parameters.40">Parameters</h3><pre>table</pre><p style="margin-left: 30.0px;">The name (optionally schema-qualified) of an existing table.</p><pre>column</pre><p style="margin-left: 30.0px;">The name of a column in table. The column name can be qualified with a subfield name or array subscript, if needed. (Inserting into only some fields of a composite column leaves the other fields null.)</p><pre>DEFAULT VALUES</pre><p style="margin-left: 30.0px;">All columns will be filled with their default values.</p><pre>expression</pre><p style="margin-left: 30.0px;">An expression or value to assign to the corresponding column.</p><pre>DEFAULT</pre><p style="margin-left: 30.0px;">The corresponding column will be filled with its default value.</p><pre>query</pre><p style="margin-left: 30.0px;">A query (SELECT statement) that supplies the rows to be inserted. Refer to the SELECT statement for a description of the syntax.</p><h3 id="SQLCommandReference-Examples.37">Examples</h3><p>Insert a single row into table <em>films</em><span style="font-size: medium;"> </span>:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">INSERT INTO films VALUES ('UA502', 'Bananas', 105,
'1971-07-13', 'Comedy', '82 minutes');</pre>
</div></div><p>In this example, the <em>length </em><span style="font-size: medium;"> </span>column is omitted and therefore it will have the default value:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">INSERT INTO films VALUES ('UA502', 'Bananas', 105,
'1971-07-13', 'Comedy', '82 minutes');</pre>
</div></div><p>This example uses the DEFAULT clause for the <em>date_prod </em><span style="font-size: medium;"> </span>column rather than specifying a value:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: actionscript3; gutter: false" style="font-size:12px;">INSERT INTO films VALUES ('UA502', 'Bananas', 105, DEFAULT,
'Comedy', '82 minutes');</pre>
</div></div><p>To insert a row consisting entirely of default values:<span> </span></p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">INSERT INTO films DEFAULT VALUES;</pre>
</div></div><p>To insert multiple rows using the multirow VALUES syntax:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">INSERT INTO films (code, title, did, date_prod, kind) VALUES
('B6717', 'Tampopo', 110, '1985-02-10', 'Comedy'),
('HG120', 'The Dinner Game', 140, DEFAULT, 'Comedy');</pre>
</div></div><p>This example inserts some rows into table <em>films </em><span style="font-size: medium;"> </span>from a table <em>tmp_films </em><span style="font-size: medium;"> </span>with the same column layout as <em>films</em><span style="font-size: medium;"> </span>:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">INSERT INTO films SELECT * FROM tmp_films WHERE date_prod &lt;
'2004-05-07';</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.44">Compatibility</h3><p>INSERT conforms to the SQL standard. The case in which a column name list is omitted, but not all the columns are filled from the VALUES clause or query, is disallowed by the standard.</p><p>Possible limitations of the <em>query </em><span style="font-size: small;"> </span>clause are documented under SELECT.</p><h3 id="SQLCommandReference-SeeAlso.39">See Also</h3><p>COPY, SELECT, CREATE EXTERNAL TABLE</p><h2 id="SQLCommandReference-PREPARE">PREPARE</h2><p>Prepare a statement for execution.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">PREPARE name [ (datatype [, ...] ) ] AS statement</pre>
</div></div><h3 id="SQLCommandReference-Description.45">Description</h3><p>PREPARE creates a prepared statement, possibly with unbound parameters. A prepared statement is a server-side object that can be used to optimize performance. A prepared statement may be subsequently executed with a binding for its parameters. HAWQ may choose to replan the query for different executions of the same prepared statement.</p><p align="LEFT">Prepared statements can take parameters: values that are substituted into the statement when it is executed. When creating the prepared statement, refer to parameters by position, using $1, $2, etc. A corresponding list of parameter data types can optionally be specified. When a parameter’s data type is not specified or is declared as unknown, the type is inferred from the context in which the parameter is used (if possible). When executing the statement, specify the actual values for these parameters in the EXECUTE statement.</p><p align="LEFT">Prepared statements only last for the duration of the current database session. When the session ends, the prepared statement is forgotten, so it must be recreated before being used again. This also means that a single prepared statement cannot be used by multiple simultaneous database clients; however, each client can create their own prepared statement to use. The prepared statement can be manually cleaned up using the DEALLOCATE command.</p><p align="LEFT">Prepared statements have the largest performance advantage when a single session is being used to execute a large number of similar statements. The performance difference will be particularly significant if the statements are complex to plan or rewrite, for example, if the query involves a join of many tables or requires the application of several rules. If the statement is relatively simple to plan and rewrite but relatively expensive to execute, the performance advantage of prepared statements will be less noticeable.</p><h3 id="SQLCommandReference-Parameters.41">Parameters</h3><pre>name</pre><p style="margin-left: 30.0px;">An arbitrary name given to this particular prepared statement. It must be unique within a single session and is subsequently used to execute or deallocate a previously prepared statement.</p><pre>datatype</pre><p align="LEFT" style="margin-left: 30.0px;">The data type of a parameter to the prepared statement. If the data type of a particular parameter is unspecified or is specified as unknown, it will be inferred from the context in which the parameter is used. To refer to the parameters in the prepared statement itself, use $1, $2, etc.</p><pre>statement</pre><p style="margin-left: 30.0px;">Any SELECT, INSERT, UPDATE, DELETE, or VALUES statement.</p><h3 id="SQLCommandReference-Notes.26">Notes</h3><p>In some situations, the query plan produced for a prepared statement will be inferior to the query plan that would have been chosen if the statement had been submitted and executed normally. This is because when the statement is planned and the planner attempts to determine the optimal query plan, the actual values of any parameters specified in the statement are unavailable. HAWQ collects statistics on the distribution of data in the table, and can use constant values in a statement to make guesses about the likely result of executing the statement. Since this data is unavailable when planning prepared statements with parameters, the chosen plan may be suboptimal. To examine the query plan HAWQ has chosen for a prepared statement, use EXPLAIN.</p><p>For more information on query planning and the statistics collected by HAWQ for that purpose, see the ANALYZE documentation.</p><p>You can see all available prepared statements of a session by querying the pg_prepared_statements system view.</p><h3 id="SQLCommandReference-Examples.38">Examples</h3><p>Create a prepared statement for an INSERT statement, and then execute it:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">PREPARE fooplan (int, text, bool, numeric) AS INSERT INTO foo VALUES($1, $2, $3, $4);
EXECUTE fooplan(1, 'Hunter Valley', 't', 200.00);</pre>
</div></div><p>Create a prepared statement for a SELECT statement, and then execute it. Note that the data type of the second parameter is not specified, so it is inferred from the context in which $2 is used:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">PREPARE usrrptplan (int) AS SELECT * FROM users u, logs l
WHERE u.usrid=$1 AND u.usrid=l.usrid AND l.date = $2;
EXECUTE usrrptplan(1, current_date);</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.45">Compatibility</h3><p align="LEFT">The SQL standard includes a PREPARE statement, but it is only for use in embedded SQL. This version of the PREPARE statement also uses a somewhat different syntax.</p><h3 id="SQLCommandReference-SeeAlso.40">See Also</h3><p>EXECUTE, DEALLOCATE</p><h2 id="SQLCommandReference-REASSIGNOWNED">REASSIGN OWNED</h2><p>Changes the ownership of database objects owned by a database role.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">REASSIGN OWNED BY old_role [, ...] TO new_role</pre>
</div></div><h3 id="SQLCommandReference-Description.46">Description</h3><p>REASSIGN OWNED reassigns all the objects in the current database that are owned by old_row to <em>new_role</em><span style="font-size: small;"> </span>. Note that it does not change the ownership of the database itself.</p><h3 id="SQLCommandReference-Parameters.42">Parameters</h3><pre>old_role</pre><p align="LEFT" style="margin-left: 30.0px;">The name of a role. The ownership of all the objects in the current database owned by this role will be reassigned to <em>new_role</em><span style="font-size: small;"> </span>.</p><pre>new_role</pre><p style="margin-left: 30.0px;">The name of the role that will be made the new owner of the affected objects.</p><h3 id="SQLCommandReference-Notes.27">Notes</h3><p>REASSIGN OWNED is often used to prepare for the removal of one or more roles. Because REASSIGN OWNED only affects the objects in the current database, it is usually necessary to execute this command in each database that contains objects owned by a role that is to be removed.</p><p align="LEFT">The DROP OWNED command is an alternative that drops all the database objects owned by one or more roles.</p><p align="LEFT">The REASSIGN OWNED command does not affect the privileges granted to the old roles in objects that are not owned by them. Use DROP OWNED to revoke those privileges.</p><h3 id="SQLCommandReference-Examples.39">Examples</h3><p>Reassign any database objects owned by the role named <em>sally </em><span style="font-size: medium;"> </span>and <em>bob </em>to <em>admin</em>;</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">REASSIGN OWNED BY sally, bob TO admin;</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.46">Compatibility</h3><p>The REASSIGN OWNED statement is a HAWQ extension.</p><h3 id="SQLCommandReference-SeeAlso.41">See Also</h3><p>DROP OWNED, DROP ROLE</p><h2 id="SQLCommandReference-RELEASESAVEPOINT">RELEASE SAVEPOINT</h2><p>Destroys a previously defined savepoint.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">RELEASE [SAVEPOINT] savepoint_name</pre>
</div></div><h3 id="SQLCommandReference-Description.47">Description</h3><p align="LEFT">RELEASE SAVEPOINT destroys a savepoint previously defined in the current transaction.</p><p align="LEFT">Destroying a savepoint makes it unavailable as a rollback point, but it has no other user visible behavior. It does not undo the effects of commands executed after the savepoint was established. (To do that, see ROLLBACK TO SAVEPOINT.) Destroying a savepoint when it is no longer needed may allow the system to reclaim some resources earlier than transaction end.</p><p align="LEFT">RELEASE SAVEPOINT also destroys all savepoints that were established <em>after </em><span style="font-size: medium;"> </span>the named savepoint was established.</p><h3 id="SQLCommandReference-Parameters.43">Parameters</h3><pre>savepoint_name</pre><p align="LEFT" style="margin-left: 30.0px;">The name of the savepoint to destroy.</p><h3 id="SQLCommandReference-Examples.40">Examples</h3><p>To establish and later destroy a savepoint:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">BEGIN;
INSERT INTO table1 VALUES (3);
SAVEPOINT my_savepoint;
INSERT INTO table1 VALUES (4);
RELEASE SAVEPOINT my_savepoint;
COMMIT;</pre>
</div></div><p>The above transaction will insert both 3 and 4.</p><h3 id="SQLCommandReference-Compatibility.47">Compatibility</h3><p>This command conforms to the SQL standard. The standard specifies that the key word SAVEPOINT is mandatory, but HAWQ allows it to be omitted.</p><h3 id="SQLCommandReference-SeeAlso.42">See Also</h3><p>BEGIN, SAVEPOINT, ROLLBACK TO SAVEPOINT, COMMIT</p><h2 id="SQLCommandReference-RESET">RESET</h2><p>Restores the value of a system configuration parameter to the default value.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">RESET configuration_parameter
RESET ALL</pre>
</div></div><h3 id="SQLCommandReference-Description.48">Description</h3><p>RESET restores system configuration parameters to their default values. RESET is an alternative spelling for SET <em>configuration_parameter </em><span style="font-size: small;"> </span>TO DEFAULT.</p><p align="LEFT">The default value is defined as the value that the parameter would have had, had no SET ever been issued for it in the current session. The actual source of this value might be a compiled-in default, the master postgresql.conf configuration file, command-line options, or per-database or per-user default settings. See “Server Configuration Parameters” on page 368.</p><h3 id="SQLCommandReference-Parameters.44">Parameters</h3><pre>configuration_parameter</pre><p align="LEFT" style="margin-left: 30.0px;">The name of a system configuration parameter. See “Server Configuration Parameters” on page 368 for details.</p><pre>ALL</pre><p style="margin-left: 30.0px;">Resets all settable configuration parameters to their default values.</p><h3 id="SQLCommandReference-Examples.41">Examples</h3><p>Set the <em>work_mem </em><span style="font-size: medium;"> </span>configuration parameter to its default value:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">RESET work_mem;</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.48">Compatibility</h3><p align="LEFT">RESET is a HAWQ extension.</p><h3 id="SQLCommandReference-SeeAlso.43">See Also</h3><p>SET</p><h2 id="SQLCommandReference-REVOKE">REVOKE</h2><p>Removes access privileges.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">REVOKE [GRANT OPTION FOR] { {SELECT | INSERT | UPDATE | DELETE
       | REFERENCES | TRIGGER} [,...] | ALL [PRIVILEGES] }
       ON [TABLE] tablename [, ...]
       FROM {rolename | PUBLIC} [, ...]
       [CASCADE | RESTRICT]
REVOKE [GRANT OPTION FOR] { {USAGE | SELECT | UPDATE} [,...]
       | ALL [PRIVILEGES] }
       ON SEQUENCE sequencename [, ...]
       FROM { rolename | PUBLIC } [, ...]
       [CASCADE | RESTRICT]
REVOKE [GRANT OPTION FOR] { {CREATE | CONNECT
       | TEMPORARY | TEMP} [,...] | ALL [PRIVILEGES] }
       ON DATABASE dbname [, ...]
       FROM {rolename | PUBLIC} [, ...]
       [CASCADE | RESTRICT]
REVOKE [GRANT OPTION FOR] {EXECUTE | ALL [PRIVILEGES]}
       ON FUNCTION funcname ( [[argmode] [argname] argtype
                               [, ...]] ) [, ...]
       FROM {rolename | PUBLIC} [, ...]
       [CASCADE | RESTRICT]
REVOKE [GRANT OPTION FOR] {USAGE | ALL [PRIVILEGES]}
       ON LANGUAGE langname [, ...]
       FROM {rolename | PUBLIC} [, ...]
       [ CASCADE | RESTRICT ]
REVOKE [GRANT OPTION FOR] { {CREATE | USAGE} [,...]
       | ALL [PRIVILEGES] }
       ON SCHEMA schemaname [, ...]
       FROM {rolename | PUBLIC} [, ...]
       [CASCADE | RESTRICT]
REVOKE [GRANT OPTION FOR] { CREATE | ALL [PRIVILEGES] }
       ON TABLESPACE tablespacename [, ...]
       FROM { rolename | PUBLIC } [, ...]
       [CASCADE | RESTRICT]
REVOKE [ADMIN OPTION FOR] parent_role [, ...]
       FROM member_role [, ...]
       [CASCADE | RESTRICT]</pre>
</div></div><h3 id="SQLCommandReference-Description.49">Description</h3><p>REVOKE command revokes previously granted privileges from one or more roles. The key word PUBLIC refers to the implicitly defined group of all roles.</p><p align="LEFT">See the description of the GRANT command for the meaning of the privilege types.</p><p align="LEFT">Note that any particular role will have the sum of privileges granted directly to it, privileges granted to any role it is presently a member of, and privileges granted to PUBLIC. Thus, for example, revoking SELECT privilege from PUBLIC does not necessarily mean that all roles have lost SELECT privilege on the object: those who have it granted directly or via another role will still have it.</p><p align="LEFT">If GRANT OPTION FOR is specified, only the grant option for the privilege is revoked, not the privilege itself. Otherwise, both the privilege and the grant option are revoked.</p><p align="LEFT">If a role holds a privilege with grant option and has granted it to other roles then the privileges held by those other roles are called dependent privileges. If the privilege or the grant option held by the first role is being revoked and dependent privileges exist, those dependent privileges are also revoked if CASCADE is specified, else the revoke action will fail. This recursive revocation only affects privileges that were granted through a chain of roles that is traceable to the role that is the subject of this REVOKE command. Thus, the affected roles may effectively keep the privilege if it was also granted through other roles.</p><p align="LEFT">When revoking membership in a role, GRANT OPTION is instead called ADMIN OPTION, but the behavior is similar.</p><h3 id="SQLCommandReference-Parameters.45">Parameters</h3><p>See GRANT.</p><h3 id="SQLCommandReference-Examples.42">Examples</h3><p>Revoke insert privilege for the public on table <em>films</em>:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">REVOKE INSERT ON films FROM PUBLIC;</pre>
</div></div><p>Revoke all privileges from role <em>sally </em><span style="font-size: medium;"> </span>on view <em>topten</em>. Note that this actually means revoke all privileges that the current role granted (if not a superuser).</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">REVOKE ALL PRIVILEGES ON topten FROM sally;</pre>
</div></div><p> Revoke membership in role <em>admins </em><span style="font-size: medium;"> </span>from user <em>joe</em><span style="font-size: medium;"> </span>:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">REVOKE admins FROM joe;</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.49">Compatibility</h3><p>The compatibility notes of the GRANT command also apply to REVOKE.</p><p align="LEFT">One of RESTRICT or CASCADE is required according to the standard, but HAWQ assumes RESTRICT by default.</p><p>See Also</p><p>GRANT</p><h2 id="SQLCommandReference-ROLLBACK">ROLLBACK</h2><p>Aborts the current transaction.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">ROLLBACK [WORK | TRANSACTION]</pre>
</div></div><h3 id="SQLCommandReference-Description.50">Description</h3><p>ROLLBACK rolls back the current transaction and causes all the updates made by the transaction to be discarded</p><h3 id="SQLCommandReference-Parameters.46">Parameters</h3><pre>WORK<br/>TRANSACTION</pre><p>Optional key words. They have no effect.</p><h3 id="SQLCommandReference-Notes.28">Notes</h3><p>Use COMMIT to successfully end the current transaction.</p><p align="LEFT">Issuing ROLLBACK when not inside a transaction does no harm, but it will provoke a warning message.</p><h3 id="SQLCommandReference-Examples.43">Examples</h3><p>To discard all changes made in the current transaction:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">ROLLBACK;</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.50">Compatibility</h3><p>The SQL standard only specifies the two forms ROLLBACK and ROLLBACK WORK. Otherwise, this command is fully conforming.</p><h3 id="SQLCommandReference-SeeAlso.44">See Also</h3><p>BEGIN, COMMIT, SAVEPOINT, ROLLBACK TO SAVEPOINT<span style="color: rgb(19,73,255);font-size: small;"> </span></p><h2 id="SQLCommandReference-ROLLBACKTOSAVEPOINT">ROLLBACK TO SAVEPOINT</h2><p>Rolls back the current transaction to a savepoint.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">ROLLBACK [WORK | TRANSACTION] TO [SAVEPOINT] savepoint_name</pre>
</div></div><h3 id="SQLCommandReference-Description.51">Description</h3><p>This command will roll back all commands that were executed after the savepoint was established. The savepoint remains valid and can be rolled back to again later, if needed.</p><p align="LEFT">ROLLBACK TO SAVEPOINT implicitly destroys all savepoints that were established after the named savepoint.</p><h3 id="SQLCommandReference-Parameters.47">Parameters</h3><pre>WORK<br/>TRANSACTION</pre><p>Optional key words. They have no effect.</p><pre>savepoint_name</pre><p>The name of a savepoint to roll back to.</p><h3 id="SQLCommandReference-Notes.29">Notes</h3><p>Use RELEASE SAVEPOINT to destroy a savepoint without discarding the effects of commands executed after it was established. Specifying a savepoint name that has not been established is an error.</p><p align="LEFT">Cursors have somewhat non-transactional behavior with respect to savepoints. Any cursor that is opened inside a savepoint will be closed when the savepoint is rolled back. If a previously opened cursor is affected by a FETCH command inside a savepoint that is later rolled back, the cursor position remains at the position that FETCH left it pointing to (that is, FETCH is not rolled back). Closing a cursor is not undone by rolling back, either. A cursor whose execution causes a transaction to abort is put in a can’t-execute state, so while the transaction can be restored using ROLLBACK TO SAVEPOINT, the cursor can no longer be used.</p><h3 id="SQLCommandReference-Examples.44">Examples</h3><p align="LEFT">To undo the effects of the commands executed after <em>my_savepoint </em><span style="font-size: medium;"> </span>was established:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">ROLLBACK TO SAVEPOINT my_savepoint;</pre>
</div></div><p>Cursor positions are not affected by a savepoint rollback:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">BEGIN;

DECLARE foo CURSOR FOR SELECT 1 UNION SELECT 2;
SAVEPOINT foo;
FETCH 1 FROM foo;
column
----------
1
ROLLBACK TO SAVEPOINT foo;
FETCH 1 FROM foo;
column
----------
2
COMMIT;
Compatibility</pre>
</div></div><p>The SQL standard specifies that the key word SAVEPOINT is mandatory, but HAWQ (and Oracle) allow it to be omitted. SQL allows only WORK, not TRANSACTION, as a noise word after ROLLBACK. Also, SQL has an optional clause AND [NO] CHAIN which is not currently supported by HAWQ. Otherwise, this command conforms to the SQL standard.</p><h3 id="SQLCommandReference-SeeAlso.45">See Also</h3><p>BEGIN, COMMIT, SAVEPOINT, RELEASE SAVEPOINT, ROLLBACK</p><h2 id="SQLCommandReference-SAVEPOINT">SAVEPOINT</h2><p>Defines a new savepoint within the current transaction.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SAVEPOINT savepoint_name</pre>
</div></div><h3 id="SQLCommandReference-Description.52">Description</h3><p>SAVEPOINT establishes a new savepoint within the current transaction.</p><p align="LEFT">A savepoint is a special mark inside a transaction that allows all commands that are executed after it was established to be rolled back, restoring the transaction state to what it was at the time of the savepoint.</p><h3 id="SQLCommandReference-Parameters.48">Parameters</h3><pre>savepoint_name</pre><p align="LEFT" style="margin-left: 30.0px;">The name of the new savepoint.</p><h3 id="SQLCommandReference-Notes.30">Notes</h3><p>Use ROLLBACK TO SAVEPOINT to rollback to a savepoint. Use RELEASE SAVEPOINT to destroy a savepoint, keeping the effects of commands executed after it was established.</p><p align="LEFT">Savepoints can only be established when inside a transaction block. There can be multiple savepoints defined within a transaction.</p><h3 id="SQLCommandReference-Examples.45">Examples</h3><p>To establish a savepoint and later undo the effects of all commands executed after it was established:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">BEGIN;
INSERT INTO table1 VALUES (1);
SAVEPOINT my_savepoint;
INSERT INTO table1 VALUES (2);
ROLLBACK TO SAVEPOINT my_savepoint;
INSERT INTO table1 VALUES (3);
COMMIT;</pre>
</div></div><p align="LEFT">The above transaction will insert the values 1 and 3, but not 2.</p><p>To establish and later destroy a savepoint:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">BEGIN;
INSERT INTO table1 VALUES (3);
SAVEPOINT my_savepoint;
INSERT INTO table1 VALUES (4);
RELEASE SAVEPOINT my_savepoint;
COMMIT;</pre>
</div></div><p>The above transaction will insert both 3 and 4.</p><h3 id="SQLCommandReference-Compatibility.51">Compatibility</h3><p>SQL requires a savepoint to be destroyed automatically when another savepoint with the same name is established. In HAWQ, the old savepoint is kept, though only the more recent one will be used when rolling back or releasing. (Releasing the newer savepoint will cause the older one to again become accessible to ROLLBACK TO SAVEPOINT and RELEASE SAVEPOINT.) Otherwise, SAVEPOINT is fully SQL conforming</p><h3 id="SQLCommandReference-SeeAlso.46">See Also</h3><p>BEGIN, COMMIT, ROLLBACK, RELEASE SAVEPOINT, ROLLBACK TO SAVEPOINT</p><h2 id="SQLCommandReference-SELECT">SELECT</h2><p>Retrieves rows from a table or view.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SELECT [ALL | DISTINCT [ON (expression [, ...])]]
  * | expression [[AS] output_name] [, ...]
  [FROM from_item [, ...]]
  [WHERE condition]
  [GROUP BY grouping_element [, ...]]
  [HAVING condition [, ...]]
  [WINDOW window_name AS (window_specification)]
  [{UNION | INTERSECT | EXCEPT} [ALL] select]
  [ORDER BY expression [ASC | DESC | USING operator] [, ...]]
  [LIMIT {count | ALL}]
  [OFFSET start]
 where grouping_element can be one of:
  ()
   expression
   ROLLUP (expression [,...])
  CUBE (expression [,...])
  GROUPING SETS ((grouping_element [, ...]))
 where window_specification can be:
  [window_name]
  [PARTITION BY expression [, ...]]
  [ORDER BY expression [ASC | DESC | USING operator] [, ...]
     [{RANGE | ROWS}
          { UNBOUNDED PRECEDING
          | expression PRECEDING
          | CURRENT ROW
          | BETWEEN window_frame_bound AND window_frame_bound }]]
    where window_frame_bound can be one of:
      UNBOUNDED PRECEDING
      expression PRECEDING
      CURRENT ROW
      expression FOLLOWING
      UNBOUNDED FOLLOWING
where from_item can be one of:
[ONLY] table_name [[AS] alias [( column_alias [, ...] )]]
(select) [AS] alias [( column_alias [, ...] )]
function_name( [argument [, ...]] ) [AS] alias
              [( column_alias [, ...]
                | column_definition [, ...] )]
function_name( [argument [, ...]] ) AS
              ( column_definition [, ...] )
from_item [NATURAL] join_type from_item
           [ON join_condition | USING ( join_column [, ...] )]</pre>
</div></div><h3 id="SQLCommandReference-Description.53">Description</h3><p>SELECT retrieves rows from zero or more tables. The general processing of SELECT is as follows:</p><ol><li>All elements in the FROM list are computed. (Each element in the FROM list is a real or virtual table.) If more than one element is specified in the FROM list, they are cross-joined together.</li><li>If the WHERE clause is specified, all rows that do not satisfy the condition are eliminated from the output.</li><li>If the GROUP BY clause is specified, the output is divided into groups of rows that match on one or more of the defined grouping elements. If the HAVING clause is present, it eliminates groups that do not satisfy the given condition.</li><li>If a window expression is specified (and optional WINDOW clause), the output is organized according to the positional (row) or value-based (range) window frame.</li><li>DISTINCT eliminates duplicate rows from the result. DISTINCT ON eliminates rows that match on all the specified expressions. ALL (the default) will return all candidate rows, including duplicates.</li><li>The actual output rows are computed using the SELECT output expressions for each selected row.</li><li>Using the operators UNION, INTERSECT, and EXCEPT, the output of more than one SELECT statement can be combined to form a single result set. The UNION operator returns all rows that are in one or both of the result sets. The INTERSECT operator returns all rows that are strictly in both result sets. The EXCEPT operator returns the rows that are in the first result set but not in the second. In all three cases, duplicate rows are eliminated unless ALL is specified.</li><li>If the ORDER BY clause is specified, the returned rows are sorted in the specified order. If ORDER BY is not given, the rows are returned in whatever order the system finds fastest to produce.</li><li>If the LIMIT or OFFSET clause is specified, the SELECT statement only returns a subset of the result rows.</li></ol><p>You must have SELECT privilege on a table to read its values.</p><h3 id="SQLCommandReference-Parameters.49">Parameters</h3><h5 id="SQLCommandReference-TheSELECTList">The SELECT List</h5><p>The SELECT list (between the key words SELECT and FROM) specifies expressions that form the output rows of the SELECT statement. The expressions can (and usually do) refer to columns computed in the FROM clause.</p><p align="LEFT">Using the clause [AS] <em>output_name</em><span style="font-size: small;"> </span>, another name can be specified for an output<span style="font-size: medium;"><span style="font-size: medium;"> </span></span>column. This name is primarily used to label the column for display. It can also be used to refer to the column’s value in ORDER BY and GROUP BY clauses, but not in the WHERE or HAVING clauses; there you must write out the expression instead. The AS keyword is optional in most cases (such as when declaring an alias for column names, constants, function calls, and simple unary operator expressions). In cases where the declared alias is a reserved SQL keyword, the <em>output_name </em><span style="font-size: small;"> </span>must be enclosed in double quotes to avoid ambiguity.</p><p align="LEFT">An <em>expression </em><span style="font-size: small;"> </span>in the SELECT list can be a constant value, a column reference, an operator invocation, a function call, an aggregate expression, a window expression, a scalar subquery, and so on. There are a number of constructs that can be classified as an expression but do not follow any general syntax rules.</p><p align="LEFT">Instead of an expression, * can be written in the output list as a shorthand for all the columns of the selected rows. Also, one can write <em>table_name</em><span style="font-size: small;"> </span>.* as a shorthand for the columns coming from just that table.</p><h4 id="SQLCommandReference-TheFROMClause">The FROM Clause</h4><p align="LEFT">The FROM clause specifies one or more source tables for the SELECT. If multiple sources are specified, the result is the Cartesian product (cross join) of all the sources. But usually qualification conditions are added to restrict the returned rows to a small subset of the Cartesian product. The FROM clause can contain the following elements:</p><pre>table_name</pre><p style="margin-left: 30.0px;">The name (optionally schema-qualified) of an existing table or view. If ONLY is specified, only that table is scanned. If ONLY is not specified, the table and all its descendant tables (if any) are scanned.</p><pre>alias</pre><p style="margin-left: 30.0px;">A substitute name for the FROM item containing the alias. An alias is used for brevity or to eliminate ambiguity for self-joins (where the same table is scanned multiple times). When an alias is provided, it completely hides the actual name of the table or function; for example given FROM foo AS f, the remainder of the SELECT must refer to this FROM item as f not foo. If an alias is written, a column alias list can also be written to provide substitute names for one or more columns of the table.<span style="font-size: medium;"><span style="font-size: medium;"> </span></span></p><pre>select</pre><p style="margin-left: 30.0px;">A sub-SELECT can appear in the FROM clause. This acts as though its output were created as a temporary table for the duration of this single SELECT command. Note that the sub-SELECT must be surrounded by parentheses, and an alias must be provided for it. A VALUES command can also be used here. See “Nonstandard Clauses” on page 209 for limitations of using correlated sub-selects in HAWQ.</p><pre>function_name</pre><p style="margin-left: 30.0px;">Function calls can appear in the FROM clause. (This is especially useful for functions that return result sets, but any function can be used.) This acts as though its output were created as a temporary table for the duration of this single SELECT command. An alias may also be used. If an alias is written, a column alias list can also be written to provide substitute names for one or more attributes of the function’s composite return type. If the function has been defined as returning the record data type, then an alias or the key word AS must be present, followed by a column definition list in the form ( column_name data_type [, ... ] ). The column definition list must match the actual number and types of columns returned by the function.</p><pre>join_type</pre><p style="margin-left: 30.0px;">One of:</p><ul><li style="list-style-type: none;background-image: none;"><ul><li>[INNER] JOIN</li><li>LEFT [OUTER] JOIN</li><li>RIGHT [OUTER] JOIN</li><li>FULL [OUTER] JOIN</li><li>CROSS JOIN</li></ul></li></ul><p style="margin-left: 30.0px;">For the INNER and OUTER join types, a join condition must be specified, namely exactly one of NATURAL, ON <em>join_condition</em><span style="font-size: small;"> </span>, or USING (<em>join_column </em><span style="font-size: small;"> </span>[,...]). See below for the meaning. For CROSS JOIN, none of these clauses may appear.</p><p align="LEFT" style="margin-left: 30.0px;">A JOIN clause combines two FROM items. Use parentheses if necessary to determine the order of nesting. In the absence of parentheses, JOINs nest left-to-right. In any case. JOIN binds more tightly than the commas separating FROM items. CROSS JOIN and INNER JOIN produce a simple Cartesian product, the same result as you get from listing the two items at the top level of FROM, but restricted by the join condition (if any).</p><p align="LEFT" style="margin-left: 30.0px;">CROSS JOIN is equivalent to INNER JOIN ON (TRUE), that is, no rows are removed by qualification. These join types are just a notational convenience, since they do nothing you could not do with plain FROM and WHERE.</p><p align="LEFT" style="margin-left: 30.0px;">LEFT OUTER JOIN returns all rows in the qualified Cartesian product (i.e., all combined rows that pass its join condition), plus one copy of each row in the left-hand table for which there was no right-hand row that passed the join condition. This left-hand row is extended to the full width of the joined table by inserting null values for the right-hand columns. Note that only the JOIN clause’s own condition is considered while deciding which rows have matches. Outer conditions are applied afterwards.</p><p align="LEFT" style="margin-left: 30.0px;">Conversely, RIGHT OUTER JOIN returns all the joined rows, plus one row for each unmatched right-hand row (extended with nulls on the left). This is just a notational convenience, since you could convert it to a LEFT OUTER JOIN by switching the left and right inputs.</p><p align="LEFT" style="margin-left: 30.0px;">FULL OUTER JOIN returns all the joined rows, plus one row for each unmatched left-hand row (extended with nulls on the right), plus one row for each unmatched right-hand row (extended with nulls on the left).</p><pre>ON j<em>oin_condition</em></pre><p style="margin-left: 30.0px;">join_condition is an expression resulting in a value of type boolean (similar to a WHERE clause) that specifies which rows in a join are considered to match.</p><pre>USING (join_column  [, ...])</pre><p style="margin-left: 30.0px;">A clause of the form USING ( a, b, ... ) is shorthand for ON left_table.a =right_table.a AND left_table.b = right_table.b ....Also, USING implies that only one of each pair of equivalent columns will be included in the join output, not both.</p><pre>NATURAL</pre><p style="margin-left: 30.0px;">NATURAL is shorthand for a USING list that mentions all columns in the two tables that have the same names.</p><h4 id="SQLCommandReference-TheWHEREClause">The WHERE Clause</h4><p>The optional WHERE clause has the general form:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">WHERE condition</pre>
</div></div><p>Where <em>condition </em><span style="font-size: small;"> </span>is any expression that evaluates to a result of type boolean. Any row that does not satisfy this condition will be eliminated from the output. A row satisfies the condition if it returns true when the actual row values are substituted for any variable references.</p><h4 id="SQLCommandReference-TheGROUPBYClause">The GROUP BY Clause</h4><p>The optional GROUP BY clause has the general form:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">GROUP BY grouping_element  [, ...]
where grouping_element  can be one of:(
)
expression
ROLLUP (
expression  [,...])
CUBE (expression  [,...])
GROUPING SETS ((grouping_element  [, ...]))</pre>
</div></div><p align="LEFT">GROUP BY will condense into a single row all selected rows that share the same values for the grouped expressions. <em>expression </em><span style="font-size: small;"> </span>can be an input column name, or the name or ordinal number of an output column (SELECT list item), or an arbitrary expression formed from input-column values. In case of ambiguity, a GROUP BY name will be interpreted as an input-column name rather than an output column name.</p><p align="LEFT">Aggregate functions, if any are used, are computed across all rows making up each group, producing a separate value for each group (whereas without GROUP BY, an aggregate produces a single value computed across all the selected rows). When GROUP BY is present, it is not valid for the SELECT list expressions to refer to ungrouped columns except within aggregate functions, since there would be more than one possible value to return for an ungrouped column.</p><p align="LEFT">HAWQ has the following additional OLAP grouping extensions (often referred to as supergroups):</p><h4 id="SQLCommandReference-ROLLUP">ROLLUP</h4><p>A ROLLUP grouping is an extension to the GROUP BY clause that creates aggregate subtotals that roll up from the most detailed level to a grand total, following a list of grouping columns (or expressions). ROLLUP takes an ordered list of grouping columns, calculates the standard aggregate values specified in the GROUP BY clause, then creates progressively higher-level subtotals, moving from right to left through the list. Finally, it creates a grand total. A ROLLUP grouping can be thought of as a series of grouping sets. For example:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">GROUP BY ROLLUP (a,b,c)</pre>
</div></div><p><span style="font-size: medium;"> </span>is equivalent to:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">GROUP BY GROUPING SETS( (a,b,c), (a,b), (a), () )</pre>
</div></div><p align="LEFT">Notice that the <em>n </em><span style="font-size: medium;"> </span>elements of a ROLLUP translate to <em>n</em><span style="font-size: medium;"> </span>+1 grouping sets. Also, the order in which the grouping expressions are specified is significant in a ROLLUP.</p><h4 id="SQLCommandReference-CUBE">CUBE</h4><p>A CUBE grouping is an extension to the GROUP BY clause that creates subtotals for all of the possible combinations of the given list of grouping columns (or expressions). In terms of multidimensional analysis, CUBE generates all the subtotals that could be calculated for a data cube with the specified dimensions. For example:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">GROUP BY CUBE (a,b,c)</pre>
</div></div><p align="LEFT"><span style="font-size: medium;"> </span>is equivalent to:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;"> GROUP BY GROUPING SETS( (a,b,c), (a,b), (a,c), (b,c), (a), (b), (c), () )</pre>
</div></div><p>Notice that <em>n </em><span style="font-size: medium;"> </span>elements of a CUBE translate to 2<em>n </em><span style="font-size: xx-small;"> </span>grouping sets. Consider using CUBE in any situation requiring cross-tabular reports. CUBE is typically most suitable in queries that use columns from multiple dimensions rather than columns representing different levels of a single dimension. For instance, a commonly requested cross-tabulation might need subtotals for all the combinations of month, state, and product.</p><h4 id="SQLCommandReference-GROUPINGSETS">GROUPING SETS</h4><p>You can selectively specify the set of groups that you want to create using a GROUPING SETS expression within a GROUP BY clause. This allows precise specification across multiple dimensions without computing a whole ROLLUP or CUBE. For example:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">GROUP BY GROUPING SETS( (a,c), (a,b) )</pre>
</div></div><p>If using the grouping extension clauses ROLLUP, CUBE, or GROUPING SETS, two challenges arise. First, how do you determine which result rows are subtotals, and then the exact level of aggregation for a given subtotal. Or, how do you differentiate between result rows that contain both stored NULL values and “NULL” values created by the ROLLUP or CUBE. Secondly, when duplicate grouping sets are specified in the GROUP BY clause, how do you determine which result rows are duplicates? There are two additional grouping functions you can use in the SELECT list to help with this:<span style="font-size: medium;">  </span></p><ul><li><span style="font-size: medium;"> </span>grouping(column [, ...]) The grouping function can be applied to one or more grouping attributes to distinguish super-aggregated rows from regular grouped rows. This can be helpful in distinguishing a “NULL” representing the set of all values in a super-aggregated row from a NULL value in a regular row. Each argument in this function produces a bit — either 1 or 0, where 1 means the result row is super-aggregated, and 0 means the result row is from a regular grouping. The grouping function returns an integer by treating these bits as a binary number and then converting it to a base-10 integer.</li><li>group_id() For grouping extension queries that contain duplicate grouping sets, the group_id function is used to identify duplicate rows in the output. All <em>unique </em>grouping set output rows will have a group_id value of 0. For each duplicate grouping set detected, the group_id function assigns a group_id number greater than 0. All output rows in a particular duplicate grouping set are identified by the same group_id number.</li></ul><h4 id="SQLCommandReference-TheWINDOWClause">The WINDOW Clause</h4><p align="LEFT">The WINDOW clause is used to define a window that can be used in the OVER() expression of a window function such as rank or avg. For example:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SELECT vendor, rank() OVER (mywindow) FROM sale
GROUP BY vendor
WINDOW mywindow AS (ORDER BY sum(prc*qty));</pre>
</div></div><p>A WINDOW clause is has this general form:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">WINDOW window_name AS (window_specification)
where  window_specification can be:
[window_name]
[PARTITION BY expression [, ...]]
[ORDER BY expression [ASC | DESC | USING operator] [, ...]
[{RANGE | ROWS}
{ UNBOUNDED PRECEDING
| expression PRECEDING
| CURRENT ROW
| BETWEEN 
window_frame_bound AND window_frame_bound }]]
where window_frame_bound can be one of:
UNBOUNDED PRECEDING
expression PRECEDING
CURRENT ROW
expression FOLLOWING
UNBOUNDED FOLLOWING</pre>
</div></div><pre>window_name</pre><p style="margin-left: 30.0px;">Gives a name to the window specification.</p><pre>PARTITION BY</pre><p style="margin-left: 30.0px;">The PARTITION BY clause organizes the result set into logical groups based on the unique values of the specified expression. When used with window functions, the functions are applied to each partition independently. For example, if you follow PARTITION BY with a column name, the result set is partitioned by the distinct values of that column. If omitted, the entire result set is considered one partition.</p><pre>ORDER BY</pre><p style="margin-left: 30.0px;">The ORDER BY clause defines how to sort the rows in each partition of the result set. If omitted, rows are returned in whatever order is most efficient and may vary.</p><p align="LEFT" style="margin-left: 30.0px;">Note: Columns of data types that lack a coherent ordering, such as time, are not good candidates for use in the ORDER BY clause of a window specification. Time, with or without time zone, lacks a coherent ordering because addition and subtraction do not have the expected effects. For example, the following is not generally true:x::time &lt; x::time + '2 hour'::interval</p><pre>ROWS | RANGE</pre><p style="margin-left: 30.0px;">Use either a ROWS or RANGE clause to express the bounds of the window. The window bound can be one, many, or all rows of a partition. You can express the bound of the window either in terms of a range of data values offset from the value</p><p align="LEFT" style="margin-left: 30.0px;">in the current row (RANGE), or in terms of the number of rows offset from the currentrow (ROWS). When using the RANGE clause, you must also use an ORDER BY clause. This is because the calculation performed to produce the window requires that the values be sorted. Additionally, the ORDER BY clause cannot contain more than one expression, and the expression must result in either a date or a numeric value. When using the ROWS or RANGE clauses, if you specify only a starting row, the current row is used as the last row in the window.</p><p style="margin-left: 30.0px;">PRECEDING</p><p style="margin-left: 60.0px;">The PRECEDING clause defines the first row of the window using the current row as a reference point. The starting row is expressed in terms of the number of rows preceding the current row. For example, in the case of ROWS framing, 5 PRECEDING sets the window to start with the fifth row preceding the current row. In the case of RANGE framing, it sets the window to start with the first row whose ordering column value precedes that of the current row by 5 in the given order. If the specified order is ascending by date, this will be the first row within 5 days before the current row. UNBOUNDED PRECEDING sets the first row in the window to be the first row in the partition.</p><p style="margin-left: 30.0px;">BETWEEN</p><p style="margin-left: 60.0px;">The BETWEEN clause defines the first and last row of the window, using the current row as a reference point. First and last rows are expressed in terms of the number of rows preceding and following the current row, respectively. For example, BETWEEN 3 PRECEDING AND 5 FOLLOWING sets the window to start with the third row preceding the current row, and end with the fifth row following the current row. Use BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING to set the first and last rows in the window to be the first and last row in the partition, respectively. This is equivalent to the default behavior if no ROW or RANGE clause is specified.</p><p style="margin-left: 30.0px;">FOLLOWING</p><p align="LEFT" style="margin-left: 60.0px;">The FOLLOWING clause defines the last row of the window using the current row as a reference point. The last row is expressed in terms of the number of rows following the current row. For example, in the case of ROWS framing, 5 FOLLOWING sets the window to end with the fifth row following the current row. In the case of RANGE framing, it sets the window to end with the last row whose ordering column value follows that of the current row by 5 in the given order. If the specified order is ascending by date, this will be the last row within 5 days after the current row. Use UNBOUNDED FOLLOWING to set the last row in the window to be the last row in the partition.</p><p align="LEFT" style="margin-left: 30.0px;">If you do not specify a ROW or a RANGE clause, the window bound starts with the first row in the partition (UNBOUNDED PRECEDING) and ends with the current row (CURRENT ROW) if ORDER BY is used. If an ORDER BY is not specified, the window starts with the first row in the partition (UNBOUNDED PRECEDING) and ends with last row in the partition (UNBOUNDED FOLLOWING).</p><h4 id="SQLCommandReference-TheHAVINGClause">The HAVING Clause</h4><p>The optional HAVING clause has the general form:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: scala; gutter: false" style="font-size:12px;">HAVING condition</pre>
</div></div><p align="LEFT">Where <em>condition </em><span style="font-size: small;"> </span>is the same as specified for the WHERE clause. HAVING eliminates group rows that do not satisfy the condition. HAVING is different from WHERE: WHERE filters individual rows before the application of GROUP BY, while HAVING filters group rows created by GROUP BY. Each column referenced in <em>condition </em><span style="font-size: small;"> </span>must unambiguously reference a grouping column, unless the reference appears within an aggregate function.</p><p align="LEFT">The presence of HAVING turns a query into a grouped query even if there is no GROUP BY clause. This is the same as what happens when the query contains aggregate functions but no GROUP BY clause. All the selected rows are considered to form a single group, and the SELECT list and HAVING clause can only reference table columns from within aggregate functions. Such a query will emit a single row if the HAVING condition is true, zero rows if it is not true.</p><h4 id="SQLCommandReference-TheUNIONClause">The UNION Clause</h4><p>The UNION clause has this general form:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">select_statement
UNION [ALL] select_statement</pre>
</div></div><p align="LEFT">Where <em>select_statement </em><span style="font-size: small;"> </span>is any SELECT statement without an ORDER BY, LIMIT, FOR UPDATE, or FOR SHARE clause. (ORDER BY and LIMIT can be attached to a subquery expression if it is enclosed in parentheses. Without parentheses, these clauses will be taken to apply to the result of the UNION, not to its right-hand input expression.)</p><p align="LEFT">The UNION operator computes the set union of the rows returned by the involved SELECT statements. A row is in the set union of two result sets if it appears in at least one of the result sets. The two SELECT statements that represent the direct operands of the UNION must produce the same number of columns, and corresponding columns must be of compatible data types.</p><p align="LEFT">The result of UNION does not contain any duplicate rows unless the ALL option is specified. ALL prevents elimination of duplicates. (Therefore, UNION ALL is usually significantly quicker than UNION; use ALL when you can.)</p><p>Multiple UNION operators in the same SELECT statement are evaluated left to right, unless otherwise indicated by parentheses.</p><p>Currently, FOR UPDATE and FOR SHARE may not be specified either for a UNION result or for any input of a UNION.</p><h4 id="SQLCommandReference-TheINTERSECTClause">The INTERSECT Clause</h4><p>The INTERSECT clause has this general form:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">select_statement INTERSECT [ALL] select_statement</pre>
</div></div><p align="LEFT">Where <em>select_statement </em><span style="font-size: small;"> </span>is any SELECT statement without an ORDER BY, LIMIT, FOR UPDATE, or FOR SHARE clause.</p><p align="LEFT">The INTERSECT operator computes the set intersection of the rows returned by the involved SELECT statements. A row is in the intersection of two result sets if it appears in both result sets.<span style="font-size: medium;"> </span></p><p align="LEFT">The result of INTERSECT does not contain any duplicate rows unless the ALL option is specified. With ALL, a row that has <em>m </em><span style="font-size: small;"> </span>duplicates in the left table and <em>n </em><span style="font-size: small;"> </span>duplicates in the right table will appear min(<em>m</em><span style="font-size: small;"> </span>,<em>n</em><span style="font-size: small;"> </span>) times in the result set.</p><p align="LEFT">Multiple INTERSECT operators in the same SELECT statement are evaluated left to right, unless parentheses dictate otherwise. INTERSECT binds more tightly than UNION. That is, A UNION B INTERSECT C will be read as A UNION (B INTERSECT C).</p><p>Currently, FOR UPDATE and FOR SHARE may not be specified either for an INTERSECT result or for any input of an INTERSECT.</p><h4 id="SQLCommandReference-TheEXCEPTClause">The EXCEPT Clause</h4><p>The EXCEPT clause has this general form:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">select_statement EXCEPT [ALL] select_statement</pre>
</div></div><p align="LEFT"><span style="font-size: medium;"><span style="font-size: small;"> </span></span>Where <em>select_statement </em><span style="font-size: small;"> </span>is any SELECT statement without an ORDER BY, LIMIT, FOR UPDATE, or FOR SHARE clause.</p><p>The EXCEPT operator computes the set of rows that are in the result of the left SELECT statement but not in the result of the right one.</p><p>The result of EXCEPT does not contain any duplicate rows unless the ALL option is specified. With ALL, a row that has <em>m </em><span style="font-size: small;"> </span>duplicates in the left table and <em>n </em><span style="font-size: small;"> </span>duplicates in the right table will appear max(<em>m-n</em><span style="font-size: small;"> </span>,0) times in the result set.</p><p align="LEFT">Multiple EXCEPT operators in the same SELECT statement are evaluated left to right, unless parentheses dictate otherwise. EXCEPT binds at the same level as UNION.</p><p>Currently, FOR UPDATE and FOR SHARE may not be specified either for an EXCEPT result or for any input of an EXCEPT.</p><h4 id="SQLCommandReference-TheORDERBYClause">The ORDER BY Clause</h4><p>The optional ORDER BY clause has this general form:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">ORDER BY 
expression [ASC | DESC | USING operator] [, ...]</pre>
</div></div><p align="LEFT">Where <em>expression </em><span style="font-size: small;"> </span>can be the name or ordinal number of an output column (SELECT list item), or it can be an arbitrary expression formed from input-column values.</p><p>The ORDER BY clause causes the result rows to be sorted according to the specified expressions. If two rows are equal according to the left-most expression, they are compared according to the next expression and so on. If they are equal according to all specified expressions, they are returned in an implementation-dependent order.</p><p align="LEFT">The ordinal number refers to the ordinal (left-to-right) position of the result column. This feature makes it possible to define an ordering on the basis of a column that does not have a unique name. This is never absolutely necessary because it is always possible to assign a name to a result column using the AS clause.</p><p>It is also possible to use arbitrary expressions in the ORDER BY clause, including columns that do not appear in the SELECT result list. Thus the following statement is valid:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SELECT name FROM distributors ORDER BY code;</pre>
</div></div><p>A limitation of this feature is that an ORDER BY clause applying to the result of a UNION, INTERSECT, or EXCEPT clause may only specify an output column name or <span style="font-size: medium;"><span style="font-size: small;">n</span></span>umber, not an expression.</p><p><span style="font-size: medium;"><span style="font-size: small;"> </span></span>If an ORDER BY expression is a simple name that matches both a result column name and an input column name, ORDER BY will interpret it as the result column name. This is the opposite of the choice that GROUP BY will make in the same situation. This inconsistency is made to be compatible with the SQL standard.</p><p align="LEFT">Optionally one may add the key word ASC (ascending) or DESC (descending) after any expression in the ORDER BY clause. If not specified, ASC is assumed by default. Alternatively, a specific ordering operator name may be specified in the USING clause. ASC is usually equivalent to USING &lt; and DESC is usually equivalent to USING &gt;. (But the creator of a user-defined data type can define exactly what the default sort ordering is, and it might correspond to operators with other names.)</p><p align="LEFT">The null value sorts higher than any other value. In other words, with ascending sort order, null values sort at the end, and with descending sort order, null values sort at the beginning.<span style="font-size: medium;"><span style="font-size: small;"> </span></span></p><p align="LEFT">Character-string data is sorted according to the locale-specific collation order that was established when the HAWQ system was initialized.</p><h4 id="SQLCommandReference-TheDISTINCTClause">The DISTINCT Clause</h4><p>If DISTINCT is specified, all duplicate rows are removed from the result set (one row is kept from each group of duplicates). ALL specifies the opposite: all rows are kept. ALL is the default.</p><p align="LEFT">DISTINCT ON (<em>expression </em><span style="font-size: small;"> </span>[, ...] ) keeps only the first row of each set of rows where the given expressions evaluate to equal. The DISTINCT ON expressions are interpreted using the same rules as for ORDER BY. Note that the ‘first row’ of each set is unpredictable unless ORDER BY is used to ensure that the desired row appears first. For example:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SELECT DISTINCT ON (location) location, time, report FROM
weather_reports ORDER BY location, time DESC;</pre>
</div></div><p>retrieves the most recent weather report for each location. But if we had not used ORDER BY to force descending order of time values for each location, we would have gotten a report from an unpredictable time for each location.</p><p>The DISTINCT ON expression(s) must match the left-most ORDER BY expression(s). The ORDER BY clause will normally contain additional expression(s) that determine the desired precedence of rows within each DISTINCT ON group.<span style="font-size: medium;"><span style="font-size: small;"> </span></span></p><h4 id="SQLCommandReference-TheLIMITClause">The LIMIT Clause</h4><p align="LEFT">The LIMIT clause consists of two independent sub-clauses:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">LIMIT {count  | ALL} OFFSET start</pre>
</div></div><p>Where <em>count </em><span style="font-size: small;"> </span>specifies the maximum number of rows to return, while <em>start </em><span style="font-size: small;"> </span>specifies the number of rows to skip before starting to return rows. When both are specified, start rows are skipped before starting to count the count rows to be returned.</p><p align="LEFT">When using LIMIT, it is a good idea to use an ORDER BY clause that constrains the result rows into a unique order. Otherwise you will get an unpredictable subset of the query’s rows — you may be asking for the tenth through twentieth rows, but tenth through twentieth in what ordering? You don’t know what ordering unless you specify ORDER BY.</p><p align="LEFT">The query planner takes LIMIT into account when generating a query plan, so you are very likely to get different plans (yielding different row orders) depending on what you use for LIMIT and OFFSET. Thus, using different LIMIT/OFFSET values to select different subsets of a query result will give inconsistent results unless you enforce a predictable result ordering with ORDER BY. This is not a defect; it is an inherent  consequence of the fact that SQL does not promise to deliver the results of a query in any particular order unless ORDER BY is used to constrain the order.</p><h3 id="SQLCommandReference-Examples.46">Examples</h3><p>To join the table <em>films </em><span style="font-size: medium;"> </span>with the table <em>distributors</em><span style="font-size: medium;"> </span>:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SELECT f.title, f.did, d.name, f.date_prod, f.kind FROM
distributors d, films f WHERE f.did = d.did</pre>
</div></div><p align="LEFT">To sum the column <em>length </em><span style="font-size: medium;"> </span>of all films and group the results by <em>kind</em><span style="font-size: medium;"> </span>:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SELECT kind, sum(length) AS total FROM films GROUP BY kind;</pre>
</div></div><p align="LEFT">To sum the column <em>length </em><span style="font-size: medium;"> </span>of all films, group the results by <em>kind </em><span style="font-size: medium;"> </span>and show those group totals that are less than 5 hours:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SELECT kind, sum(length) AS total FROM films GROUP BY kind
HAVING sum(length) &lt; interval '5 hours';</pre>
</div></div><p>Calculate the subtotals and grand totals of all sales for movie kind and <em>distributor</em>.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SELECT kind, distributor, sum(prc*qty) FROM sales
GROUP BY ROLLUP(kind, distributor)
ORDER BY 1,2,3;</pre>
</div></div><p>Calculate the rank of movie distributors based on total sales:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SELECT distributor, sum(prc*qty),
rank() OVER (ORDER BY sum(prc*qty) DESC)
FROM sale
GROUP BY distributor ORDER BY 2 DESC;</pre>
</div></div><p align="LEFT">The following two examples are identical ways of sorting the individual results according to the contents of the second column (<em>name</em><span style="font-size: medium;"> </span>):</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SELECT * FROM distributors ORDER BY name;
SELECT * FROM distributors ORDER BY 2;</pre>
</div></div><p align="LEFT">The next example shows how to obtain the union of the tables <em>distributors </em><span style="font-size: medium;"> </span>and <em>actors</em>, restricting the results to those that begin with the letter <em>W </em><span style="font-size: medium;"> </span>in each table. Only distinct rows are wanted, so the key word ALL is omitted:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SELECT distributors.name FROM distributors WHERE
distributors.name LIKE 'W%' UNION SELECT actors.name FROM
actors WHERE actors.name LIKE 'W%';</pre>
</div></div><p align="LEFT">This example shows how to use a function in the FROM clause, both with and without a column definition list:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">CREATE FUNCTION distributors(int) RETURNS SETOF distributors
AS $$ SELECT * FROM distributors WHERE did = $1; $$ LANGUAGE
SQL;
SELECT * FROM distributors(111);
CREATE FUNCTION distributors_2(int) RETURNS SETOF record AS
$$ SELECT * FROM distributors WHERE did = $1; $$ LANGUAGE
SQL;
SELECT * FROM distributors_2(111) AS (dist_id int, dist_name
text);</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.52">Compatibility</h3><p>The SELECT statement is compatible with the SQL standard, but there are some extensions and some missing features.</p><h4 id="SQLCommandReference-OmittedFROMClauses">Omitted FROM Clauses</h4><p>HAWQ allows one to omit the FROM clause. It has a straightforward use to compute the results of simple expressions. For example:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SELECT 2+2;</pre>
</div></div><p align="LEFT">Some other SQL databases cannot do this except by introducing a dummy one-row table from which to do the SELECT.</p><p>Note that if a FROM clause is not specified, the query cannot reference any database tables. For compatibility with applications that rely on this behavior the add_missing_from configuration variable can be enabled.</p><h4 id="SQLCommandReference-TheASKeyWord">The AS Key Word</h4><p align="LEFT">In the SQL standard, the optional key word AS is just noise and can be omitted without affecting the meaning. The HAWQ parser requires this key word when renaming output columns because the type extensibility features lead to parsing ambiguities without it. AS is optional in FROM items, however.</p><h4 id="SQLCommandReference-NamespaceAvailabletoGROUPBYandORDERBY">Namespace Available to GROUP BY and ORDER BY</h4><p>In the SQL-92 standard, a ORDER BY clause may only use result column names or numbers, while a GROUP BY clause may only use expressions based on input column names. HAWQ extends each of these clauses to allow the other choice as well (but it uses the standard’s interpretation if there is ambiguity). HAWQ also allows both clauses to specify arbitrary expressions. Note that names appearing in an expression will always be taken as input-column names, not as result-column names. SQL:1999 and later use a slightly different definition which is not entirely upward compatible with SQL-92. In most cases, however, HAWQ will interpret an ORDER BY or GROUP BY expression the same way SQL:1999 does.</p><h4 id="SQLCommandReference-NonstandardClauses">Nonstandard Clauses</h4><p>The clauses DISTINCT ON, LIMIT, and OFFSET are not defined in the SQL standard.</p><h4 id="SQLCommandReference-LimitedUseofSTABLEandVOLATILEFunctions">Limited Use of STABLE and VOLATILE Functions</h4><p>To prevent data from becoming out-of-sync across the segments in HAWQ, any function classified as STABLE or VOLATILE cannot be executed at the segment database level if it contains SQL or modifies the database in any way.</p><h3 id="SQLCommandReference-SeeAlso.47">See Also</h3><p>EXPLAIN</p><h2 id="SQLCommandReference-SELECTINTO">SELECT INTO</h2><p>Defines a new table from the results of a query.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SELECT [ALL | DISTINCT [ON ( 
expression [, ...] )]]
    * | expression [AS output_name] [, ...]
    INTO [TEMPORARY | TEMP] [TABLE] new_table
    [FROM from_item [, ...]]
    [WHERE condition]
    [GROUP BY expression [, ...]]
    [HAVING condition [, ...]]
    [{UNION | INTERSECT | EXCEPT} [ALL] select]
    [ORDER BY expression [ASC | DESC | USING operator] [, ...]]
    [LIMIT {count | ALL}]
    [OFFSET start]
[...]]</pre>
</div></div><h3 id="SQLCommandReference-Description.54">Description</h3><p>SELECT INTO creates a new table and fills it with data computed by a query. The data is not returned to the client, as it is with a normal SELECT. The new table’s columns have the names and data types associated with the output columns of the SELECT.</p><h3 id="SQLCommandReference-Parameters.50">Parameters</h3><p>The majority of parameters for SELECT INTO are the same as SELECT.</p><pre>TEMPORARY<br/>TEMP</pre><p style="margin-left: 30.0px;">If specified, the table is created as a temporary table.</p><pre>new_table</pre><p style="margin-left: 30.0px;">The name (optionally schema-qualified) of the table to be created.</p><h3 id="SQLCommandReference-Examples.47">Examples</h3><p align="LEFT">Create a new table <em>films_recent </em><span style="font-size: medium;"> </span>consisting of only recent entries from the table <em>films</em><span style="font-size: medium;"> </span>:</p><h3 id="SQLCommandReference-Compatibility.53">Compatibility</h3><p>The SQL standard uses SELECT INTO to represent selecting values into scalar variables of a host program, rather than creating a new table. The HAWQ usage of SELECT INTO to represent table creation is historical. It is best to use CREATE TABLE AS for this purpose in new applications.</p><h3 id="SQLCommandReference-SeeAlso.48">See Also</h3><p>SELECT, CREATE TABLE AS</p><h2 id="SQLCommandReference-SET">SET</h2><p>Changes the value of a HAWQ configuration parameter.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SET [SESSION | LOCAL] configuration_parameter {TO | =} value | 'value' | DEFAULT}
SET [SESSION | LOCAL] TIME ZONE {timezone | LOCAL | DEFAULT}</pre>
</div></div><h3 id="SQLCommandReference-Description.55">Description</h3><p>The SET command changes server configuration parameters. Any configuration parameter classified as a <em>session </em><span style="font-size: medium;"> </span>parameter can be changed on-the-fly with SET (see “Server Configuration Parameters” for details). SET only affects the value used by the current session.</p><p align="LEFT">If SET or SET SESSION is issued within a transaction that is later aborted, the effects of the SET command disappear when the transaction is rolled back. Once the surrounding transaction is committed, the effects will persist until the end of the session, unless overridden by another SET.</p><p align="LEFT">The effects of SET LOCAL last only till the end of the current transaction, whether committed or not. A special case is SET followed by SET LOCAL within a single transaction: the SET LOCAL value will be seen until the end of the transaction, but afterwards (if the transaction is committed) the SET value will take effect.</p><h3 id="SQLCommandReference-Parameters.51">Parameters</h3><pre>SESSION</pre><p align="LEFT" style="margin-left: 30.0px;">Specifies that the command takes effect for the current session. This is the default.</p><pre>LOCAL</pre><p style="margin-left: 30.0px;">Specifies that the command takes effect for only the current transaction. After COMMIT or ROLLBACK, the session-level setting takes effect again. Note that SET LOCAL will appear to have no effect if it is executed outside of a transaction.</p><pre>configuration_parameter</pre><p style="margin-left: 30.0px;">The name of a HAWQ configuration parameter. Only parameters classified as session can be changed with SET. See “Server Configuration Parameters”.</p><pre>value</pre><p style="margin-left: 30.0px;">New value of parameter. Values can be specified as string constants, identifiers,numbers, or comma-separated lists of these. DEFAULT can be used to specify resetting the parameter to its default value. If specifying memory sizing or time units, enclose the value in single quotes.</p><pre>TIME ZONE</pre><p style="margin-left: 30.0px;">SET TIME ZONE value is an alias for SET timezone TO <em>value</em><span style="font-size: small;"> </span>. The syntax SET TIME ZONE allows special syntax for the time zone specification. Here are examples of valid values</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">'PST8PDT'
'Europe/Rome'
-7 (time zone 7 hours west from UTC)
INTERVAL '-08:00' HOUR TO MINUTE (time zone 8 hours west from UTC)</pre>
</div></div><pre>LOCAL<br/>DEFAULT</pre><p align="LEFT" style="margin-left: 30.0px;">Set the time zone to your local time zone (the one that the server’s operating system defaults to). See the Time zone section of the PostgreSQL documentation for more information about time zones in HAWQ.</p><h3 id="SQLCommandReference-Examples.48">Examples</h3><p>Set the schema search path:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SET search_path TO my_schema, public;</pre>
</div></div><p align="LEFT">Increase work memory to 200 MB:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SET work_mem TO '200MB';</pre>
</div></div><p align="LEFT">Set the style of date to traditional POSTGRES with “day before month” input convention:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SET datestyle TO postgres, dmy;</pre>
</div></div><p align="LEFT">Set the time zone for San Mateo, California:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SET TIME ZONE 'PST8PDT';</pre>
</div></div><p align="LEFT">Set the time zone for Italy:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SET TIME ZONE 'Europe/Rome';</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.54">Compatibility</h3><p align="LEFT">SET TIME ZONE extends syntax defined in the SQL standard. The standard allows only numeric time zone offsets while HAWQ allows more flexible time-zone specifications. All other SET features are HAWQ extensions.</p><h3 id="SQLCommandReference-SeeAlso.49">See Also</h3><p>RESET, SHOW</p><h2 id="SQLCommandReference-SETROLE">SET ROLE</h2><p>Sets the current role identifier of the current session.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SET [SESSION | LOCAL] ROLE rolename
SET [SESSION | LOCAL] ROLE NONE
RESET ROLE</pre>
</div></div><h3 id="SQLCommandReference-Description.56">Description</h3><p>This command sets the current role identifier of the current SQL-session context to be rolename. The role name may be written as either an identifier or a string literal. After SET ROLE, permissions checking for SQL commands is carried out as though the named role were the one that had logged in originally.</p><p align="LEFT">The specified <em>rolename </em><span style="font-size: medium;"> </span>must be a role that the current session user is a member of. If the session user is a superuser, any role can be selected. The NONE and RESET forms reset the current role identifier to be the current session role identifier. These forms may be executed by any user.</p><h3 id="SQLCommandReference-Parameters.52">Parameters</h3><pre>SESSION</pre><p style="margin-left: 30.0px;">Specifies that the command takes effect for the current session. This is the default.</p><pre>LOCAL</pre><p align="LEFT" style="margin-left: 30.0px;">Specifies that the command takes effect for only the current transaction. After COMMIT or ROLLBACK, the session-level setting takes effect again. Note that SET LOCAL will appear to have no effect if it is executed outside of a transaction.</p><pre>rolename</pre><p style="margin-left: 30.0px;">The name of a role to use for permissions checking in this session.</p><pre>NONE<br/>RESET</pre><p style="margin-left: 30.0px;">Reset the current role identifier to be the current session role identifier (that of the role used to log in).</p><h3 id="SQLCommandReference-Notes.31">Notes</h3><p>Using this command, it is possible to either add privileges or restrict privileges. If the session user role has the INHERITS attribute, then it automatically has all the privileges of every role that it could SET ROLE to; in this case SET ROLE effectively drops all the privileges assigned directly to the session user and to the other roles it is a member of, leaving only the privileges available to the named role. On the other hand, if the session user role has the NOINHERITS attribute, SET ROLE drops the privileges assigned directly to the session user and instead acquires the privileges available to the named role.</p><p align="LEFT">In particular, when a superuser chooses to SET ROLE to a non-superuser role, she loses her superuser privileges.</p><p align="LEFT">SET ROLE has effects comparable to SET SESSION AUTHORIZATION, but the privilege checks involved are quite different. Also, SET SESSION AUTHORIZATION determines which roles are allowable for later SET ROLE commands, whereas changing roles with SET ROLE does not change the set of roles allowed to a later SET ROLE.</p><h3 id="SQLCommandReference-Examples.49">Examples</h3><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SELECT SESSION_USER, CURRENT_USER;
session_user | current_user
--------------+--------------
peter | peter
SET ROLE 'paul';
SELECT SESSION_USER, CURRENT_USER;
session_user | current_user
--------------+--------------
peter | paul</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.55">Compatibility</h3><p align="LEFT">HAWQ allows identifier syntax (<em>rolename</em><span style="font-size: small;"> </span>), while the SQL standard requires the role name to be written as a string literal. SQL does not allow this command during a transaction; HAWQ does not make this restriction. The SESSION and LOCAL modifiers are a HAWQ extension, as is the RESET syntax.</p><h3 id="SQLCommandReference-SeeAlso.50">See Also</h3><p>SET SESSION AUTHORIZATION</p><h2 id="SQLCommandReference-SETSESSIONAUTHORIZATION">SET SESSION AUTHORIZATION</h2><p>Sets the session role identifier and the current role identifier of the current session.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SET [SESSION | LOCAL] SESSION AUTHORIZATION rolename
SET [SESSION | LOCAL] SESSION AUTHORIZATION DEFAULT
RESET SESSION AUTHORIZATION</pre>
</div></div><h3 id="SQLCommandReference-Description.57">Description</h3><p>This command sets the session role identifier and the current role identifier of the current SQL-session context to be <em>rolename</em><span style="font-size: medium;"> </span>. The role name may be written as either an identifier or a string literal. Using this command, it is possible, for example, to temporarily become an unprivileged user and later switch back to being a superuser.</p><p align="LEFT">The session role identifier is initially set to be the (possibly authenticated) role name provided by the client. The current role identifier is normally equal to the session user identifier, but may change temporarily in the context of setuid functions and similar mechanisms; it can also be changed by SET ROLE. The current user identifier is relevant for permission checking.</p><p align="LEFT">The session user identifier may be changed only if the initial session user (the authenticated user) had the superuser privilege. Otherwise, the command is accepted only if it specifies the authenticated user name.</p><p align="LEFT">The DEFAULT and RESET forms reset the session and current user identifiers to be the originally authenticated user name. These forms may be executed by any user.</p><h3 id="SQLCommandReference-Parameters.53">Parameters</h3><pre>SESSION</pre><p style="margin-left: 30.0px;">Specifies that the command takes effect for the current session. This is the default.</p><pre>LOCAL</pre><p style="margin-left: 30.0px;">Specifies that the command takes effect for only the current transaction. After COMMIT or ROLLBACK, the session-level setting takes effect again. Note that SET LOCAL will appear to have no effect if it is executed outside of a transaction.</p><pre>rolename</pre><p style="margin-left: 30.0px;">The name of the role to assume.</p><pre>NONE<br/>RESET</pre><p style="margin-left: 30.0px;">Reset the session and current role identifiers to be that of the role used to log in.</p><h3 id="SQLCommandReference-Examples.50">Examples</h3><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SELECT SESSION_USER, CURRENT_USER;
session_user | current_user
--------------+--------------
peter | peter
SET SESSION AUTHORIZATION 'paul';
SELECT SESSION_USER, CURRENT_USER;
session_user | current_user
--------------+--------------
paul | paul</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.56">Compatibility</h3><p>The SQL standard allows some other expressions to appear in place of the literal rolename , but these options are not important in practice. HAWQ allows identifier syntax (“r<em>olename</em><span style="font-size: small;"> </span>”), which SQL does not. SQL does not allow this command during a transaction; HAWQ does not make this restriction. The</p><p align="LEFT">SESSION and LOCAL modifiers are a HAWQ extension, as is the RESET syntax.</p><h3 id="SQLCommandReference-SeeAlso.51">See Also</h3><p>SET ROLE</p><h2 id="SQLCommandReference-SHOW">SHOW</h2><p>Shows the value of a system configuration parameter.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SHOW configuration_parameter
SHOW ALL</pre>
</div></div><h3 id="SQLCommandReference-Description.58">Description</h3><p>SHOW will display the current settings of HAWQ system configuration parameters. These parameters can be set using the SET statement, or by editing the postgresql.conf configuration file of the HAWQ master. Note that some parameters viewable by SHOW are read-only — their values can be viewed but not set. See “Server Configuration Parameters”.</p><h3 id="SQLCommandReference-Parameters.54">Parameters</h3><pre>configuration_parameter</pre><p style="margin-left: 30.0px;">The name of a system configuration parameter. See “Server Configuration Parameters”.</p><pre>ALL</pre><p style="margin-left: 30.0px;">Shows the current value of all configuration parameters.</p><h3 id="SQLCommandReference-Examples.51">Examples</h3><p>Show the current setting of the parameter <em>search_path</em><span style="font-size: medium;"> </span>:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SHOW search_path;</pre>
</div></div><p align="LEFT">Show the current setting of all parameters:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">SHOW ALL;</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.57">Compatibility</h3><p>SHOW is a HAWQ extension.</p><h3 id="SQLCommandReference-SeeAlso.52">See Also</h3><p>SET, RESET</p><h2 id="SQLCommandReference-TRUNCATE">TRUNCATE</h2><p>Empties a table of all rows.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: actionscript3; gutter: false" style="font-size:12px;">TRUNCATE [TABLE] name [, ...] [CASCADE | RESTRICT]</pre>
</div></div><h3 id="SQLCommandReference-Description.59">Description</h3><p>TRUNCATE quickly removes all rows from a table or set of tables. This is most useful on large tables.</p><h3 id="SQLCommandReference-Parameters.55">Parameters</h3><pre>name</pre><p style="margin-left: 30.0px;">The name (optionally schema-qualified) of a table to be truncated.</p><pre>CASCADE</pre><p style="margin-left: 30.0px;">Since this key word applies to foreign key references (which are not supported in HAWQ) it has no effect.</p><pre>RESTRICT</pre><p style="margin-left: 30.0px;">Since this key word applies to foreign key references (which are not supported in HAWQ) it has no effect.</p><h3 id="SQLCommandReference-Notes.32">Notes</h3><p>Only the owner of a table may TRUNCATE it. TRUNCATE will not perform the following:</p><ul><li>Run any user-defined ON DELETE triggers that might exist for the tables.</li><li>Truncate any tables that inherit from the named table. Only the named table is truncated, not its child tables.</li></ul><h3 id="SQLCommandReference-Examples.52">Examples<span style="font-size: medium;"> </span></h3><p align="LEFT">Empty the table films:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">TRUNCATE films;</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.58">Compatibility</h3><p>There is no TRUNCATE command in the SQL standard.</p><h3 id="SQLCommandReference-SeeAlso.53">See Also</h3><p>DROP TABLE</p><h2 id="SQLCommandReference-VACUUM">VACUUM</h2><p>Garbage-collects and optionally analyzes a database.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">VACUUM [FULL] [FREEZE] [VERBOSE] [table]
VACUUM [FULL] [FREEZE] [VERBOSE] ANALYZE
              [table [(column [, ...] )]]</pre>
</div></div><h3 id="SQLCommandReference-Description.60">Description</h3><p>VACUUM reclaims storage occupied by deleted tuples. In normal HAWQ operation, tuples that are deleted or obsoleted by an update are not physically removed from their table; they remain present on disk until a VACUUM is done. Therefore it is necessary to don VACUUM periodically, especially on frequently-updated tables.</p><p>With no parameter, VACUUM processes every table in the current database. With a parameter, VACUUM processes only that table. VACUUM ANALYZE performs a VACUUM and then an ANALYZE for each selected table. This is a handy combination form for routine maintenance scripts. See ANALYZE for more details about its processing.</p><p>Plain VACUUM (without FULL) simply reclaims space and makes it available for re-use. This form of the command can operate in parallel with normal reading and writing of the table, as an exclusive lock is not obtained. VACUUM FULL does more extensive processing, including moving of tuples across blocks to try to compact the table to the minimum number of disk blocks. This form is much slower and requires an exclusive lock on each table while it is being processed.</p><h3 id="SQLCommandReference-Outputs.3">Outputs</h3><p>When VERBOSE is specified, VACUUM emits progress messages to indicate which table is currently being processed. Various statistics about the tables are printed as well.</p><h3 id="SQLCommandReference-Parameters.56">Parameters</h3><pre>FULL</pre><p style="margin-left: 30.0px;">Selects a full vacuum, which may reclaim more space, but takes much longer and exclusively locks the table.</p><p style="margin-left: 30.0px;"><strong>Warning:</strong> A VACUUM FULL is not recommended in HAWQ. See the “Notes” section.</p><pre>FREEZE</pre><p style="margin-left: 30.0px;">Specifying FREEZE is equivalent to performing VACUUM with the vacuum_freeze_min_age server configuration parameter set to zero. The FREEZE option is deprecated and will be removed in a future release. Set the parameter in the master postgresql.conf file instead.</p><pre>VERBOSE</pre><p style="margin-left: 30.0px;">Prints a detailed vacuum activity report for each table.</p><pre>ANALYZE</pre><p style="margin-left: 30.0px;">Updates statistics used by the planner to determine the most efficient way to execute a query.</p><pre>table</pre><p style="margin-left: 30.0px;">The name (optionally schema-qualified) of a specific table to vacuum. Defaults to all tables in the current database.</p><pre>column</pre><p style="margin-left: 30.0px;">The name of a specific column to analyze. Defaults to all columns.</p><h3 id="SQLCommandReference-Notes.33">Notes</h3><p>VACUUM cannot be executed inside a transaction block. Pivotal recommends that active production databases be vacuumed frequently (at least nightly), in order to remove expired rows. After adding or deleting a large number of rows, it may be a good idea to issue a VACUUM ANALYZE command for the affected table. This will update the system catalogs with the results of all recent changes, and allow the HAWQ query planner to make better choices in planning queries.</p><p>VACUUM causes a substantial increase in I/O traffic, which can cause poor performance for other active sessions. Therefore, it is advisable to vacuum the database at low usage times. Regular PostgreSQL has a separate optional server process called the <em>autovacuum </em>daemon, whose purpose is to automate the execution of VACUUM and ANALYZE commands. This feature is currently disabled in HAWQ.</p><p>Expired rows are held in what is called the <em>free space map</em><span style="font-size: medium;"> </span>. The free space map must be sized large enough to cover the dead rows of all tables in your database. If not sized large enough, space occupied by dead rows that overflow the free space map cannot be reclaimed by a regular VACUUM command.</p><p><em><span style="font-size: small;"><span style="font-size: medium;"> </span></span></em></p><p align="LEFT">A VACUUM FULL will reclaim all expired row space, but is a very expensive operation and may take an unacceptably long time to finish on large, distributed HAWQ tables. If you do get into a situation where the free space map has overflowed, it may be more timely to recreate the table with a CREATE TABLE AS statement and drop the old table.</p><p>A VACUUM FULL is not recommended in HAWQ. It is best to size the free space map appropriately. The free space map is configured with the following server configuration parameters:</p><ul><li>max_fsm_pages</li><li>max_fsm_relations</li></ul><h3 id="SQLCommandReference-Examples.53">Examples</h3><p>Vacuum all tables in the current database:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">VACUUM;</pre>
</div></div><p align="LEFT">Vacuum a specific table only:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">VACUUM mytable;</pre>
</div></div><p align="LEFT">Vacuum all tables in the current database and collect statistics for the query planner:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: sql; gutter: false" style="font-size:12px;">VACUUM ANALYZE;</pre>
</div></div><h3 id="SQLCommandReference-Compatibility.59">Compatibility</h3><p>There is no VACUUM statement in the SQL standard.</p><h3 id="SQLCommandReference-SeeAlso.54">See Also</h3><p>ANALYZE </p><p style="margin-left: 30.0px;"> </p>
</div></div>


            </div><!-- end of body-container content-->
          </div><!-- end of container -->
        </div><!--end of container-fluid-->
      </div><!--end of main-wrap-->

      <div class="site-footer desktop-only">
          <div class="container-fluid">
              <div class="site-footer-links">
                  <span class="version"><a href='/'>Pivotal Documentation</a></span>
                  <span>&copy;
                      <script>
                          var d = new Date();
                          document.write(d.getFullYear());
                      </script>
                      <a href='http://gopivotal.com'>Pivotal Software</a> Inc. All Rights Reserved.
                  </span>
              </div>
          </div>
      </div>

      <script type="text/javascript">
          (function() {
              var didInit = false;
              function initMunchkin() {
                  if(didInit === false) {
                      didInit = true;
                      Munchkin.init('625-IUJ-009');
                  }
              }
              var s = document.createElement('script');
              s.type = 'text/javascript';
              s.async = true;
              s.src = document.location.protocol + '//munchkin.marketo.net/munchkin.js';
              s.onreadystatechange = function() {
                  if (this.readyState == 'complete' || this.readyState == 'loaded') {
                      initMunchkin();
                  }
              };
              s.onload = initMunchkin;
              document.getElementsByTagName('head')[0].appendChild(s);
          })();
      </script>
  </div><!--end of viewport-->
  <div id="scrim"></div>
</body>
</html>