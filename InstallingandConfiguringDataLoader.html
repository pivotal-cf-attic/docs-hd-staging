
<!doctype html>
<html>
<head>
  <meta charset="utf-8">

  <!-- Always force latest IE rendering engine or request Chrome Frame -->
  <meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible">

  <!-- REPLACE X WITH PRODUCT NAME -->
  <title>Installing and Configuring DataLoader | Pivotal HD Docs | Pivotal HD Docs</title>
  <!-- Local CSS stylesheets -->
  <link href="stylesheets/master.css" media="screen,print" rel="stylesheet" type="text/css" />
  <link href="stylesheets/breadcrumbs.css" media="screen,print" rel="stylesheet" type="text/css" />
  <link href="stylesheets/search.css" media="screen,print" rel="stylesheet" type="text/css" />
  <link href="stylesheets/portal-style.css" media="screen,print" rel="stylesheet" type="text/css" />
  <link href="stylesheets/printable.css" media="print" rel="stylesheet" type="text/css" /> 
  <!-- Confluence HTML stylesheet -->
  <link href="stylesheets/site.css" media="screen,print" rel="stylesheet"  type="text/css" /> 
  <!-- Left-navigation code -->
  <!-- http://www.designchemical.com/lab/jquery-vertical-accordion-menu-plugin/examples/# -->
  <link href="stylesheets/dcaccordion.css" rel="stylesheet" type="text/css" />
  <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.4.2/jquery.min.js" type="text/javascript"></script>
  <script src='javascripts/jquery.cookie.js' type="text/javascript"></script>
  <script src='javascripts/jquery.hoverIntent.minified.js' type="text/javascript"></script>
  <script src='javascripts/jquery.dcjqaccordion.2.7.min.js' type="text/javascript"></script>
  <script type="text/javascript">
                    $(document).ready(function($){
					$('#accordion-1').dcAccordion({
						eventType: 'click',
						autoClose: true,
						saveState: true,
						disableLink: false,
						speed: 'fast',
						classActive: 'test',
						showCount: true
					});
					});
  </script>
  <link href="stylesheets/skins/graphite.css" rel="stylesheet" type="text/css" />
  <link href="stylesheets/skins/grey.css" rel="stylesheet" type="text/css" /> 
  <!-- End left-navigation code -->
  <script src="javascripts/all.js" type="text/javascript"></script>
  <link href='http://www.gopivotal.com/misc/favicon.ico' rel='shortcut icon'>
</head>

<body class="pivotalcf pivotalcf_getstarted pivotalcf_getstarted_index">
  <div class="viewport">
    <div class="mobile-navigation--wrapper mobile-only">
      <div class="navigation-drawer--container">
        <div class="navigation-item-list">
          <div class="navbar-link active">
            <a href="http://gopivotal.com">
              Home
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
          <div class="navbar-link">
            <a href="http://gopivotal.com/paas">
              PaaS
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
          <div class="navbar-link">
            <a href="http://gopivotal.com/big-data">
              Big Data
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
          <div class="navbar-link">
            <a href="http://gopivotal.com/agile">
              Agile
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
          <div class="navbar-link">
            <a href="http://gopivotal.com/support">
              Help &amp; Support
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
          <div class="navbar-link">
            <a href="http://gopivotal.com/products">
              Products
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
          <div class="navbar-link">
            <a href="http://gopivotal.com/solutions">
              Solutions
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
          <div class="navbar-link">
            <a href="http://gopivotal.com/partners">
              Partners
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
        </div>
      </div>
      <div class="mobile-nav">
        <div class="nav-icon js-open-nav-drawer">
          <i class="icon-reorder"></i>
        </div>
        <div class="header-center-icon">
          <a href="http://gopivotal.com">
            <div class="icon icon-pivotal-logo-mobile"></div>
          </a>
        </div>
      </div>
    </div>

    <div class='wrap'>
      <script src="//use.typekit.net/clb0qji.js" type="text/javascript"></script>
      <script type="text/javascript">
          try {
              Typekit.load();
          } catch (e) {
          }
      </script>
      <script type="text/javascript">
          document.domain = "gopivotal.com";
      </script>
      <div id="search-dropdown-box">
        <div class="search-dropdown--container js-search-dropdown">
          <div class="container-fluid">
            <div class="close-menu-large"><img src="http://www.gopivotal.com/sites/all/themes/gopo13/images/icon-close.png" /></div>
            <div class="search-form--container">
              <div class="form-search">
                <div class='gcse-search'></div>
                <script src="http://www.google.com/jsapi" type="text/javascript"></script>
                <script src="javascripts/cse.js" type="text/javascript"></script>
              </div>
            </div>
          </div>
        </div>
      </div>

      <header class="navbar desktop-only" id="nav">
        <div class="navbar-inner">
            <div class="container-fluid">
                <div class="pivotal-logo--container">
                    <a class="pivotal-logo" href="http://gopivotal.com"><span></span></a>
                </div>

                <ul class="nav pull-right">
                    <li class="navbar-link">
                        <a href="http://www.gopivotal.com/paas" id="paas-nav-link">PaaS</a>
                    </li>
                    <li class="navbar-link">
                        <a href="http://www.gopivotal.com/big-data" id="big-data-nav-link">BIG DATA</a>
                    </li>
                    <li class="navbar-link">
                        <a href="http://www.gopivotal.com/agile" id="agile-nav-link">AGILE</a>
                    </li>
                    <li class="navbar-link">
                        <a href="http://www.gopivotal.com/oss" id="oss-nav-link">OSS</a>
                    </li>
                    <li class="nav-search">
                        <a class="js-search-input-open" id="click-to-search"><span></span></a>
                    </li>
                </ul>
            </div>
            <a href="http://www.gopivotal.com/contact">
                <img id="get-started" src="http://www.gopivotal.com/sites/all/themes/gopo13/images/get-started.png">
            </a>
        </div>
      </header>
      <div class="main-wrap">
        <div class="container-fluid">

          <!-- Google CSE Search Box -->
          <div id='docs-search'>
              <gcse:search></gcse:search>
          </div>
          
          <div id='all-docs-link'>
            <a href="http://docs.gopivotal.com/">All Documentation</a>
          </div>
          
          <div class="container">
            <div id="sub-nav" class="nav-container">              
              
              <!-- Collapsible left-navigation-->
			  <ul class="accordion"  id="accordion-1">
				  <!-- REPLACE <li/> NODES-->

                        <li>
                <a href="index.html">Pivotal HD</a>

                            <ul>
                    <li>
                <a href="PHDEnterprise1.1.1ReleaseNotes.html">PHD Enterprise 1.1.1 Release Notes</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PHDServiceBrokerforPivotalCFv1.0.0.0.html">PHD Service Broker for Pivotal CF v1.0.0.0</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PHDInstallationandAdministration.html">PHD Installation and Administration</a>

                            <ul>
                    <li>
                <a href="OverviewofPHD.html">Overview of PHD</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="InstallingPHDUsingtheCLI.html">Installing PHD Using the CLI</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="UpgradingPHDUsingtheCLI.html">Upgrading PHD Using the CLI</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="AdministeringPHDUsingtheCLI.html">Administering PHD Using the CLI</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PHDFAQFrequentlyAskedQuestions.html">PHD FAQ (Frequently Asked Questions)</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PHDTroubleshooting.html">PHD Troubleshooting</a>

                    </li>
            </ul>
            </li>
            </ul>
                    <ul>
                    <li>
                <a href="StackandToolsReference.html">Stack and Tools Reference</a>

                            <ul>
                    <li>
                <a href="OverviewofApacheStackandPivotalComponents.html">Overview of Apache Stack and Pivotal Components</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PHD1.1.1Stack-RPMPackage.html">PHD 1.1.1 Stack - RPM Package</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PHD1.1.1Stack-BinaryPackage.html">PHD 1.1.1 Stack - Binary Package</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PHDMR11.1Stack-RPMPackage.html">PHD MR1 1.1 Stack - RPM Package</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PHDMR11.1Stack-BinaryPackage.html">PHD MR1 1.1 Stack - Binary Package</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PHDStack-OtherComponents.html">PHD Stack - Other Components</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="USSUnifiedStorageSystem.html">USS (Unified Storage System)</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HVEHadoopVirtualizationExtensions.html">HVE (Hadoop Virtualization Extensions)</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="Security.html">Security</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="ManuallyUpgradingPHDfrom1.1to1.1.1-RPM.html">Manually Upgrading PHD from 1.1 to 1.1.1 - RPM</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="ManuallyUpgradingPHDfrom1.1to1.1.1-Binary.html">Manually Upgrading PHD from 1.1 to 1.1.1 - Binary</a>

                    </li>
            </ul>
            </li>
            </ul>
                    <ul>
                    <li>
                <a href="DataLoaderInstallationandUsage.html">DataLoader Installation and Usage</a>

                            <ul>
                    <li>
                <a href="OverviewofDataLoader.html">Overview of DataLoader</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="InstallingandConfiguringDataLoader.html">Installing and Configuring DataLoader</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="UsingDataLoader.html">Using DataLoader</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="LoadingFilesandPushStreamsintoHAWQUsingPXF.html">Loading Files and Push Streams into HAWQ Using PXF</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="DataLoaderCommandLineInterface.html">DataLoader Command Line Interface</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="DataLoaderCopyStrategyandTransferPolicy.html">DataLoader Copy Strategy and Transfer Policy</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="JobTransferSpecification.html">Job (Transfer) Specification</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="DataStores.html">Data Stores</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="ConfiguringFlumeforDataLoaderPushStreaming.html">Configuring Flume for DataLoader Push Streaming</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="DataLoaderInstallationfromBinaries.html">DataLoader Installation from Binaries</a>

                    </li>
            </ul>
            </li>
            </ul>
            </li>
                        <li>
                <a href="PIVOTALCOMMANDCENTER.html">PIVOTAL COMMAND CENTER</a>

                            <ul>
                    <li>
                <a href="PCC2.1.1ReleaseNotes.html">PCC 2.1.1 Release Notes</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PCCUserGuide.html">PCC User Guide</a>

                            <ul>
                    <li>
                <a href="PCCOverview.html">PCC Overview</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="InstallingPCC.html">Installing PCC</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="UsingPCC.html">Using PCC</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="CreatingaYUMEPELRepository.html">Creating a YUM EPEL Repository</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="CommandLineReference.html">Command Line Reference</a>

                    </li>
            </ul>
            </li>
            </ul>
            </li>
                        <li>
                <a href="PivotalAdvancedDatabaseServices.html">Pivotal Advanced Database Services</a>

                            <ul>
                    <li>
                <a href="PADS1.1.4ReleaseNotes.html">PADS 1.1.4 Release Notes</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQInstallation.html">HAWQ Installation</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQAdministration.html">HAWQ Administration</a>

                            <ul>
                    <li>
                <a href="HAWQOverview.html">HAWQ Overview</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQQueryProcessing.html">HAWQ Query Processing</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="QueryingData.html">Querying Data</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="ConfiguringClientAuthentication.html">Configuring Client Authentication</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="KerberosAuthentication.html">Kerberos Authentication</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQInputFormatforMapReduce.html">HAWQ InputFormat for MapReduce</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="SQLCommandReference.html">SQL Command Reference</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="ManagementUtilityReference.html">Management Utility Reference</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="ClientUtilityReference.html">Client Utility Reference</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="ServerConfigurationParameters.html">Server Configuration Parameters</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQEnvironmentVariables.html">HAWQ Environment Variables</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQDataTypes.html">HAWQ Data Types</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="MADlibReferences.html">MADlib References</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="hawq_toolkitReference.html">hawq_toolkit Reference</a>

                    </li>
            </ul>
            </li>
            </ul>
                    <ul>
                    <li>
                <a href="PivotalExtensionFrameworkPXF.html">Pivotal Extension Framework (PXF)</a>

                            <ul>
                    <li>
                <a href="PXFInstallationandAdministration.html">PXF Installation and Administration</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PXFExternalTableandAPIReference.html">PXF External Table and API Reference</a>

                    </li>
            </ul>
            </li>
            </ul>
            </li>
              </ul>        
              
            </div><!--end of sub-nav-->
            <div class="body-container content">

              <!-- Python script replaces main content -->
			  <div id ="main"><h1>Installing and Configuring DataLoader</h1><div class="wiki-content group" id="main-content">
<p>DataLoader can manage a dynamic pool of loader machines for fast ingestion of big data. DataLoader works with both Hadoop 1.x (MR1) and Hadoop 2.x (Yarn) and can leverage them as the resource manager and job scheduler.</p><p><style type="text/css">/*<![CDATA[*/
div.rbtoc1390012351780 {padding: 0px;}
div.rbtoc1390012351780 ul {list-style: disc;margin-left: 0px;}
div.rbtoc1390012351780 li {margin-left: 0px;padding-left: 0px;}

/*]]>*/</style><div class="toc rbtoc1390012351780">
<ul class="toc-indentation">
<li><a href="#InstallingandConfiguringDataLoader-PackagesandInstallers"><span style="color: rgb(0,0,0);font-size: 20.0px;line-height: 1.5;">Packages and Installers</span></a>
<ul class="toc-indentation">
<li><a href="#InstallingandConfiguringDataLoader-RPMpackages:">RPM packages:</a>
<ul class="toc-indentation">
<li><a href="#InstallingandConfiguringDataLoader-RPMPackagesandDeployment:">RPM Packages and Deployment:</a></li>
</ul>
</li>
<li><a href="#InstallingandConfiguringDataLoader-InstallerScripts">Installer Scripts</a></li>
</ul>
</li>
<li><a href="#InstallingandConfiguringDataLoader-Prerequisites">Prerequisites</a>
<ul class="toc-indentation">
<li><a href="#InstallingandConfiguringDataLoader-InstallationofUserAccount"><span style="font-size: 20.0px;line-height: 1.5;">Installation of User Account</span></a>
<ul class="toc-indentation">
<li><a href="#InstallingandConfiguringDataLoader-CreateanInstallationUserAccount">Create an Installation User Account</a></li>
</ul>
</li>
<li><a href="#InstallingandConfiguringDataLoader-PivotalHDandZookeeperClusterInstallation">Pivotal HD and Zookeeper Cluster Installation</a></li>
<li><a href="#InstallingandConfiguringDataLoader-InstalltheJDK"><span style="color: rgb(0,0,0);font-size: 20.0px;line-height: 1.5;">Install the JDK</span></a></li>
</ul>
</li>
<li><a href="#InstallingandConfiguringDataLoader-Installation">Installation</a>
<ul class="toc-indentation">
<li><a href="#InstallingandConfiguringDataLoader-DownloadandextracttheDataLoaderfiles">Download and extract the DataLoader files</a></li>
<li><a href="#InstallingandConfiguringDataLoader-InstallDataLoader"><span style="line-height: 1.4285715;"><span style="color: rgb(0,0,0);font-size: 16.0px;line-height: 1.5625;">Install DataLoader</span> </span></a></li>
<li><a href="#InstallingandConfiguringDataLoader-UninstallDataLoader"><span style="color: rgb(0,0,0);font-size: 16.0px;line-height: 1.5625;">Uninstall DataLoader</span></a></li>
</ul>
</li>
<li><a href="#InstallingandConfiguringDataLoader-ConfiguringDataLoader"><span style="color: rgb(0,0,0);font-size: 20.0px;line-height: 1.5;">Configuring DataLoader</span></a>
<ul class="toc-indentation">
<li><a href="#InstallingandConfiguringDataLoader-StartandStopDataLoaderservices"><span style="background-color: transparent;line-height: 1.4285715;">Start and Stop DataLoader services</span></a></li>
<li><a href="#InstallingandConfiguringDataLoader-StartDataLoadermanagerdirectlyusingstartupscript">Start DataLoader manager directly using startup script</a></li>
<li><a href="#InstallingandConfiguringDataLoader-UsingtheLinuxserviceutilitytostart/stopDataLoaderservices">Using the Linux service utility to start/stop DataLoader services</a></li>
<li><a href="#InstallingandConfiguringDataLoader-AdvancedConfigurations"><span style="color: rgb(0,0,0);font-size: 20.0px;line-height: 1.5;">Advanced Configurations</span></a></li>
<li><a href="#InstallingandConfiguringDataLoader-ConfigureDataLoaderCLI"><span style="color: rgb(0,0,0);font-size: 20.0px;line-height: 1.5;">Configure DataLoader CLI</span></a></li>
</ul>
</li>
</ul>
</div></p><p><strong>Note:</strong> A properly-configured Hadoop cluster is required, and HDFS, MapReduce, and Zookeeper must be available for DataLoader to use. For Hadoop/Zookeeper deployment instructions using the Pivotal HD distribution, refer to the Pivotal HD Installation and Administrator Guide.</p><p>This chapter covers installation and configuration of the RPM packages. For binary tarball installation, refer to <a href="DataLoaderInstallationfromBinaries.html">DataLoader Installation from Binaries</a>.</p><h2 id="InstallingandConfiguringDataLoader-PackagesandInstallers"><span style="color: rgb(0,0,0);font-size: 20.0px;line-height: 1.5;">Packages and Installers</span></h2><p>DataLoader is distributed as either RPM packages, or as a binary distribution. The installation procedures are similar. Use the installation procedure that is specific to your distribution. Binary distribution installation can be found in the section: <em>DataLoader Binary Installatiion</em>.</p><h3 id="InstallingandConfiguringDataLoader-RPMpackages:">RPM packages:</h3><p>DataLoader uses two RPM packages that are deployed to the Client and Master, nodes, which can be the same. No worker installation is needed; required files are put in Hadoop DistributedCache for use at runtime.</p><h4 id="InstallingandConfiguringDataLoader-RPMPackagesandDeployment:">RPM Packages and Deployment:</h4><div class="table-wrap"><table class="confluenceTable"><tbody><tr><td class="highlight-blue confluenceTd" data-highlight-colour="blue"><p>Package Name</p></td><td class="highlight-blue confluenceTd" data-highlight-colour="blue"><p>Description</p></td><td class="highlight-blue confluenceTd" data-highlight-colour="blue"><p>Deployment Nodes</p></td></tr><tr><td class="confluenceTd"><p>dataloader-cli-2.0.4-nn.x86_64.rpm</p></td><td class="confluenceTd"><p>dataloader-cli-2.0.4-nn.x86_64.rpm provides essential files to setup dataloader client.</p></td><td class="confluenceTd"><p>Client node</p></td></tr><tr><td class="confluenceTd"><p>dataloader-service-2.0.4-nn.x86_64.rpm</p></td><td class="confluenceTd"><p>dataloader-service-2.0.4-nn pr.x86_64.rpmovides essential files to setup dataloader master.</p></td><td class="confluenceTd"><p>Master node</p></td></tr></tbody></table></div><p><strong>Note:</strong> The nn in Package Name is the RPM build number.</p><h3 id="InstallingandConfiguringDataLoader-InstallerScripts">Installer Scripts</h3><ul><li>install_dl.sh</li><li>dl-cluster.conf.template</li></ul><h2 id="InstallingandConfiguringDataLoader-Prerequisites">Prerequisites</h2><h3 id="InstallingandConfiguringDataLoader-InstallationofUserAccount"><span style="font-size: 20.0px;line-height: 1.5;">Installation of User Account</span></h3><p>In most customer environments, root account password and information is strictly controlled. To install DataLoader without using root account, use the process detailed below.</p><h4 id="InstallingandConfiguringDataLoader-CreateanInstallationUserAccount">Create an Installation User Account</h4><ol><li>Create a dladmin account on the machines where you will install DataLoader service and client. This dladmin account will be used as a system administrator account for installing DataLoader.</li><li>After the dladmin has been created, give it sudo permissions.</li></ol><div class="table-wrap"><table class="confluenceTable"><tbody><tr><td class="highlight-blue confluenceTd" data-highlight-colour="blue"># vi /etc/sudoers</td></tr></tbody></table></div><p style="margin-left: 30.0px;">This will take you to a text editor with an /etc/sudoers file already opened. Add the following line:</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><td class="highlight-blue confluenceTd" data-highlight-colour="blue">dladmin ALL=(ALL) NOPASSWD: ALL</td></tr></tbody></table></div><p style="margin-left: 30.0px;">and save the file.</p><h3 id="InstallingandConfiguringDataLoader-PivotalHDandZookeeperClusterInstallation">Pivotal HD and Zookeeper Cluster Installation</h3><p>To install Pivotal HD and the Zookeeper cluster, refer to the Pivotal HD Enterprise Installation and Administrator Guide for deployment instructions.<br/>Make sure you include the following in your HDFS configuration.</p><p><br/>For HDFS 1.x and HDFS 2.x:</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><td class="highlight-blue confluenceTd" data-highlight-colour="blue"><p>&lt;configuration&gt;<br/>&lt;property&gt;<br/>&lt;name&gt;dfs.support.append&lt;/name&gt;<br/>&lt;value&gt;true&lt;/value&gt;<br/>&lt;/property&gt;<br/>&lt;/configuration&gt;</p></td></tr></tbody></table></div><h3 id="InstallingandConfiguringDataLoader-InstalltheJDK"><span style="color: rgb(0,0,0);font-size: 20.0px;line-height: 1.5;">Install the JDK</span></h3><p>Install the JDK: Download and install the Oracle JDK1.6 (Java SE6 or JDK 6) from:</p><p><a class="external-link" href="http://www.oracle.com/technetwork/java/javase/downloads/index.html" rel="nofollow">http://www.oracle.com/technetwork/java/javase/downloads/index.html</a><br/>(<a class="external-link" href="http://www.oracle.com/technetwork/java/archive-139210.html" rel="nofollow">http://www.oracle.com/technetwork/java/archive-139210.html</a>)</p><p><span style="line-height: 1.4285715;">After installing JDK, set the JAVA_HOME environment variable referring to where you installed JDK. On a typical Linux installation with Oracle JDK 1.6, the value of this variable should be /usr/java/default/.</span></p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><td class="highlight-blue confluenceTd" data-highlight-colour="blue">export JAVA_HOME=/usr/java/default/</td></tr></tbody></table></div><p>Add $JAVA_HOME/bin into your PATH environment variable. On a Linux platform with bash shell, add the following lines into the file ~/.bashrc:</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><td class="highlight-blue confluenceTd" data-highlight-colour="blue">export PATH=$JAVA_HOME/bin:$PATH</td></tr></tbody></table></div><h2 id="InstallingandConfiguringDataLoader-Installation">Installation</h2><h3 id="InstallingandConfiguringDataLoader-DownloadandextracttheDataLoaderfiles">Download and extract the DataLoader files</h3><p><span style="line-height: 1.4285715;">Download and copy the PHDTools stack to /home/dladmin/ on the host where you want to install DataLoader. Make sure the Tarball has read permission for the user 'dladmin'.</span></p><p><span style="line-height: 1.4285715;"> </span>Extract the tarball:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[root@hdp2-w17 dladmin]# chown dladmin:dladmin PHDTools-1.0.1-xx.tar.gz
[root@hdp2-w17 dladmin]# ls -lrt PHDTools-1.0.1-xx.tar.gz
-rw-r--r-- 1 dladmin dladmin 246080597 Jun 24 11:23 PHDTools-1.0.1-xx.tar.gz
[root@hdp2-w17 dladmin]# sudo su - dladmin
[dladmin@hdp2-w17 ~]$ tar xzvf PHDTools-1.0.1-xx.tar.gz
[dladmin@hdp2-w17 ~]$ ls -lrt PHDTools-1.0.1-xx
total 12
drwxrwxr-x 3 dladmin dladmin 4096 Jun 24 11:32 uss
drwxrwxr-x 3 dladmin dladmin 4096 Jun 24 11:32 dataloader
drwxrwxr-x 3 dladmin dladmin 4096 Jun 24 11:33 spring-data-hadoop
[dladmin@hdp2-w17 ~]$ cd PHDTools-1.0.1-xx/dataloader/rpm/
[dladmin@hdp2-w17 rpm]$ ls -lrt
total 213224
-rw-r--r-- 1 dladmin dladmin 199662368 Jun 24 11:32 dataloader-service-2.0.4-35.x86_64.rpm
-rw-r--r-- 1 dladmin dladmin 18647092 Jun 24 11:32 dataloader-cli-2.0.4-35.x86_64.rpm
-r-xr-xr-x 1 dladmin dladmin 5251 Jun 24 11:33 install_dl.sh
-r--r--r-- 1 dladmin dladmin 167 Jun 24 11:33 dl-cluster.conf.template
-rw-rw-r-- 1 dladmin dladmin 69 Jun 24 11:33 dataloader-cli-2.0.4-35.x86_64.rpm.md5
-rw-rw-r-- 1 dladmin dladmin 48 Jun 24 11:33 install_dl.sh.md5
-rw-rw-r-- 1 dladmin dladmin 59 Jun 24 11:33 dl-cluster.conf.template.md5
-rw-rw-r-- 1 dladmin dladmin 73 Jun 24 11:33 dataloader-service-2.0.4-35.x86_64.rpm.md5</pre>
</div></div><p>Note: xx in the package name is the package build number.</p><h3 id="InstallingandConfiguringDataLoader-InstallDataLoader"><span style="line-height: 1.4285715;"><span style="color: rgb(0,0,0);font-size: 16.0px;line-height: 1.5625;">Install DataLoader</span> </span></h3><p>Run following commands as user "dladmin" or any user that has root privileges:</p><p><span style="line-height: 1.4285715;"> </span></p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[dladmin@hdp2-w17 ~]./install_dl.sh -i
</pre>
</div></div><p><span style="line-height: 1.4285715;">DataLoader service and the CLI tool will be installed at the default location /usr/local/gphd/dataloader-2.0.4/.</span></p><p>After installation, DataLoader can be started in pseudo distributed mode without any further configuration.</p><h3 id="InstallingandConfiguringDataLoader-UninstallDataLoader"><span style="color: rgb(0,0,0);font-size: 16.0px;line-height: 1.5625;">Uninstall DataLoader</span></h3><p><span style="line-height: 1.4285715;">There are two uninstall options. </span><span style="line-height: 1.4285715;">One option preserves customer data, and the other </span><span style="line-height: 1.4285715;">uninstalls both DataLoader and customer data.</span></p><p>To uninstall DataLoader but preserve customer data, use the command:</p><p><span style="line-height: 1.4285715;"> </span></p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[dladmin@hdp2-w17 ~]./install_dl.sh -u
</pre>
</div></div><p><span style="line-height: 1.4285715;"> </span><span style="line-height: 1.4285715;">To uninstall DataLoader and remove both binary and customer data including configuration data, enter the command:</span></p><p><span style="line-height: 1.4285715;"> </span></p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[dladmin@hdp2-w17 ~]./install_dl.sh -u -c
</pre>
</div></div><h2 id="InstallingandConfiguringDataLoader-ConfiguringDataLoader"><span style="color: rgb(0,0,0);font-size: 20.0px;line-height: 1.5;">Configuring DataLoader</span></h2><p><span style="line-height: 1.4285715;"> </span><span style="line-height: 1.4285715;">Modify the file dataloader-env.sh to reflect your Pivotal HD and Zookeeper cluster configuration. Either host names or their IP addresses can be used. This should be done as root (enter command proceeded by sudo.)</span></p><p>The file is located in /usr/local/gphd/dataloader-2.0.4/conf.</p><p>For pseudo mode, edit the file in /usr/local/gphd/dataloader-2.0.4/conf/pseudo/</p><p><span style="line-height: 1.4285715;"> </span></p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">vi /usr/local/gphd/dataloader-2.0.0/conf/dataloader-env.sh
</pre>
</div></div><p><span style="line-height: 1.4285715;"> </span><span style="line-height: 1.4285715;">The following table shows the basic parameters that must be modified to run DataLoader in distributed mode:</span></p><p><span style="line-height: 1.4285715;"> </span></p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh"><p>Parameter</p></th><th class="confluenceTh"><p>Explanation</p></th><th class="confluenceTh"><p>Default value</p></th><th class="confluenceTh"><p>Options</p></th></tr><tr><td class="confluenceTd" colspan="1"><p>DATALOADER_START_MODE</p></td><td class="confluenceTd" colspan="1"><p>This parameter controls the start mode of the DataLoader. Change this parameter if you want to start DataLoader in distributed mode;<br/>Note: If you wish to start DataLoader in pseudo distributed mode, please do not change the parameters.</p></td><td class="confluenceTd" colspan="1"> pseudo</td><td class="confluenceTd" colspan="1"> pseudo, distributed</td></tr><tr><td class="confluenceTd"><p>DATALOADER_ZK_QUORUM</p></td><td class="confluenceTd"><p>List of Zookeeper nodes in comma separated format. This list must be the same as used in Zookeeper cluster configuration, (in the “zk.cfg” file).</p></td><td class="confluenceTd"><p>Must be specified</p></td><td class="confluenceTd"><p>N/A</p></td></tr><tr><td class="confluenceTd"><p>DATALOADER_SERVICE_IP</p></td><td class="confluenceTd"><p>IP address the services will bind to ("localhost" cannot be used).</p></td><td class="confluenceTd"><p>Must be specified except for running standalone mode, and CLI is installed with service node</p></td><td class="confluenceTd"><p>N/A</p></td></tr><tr><td class="confluenceTd"><p>EXECUTOR_TYPE</p></td><td class="confluenceTd"><p>Hadoop cluster version that DataLoader is running on. DataLoader supports Hadoop 1.0 (GPHD 1.2) and Hadoop 2.0(PHD 1.x) . Other distributions, including Apache, have not been not tested.</p></td><td class="confluenceTd"><p>mrv2</p></td><td class="confluenceTd"><p>mrv1/mrv2</p></td></tr><tr><td class="confluenceTd"><p>HADOOP_INSTALL</p></td><td class="confluenceTd"><p>The Hadoop installation directory. DataLoader uses it to set the classpath. Make sure this value is set correctly.</p></td><td class="confluenceTd"><p>${HADOOP_INSTALL} <br class="atl-forced-newline"/> If user does not export this shell env variable or value is empty, it must be specified manually <br class="atl-forced-newline"/><br class="atl-forced-newline"/></p></td><td class="confluenceTd"><p>N/A</p></td></tr><tr><td class="confluenceTd"><p>HADOOP_CONF_DIR</p></td><td class="confluenceTd"><p>The Hadoop configuration directory. Set this value if you are using install_worker to install <br class="atl-forced-newline"/> workers. Otherwise, it is optional</p></td><td class="confluenceTd"><p>${HADOOP_CONF_DIR}</p><p>If user does not export this shell env variable or value is empty, it must be specified manually</p></td><td class="confluenceTd"><p> </p></td></tr><tr><td class="confluenceTd" colspan="1">DATALOADER_METRICS_REPORTING</td><td class="confluenceTd" colspan="1">Whether metrics report should be enabled. If not enabled, progress information will not be available.</td><td class="confluenceTd" colspan="1">true</td><td class="confluenceTd" colspan="1">true, false</td></tr><tr><td class="confluenceTd"><p>DATALOADER_EXECUTOR_CAPACITY</p></td><td class="confluenceTd"><p>The total number of slots(MRv1) or containers (MRv2) that are available to DataLoader. This number, called “workers,” is set according to expected number of stream jobs, batch jobs, and capacity in the HDFS cluster. As an example, the number would be 20 on a 10 node Hadoop cluster to support up to 10 stream jobs, and leave capacity for copying 10s of TB of data in multiple simultaneous batch jobs. You must set this value for DataLoader to run correctly.</p></td><td class="confluenceTd"><p>No default value, must be specified except for standalone mode.</p></td><td class="confluenceTd"><p> </p></td></tr><tr><td class="confluenceTd" colspan="1">DATALOADER_SYSTEM_DIR</td><td class="confluenceTd" colspan="1">This is a value pointer to a directory on the executor's corresponding HDFS. This folder is used by DataLoader as its working directory; it should be writable by the "dataloader" user; This folder should be created and grant edwrite access to the "dataloader" user attempting to start DataLoader service in distributed mode.</td><td class="confluenceTd" colspan="1">/datsadir/</td><td class="confluenceTd" colspan="1">N/A</td></tr><tr><td class="confluenceTd"><p>DATALOADER_DATA_DIR</p></td><td class="confluenceTd"><p>The location to put DataLoader data files.</p></td><td class="confluenceTd"><p>For RPM installation, it is set in /etc/default/dataloader, value is: /var/lib/gphd/dataloader. <br class="atl-forced-newline"/> In other case, it is ${DATALOADER_HOME}/data</p></td><td class="confluenceTd"><p> </p></td></tr><tr><td class="confluenceTd"><p>DATALOADER_LOG_DIR</p></td><td class="confluenceTd"><p>The location to put the DataLoader log files.</p></td><td class="confluenceTd"><p>For RPM installation, it is set in /etc/default/dataloader, value is: /var/log/gphd/dataloader. <br class="atl-forced-newline"/> In other case, it is set to: ${DATALOADER_HOME}/log</p></td><td class="confluenceTd"><p> </p></td></tr></tbody></table></div><p><span style="line-height: 1.4285715;"> </span><span style="line-height: 1.4285715;">Do not modify the following parameters.</span></p><ul><li>DATALOADER_HOME</li><li>DATALOADER_CONF_DIR</li><li>ZK_RUNTIME_DIR</li><li>ENGINE_HOME</li></ul><h3 id="InstallingandConfiguringDataLoader-StartandStopDataLoaderservices"><span style="background-color: transparent;line-height: 1.4285715;">Start and Stop DataLoader services</span></h3><p>Change file ownership for the Linux account login. Change the permission of the file /etc/shadow to be readable by the group root:</p><p> </p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">root# chmod g+r /etc/shadow
</pre>
</div></div><p> </p><h3 id="InstallingandConfiguringDataLoader-StartDataLoadermanagerdirectlyusingstartupscript">Start DataLoader manager directly using startup script</h3><ol><li><p>Login to the DataLoader master node as dladmin, and go to the /bin directory of the DataLoader installed location:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">$su - dladmin
$cd /usr/local/gphd/dataloader-2.0.1/bin/
</pre>
</div></div><p>Note: to reset the default dlamin user password, login as root and use "passwd dladmin" to change password</p></li><li><p>To start DataLoader service:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">$sudo -u dataloader ./dataloader.sh start
</pre>
</div></div><p>Note: To control DataLoader to start in pseudo/distributed mode, please change the "DATALOADER_START_MODE" property in the dataloader-env.sh file;</p></li><li><p>To stop DataLoader service:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">$sudo -u dataloader ./dataloader.sh stop
</pre>
</div></div></li></ol><p>Note: In the above command, <em>dataloader</em> is a service the user created during installation.</p><h3 id="InstallingandConfiguringDataLoader-UsingtheLinuxserviceutilitytostart/stopDataLoaderservices">Using the Linux service utility to start/stop DataLoader services</h3><p>Users can also use the Linux service utility to start/stop DataLoader services. </p><p>1. To start DataLoader servcies:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">$ sudo service dataloader-manager start</pre>
</div></div><p>2. To stop DataLoader services:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">$ sudo service dataloader-manager stop</pre>
</div></div><h3 id="InstallingandConfiguringDataLoader-AdvancedConfigurations"><span style="color: rgb(0,0,0);font-size: 20.0px;line-height: 1.5;">Advanced Configurations</span></h3><p><span style="line-height: 1.4285715;"> </span><span style="line-height: 1.4285715;">These configurations are used for performance tuning and are found in the /usr/local/gphd/dataloader-2.0.4/conf/dataloader.xml file.</span></p><p><span style="line-height: 1.4285715;"> </span></p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh"><p>Parameter</p></th><th class="confluenceTh"><p>Explanation</p></th><th class="confluenceTh"><p>Default value</p></th><th class="confluenceTh"><p>Options</p></th></tr><tr><td class="confluenceTd"><p>dataloader.zk.address</p></td><td class="confluenceTd"><p>Comma separated host/port list of Zookeeper. This value should be be changed: please change the dataloader_ZK_QUORUM in the <em>dataloader-env.sh</em> file.</p></td><td class="confluenceTd"><p>${DATALOADER_ZK_QUORUM}</p></td><td class="confluenceTd"><p> </p></td></tr><tr><td class="confluenceTd"><p>dataloader.manager.service.port</p></td><td class="confluenceTd"><p>The manager restful interface listening port;</p></td><td class="confluenceTd"><p>12380</p></td><td class="confluenceTd"><p> </p></td></tr><tr><td class="confluenceTd"><p>dataloader.metrics.monitoring.enable</p></td><td class="confluenceTd"><p>This flag specifies whether to enable the metrics reporting mechanism for DataLoader. Since progress monitoring depends on metrics reporting, disabling this parameter will also disable progress reporting.</p></td><td class="confluenceTd"><p>true</p></td><td class="confluenceTd"><p>true/false</p></td></tr><tr><td class="confluenceTd"><p>dataloader.metrics.server.host</p></td><td class="confluenceTd"><p>rpc host address for metrics reporting server. This parameter should be set to manager's host.<br/>This value should not be changed, if you want to change this value, please modify DATALOADER_SERVICE_IP in the dataloader-env.sh file.</p></td><td class="confluenceTd"><p>${DATALOADER_SERVICE_IP}</p></td><td class="confluenceTd"><p> </p></td></tr><tr><td class="confluenceTd"><p>dataloader.metrics.server.port</p></td><td class="confluenceTd"><p>rpc port for progress monitoring server</p></td><td class="confluenceTd"><p>12322</p></td><td class="confluenceTd"><p> </p></td></tr><tr><td class="confluenceTd"><p>dataloader.scheduler.service.rest.port</p></td><td class="confluenceTd"><p>The scheduler restful interface listening port;</p></td><td class="confluenceTd"><p>12321</p></td><td class="confluenceTd"><p> </p></td></tr><tr><td class="confluenceTd"><p>dataloader.scheduler.service.rest.host *</p></td><td class="confluenceTd"><p>The scheduler restful interface binding address. This value should not be changed, if you want to change this value, please change DATALOADER_SERVICE_IP in the dataloader-env.sh file. </p></td><td class="confluenceTd"><p>${DATALOADER_SERVICE_IP}</p></td><td class="confluenceTd"><p> </p></td></tr><tr><td class="confluenceTd"><p>dataloader.scheduler.taskscheduler.host</p></td><td class="confluenceTd"><p>The scheduler's host, worker will use this to contact scheduler for runtime task scheduling, <br class="atl-forced-newline"/> This value should not be changed, if you want to change this value, please change DATALOADER_SERVICE_IP in the <em>dataloader-env.sh</em> file.</p></td><td class="confluenceTd"><p>${DATALOADER_SERVICE_IP}</p></td><td class="confluenceTd"><p> </p></td></tr><tr><td class="confluenceTd"><p>dataloader.scheduler.taskscheduler.port</p></td><td class="confluenceTd"><p>The scheduler's port. The worker will use this to contact the scheduler for runtime task scheduling,</p></td><td class="confluenceTd"><p>12320</p></td><td class="confluenceTd"><p> </p></td></tr><tr><td class="confluenceTd" colspan="1">dataloader.worker.reader.num</td><td class="confluenceTd" colspan="1"><p>The number of reader threads to be started in each worker. <br/>Reader threads are responsible for reading data from data sources. Using multiple reader threads can enhance I/O read parallelism. However, adding excessive reader threads can burden system resources due to the context switch between reader threads.</p></td><td class="confluenceTd" colspan="1">3</td><td class="confluenceTd" colspan="1"> </td></tr><tr><td class="confluenceTd" colspan="1">dataloader.worker.writer-pipeline.num</td><td class="confluenceTd" colspan="1"><p>The number of writer/pipeline threads that will be started in each worker. <br/>Writer threads are responsible for writing data to its destination. Using multiple writer threads can enhance I/O write parallelism. However, adding excessive writer threads can burden system resources due to the context switch between writer threads.</p></td><td class="confluenceTd" colspan="1">5</td><td class="confluenceTd" colspan="1"> </td></tr><tr><td class="confluenceTd"><p>dataloader.worker.buffer.num</p></td><td class="confluenceTd"><p>The number of buffers which could be used in each worker for batch jobs. <br/>When all the buffers run out of DataLoader worker resources, the reader threads wait for buffers to become available, before reading next piece of data. <br/>Increasing the number of memory buffers used by DataLoader workers can potentially enhance the throughput and latency of a worker assigned to a job’s workload. However, this strategy will use more system resources.</p></td><td class="confluenceTd"><p>12</p></td><td class="confluenceTd"><p> </p></td></tr><tr><td class="confluenceTd"><p>dataloader.worker.buffer.size</p></td><td class="confluenceTd"><p>The size of each buffer for batch job workers. <br/>A reader thread first fetches a buffer of the specified size, before reading data from the source. It fills the buffer until either the buffer is full or the designated piece of data is completely read into buffer, then passwa it to the writer thread, to write it to the destination.<br/>Increasing the size of the memory buffers used by DataLoader workers can potentially enhance IO throughput, since it allows data read to occur in batch mode, reducing the number of I/O operations. However, it will use more system resources.</p></td><td class="confluenceTd"><p>16 * 1024 * 1024 (16MB)</p></td><td class="confluenceTd"><p> </p></td></tr><tr><td class="confluenceTd" colspan="1">dataloader.worker.streaming.server.memory.upper.limit</td><td class="confluenceTd" colspan="1"><p>The maxiumum memory that the worker can use to hold incloming data in pushstream jobs. <br/>When the size of event data held in a worker's memory not written to its destination exceeds this memory limit, the worker will stop receiving event data from the client, to avoid memory leakage.<br/>Increasing the value of this parameter can potentially enhance the latency of pushstream jobs when a worker is receiving large amounts of data from many clients. However, it will use more system resources.</p></td><td class="confluenceTd" colspan="1">335544320</td><td class="confluenceTd" colspan="1"> </td></tr><tr><td class="confluenceTd" colspan="1">dataloader.executor.notification.host</td><td class="confluenceTd" colspan="1"><p>The IP address on which the executor is to listen for the job status notification:<br/>${DATALOADER_SERVICE_IP}</p></td><td class="confluenceTd" colspan="1"> </td><td class="confluenceTd" colspan="1"> </td></tr><tr><td class="confluenceTd" colspan="1">dataloader.executor.notification.port</td><td class="confluenceTd" colspan="1">The port on which the executor is to listen for job status notifications: 12324</td><td class="confluenceTd" colspan="1">12324</td><td class="confluenceTd" colspan="1"> </td></tr></tbody></table></div><p><span style="line-height: 1.4285715;"> Advanced features are used primarily for performance tuning.</span></p><h3 id="InstallingandConfiguringDataLoader-ConfigureDataLoaderCLI"><span style="color: rgb(0,0,0);font-size: 20.0px;line-height: 1.5;">Configure DataLoader CLI</span></h3><p><span style="line-height: 1.4285715;">To use the DataLoader CLI for managing jobs and datastores, it must be configured.</span></p><p>The configuration file for CLI is located at:</p><pre>${DATALOADER_HOME}/conf/dataloader-cli.conf.</pre><p>It is a text file with key/value pair content.</p><p><span style="line-height: 1.4285715;"> </span></p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh"><p>name</p></th><th class="confluenceTh"><p>default value</p></th><th class="confluenceTh"><p>description</p></th></tr><tr><td class="confluenceTd"><p>dataloader.api.url</p></td><td class="confluenceTd"><p>http://localhost:12380/manager</p></td><td class="confluenceTd"><p>This is the location of the DataLoader scheduler's restful interface address. If CLI is installed on the same machine as the DataLoader service package, this value doesn't need to be changed.</p></td></tr><tr><td class="confluenceTd"><p>dataloader.zk.address</p></td><td class="confluenceTd"><p>localhost:12181</p></td><td class="confluenceTd"><p>This is the location of the Zookeeper servers, provided as a comma-separated list (<span>for example: </span><em>host1:2181,host2:2181)</em>. This list should be the same as used in dataloader-env.sh earlier. Do not change if using standalone or pseudo-distributed modes, as the embedded-zookeeper address is the default.</p></td></tr><tr><td class="confluenceTd"><p>dataloader.cli.queue.max.buffer</p></td><td class="confluenceTd"><p>32768</p></td><td class="confluenceTd"><p>The maximum number of unacknowledged messages that the client can hold in memory. Will be overwritten at run time if the command line param --queue-size is specified.<br/>To avoid memory leakage, when the number of unacknowledged events/messages held in the client's memory exceeds the specified limits, the client will stop accepting events from the stream until the resource become available. <br/>Increasing the value of this parameter can potentially enhance the latency when a client is receiving numerous events. However, this will use more system resources.</p></td></tr></tbody></table></div><p><span style="line-height: 1.4285715;"> </span><span style="line-height: 1.4285715;">If using pseudo-distributed mode,you can use default values, provided you are not using an external Zookeeper.</span></p><p><span style="line-height: 1.4285715;"><br/></span></p>
</div></div>


            </div><!-- end of body-container content-->
          </div><!-- end of container -->
        </div><!--end of container-fluid-->
      </div><!--end of main-wrap-->

      <div class="site-footer desktop-only">
          <div class="container-fluid">
              <div class="site-footer-links">
                  <span class="version"><a href='/'>Pivotal Documentation</a></span>
                  <span>&copy;
                      <script>
                          var d = new Date();
                          document.write(d.getFullYear());
                      </script>
                      <a href='http://gopivotal.com'>Pivotal Software</a> Inc. All Rights Reserved.
                  </span>
              </div>
          </div>
      </div>

      <script type="text/javascript">
          (function() {
              var didInit = false;
              function initMunchkin() {
                  if(didInit === false) {
                      didInit = true;
                      Munchkin.init('625-IUJ-009');
                  }
              }
              var s = document.createElement('script');
              s.type = 'text/javascript';
              s.async = true;
              s.src = document.location.protocol + '//munchkin.marketo.net/munchkin.js';
              s.onreadystatechange = function() {
                  if (this.readyState == 'complete' || this.readyState == 'loaded') {
                      initMunchkin();
                  }
              };
              s.onload = initMunchkin;
              document.getElementsByTagName('head')[0].appendChild(s);
          })();
      </script>
  </div><!--end of viewport-->
  <div id="scrim"></div>
</body>
</html>