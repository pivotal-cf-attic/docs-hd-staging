
<!doctype html>
<html>
<head>
  <meta charset="utf-8">

  <!-- Always force latest IE rendering engine or request Chrome Frame -->
  <meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible">

  <!-- REPLACE X WITH PRODUCT NAME -->
  <title>Administering PHD Using the CLI | Pivotal Docs</title>
    <!-- Local CSS stylesheets -->
    <link href="/stylesheets/master.css" media="screen,print" rel="stylesheet" type="text/css" />
    <link href="/stylesheets/breadcrumbs.css" media="screen,print" rel="stylesheet" type="text/css" />
    <link href="/stylesheets/search.css" media="screen,print" rel="stylesheet" type="text/css" />
    <link href="/stylesheets/portal-style.css" media="screen,print" rel="stylesheet" type="text/css" />
    <link href="/stylesheets/printable.css" media="print" rel="stylesheet" type="text/css" /> 
    <!-- Confluence HTML stylesheet -->
    <link href="/stylesheets/site-conf.css" media="screen,print" rel="stylesheet"  type="text/css" /> 
    <!-- Left-navigation code -->
    <!-- http://www.designchemical.com/lab/jquery-vertical-accordion-menu-plugin/examples/# -->
    <link href="/stylesheets/dcaccordion.css" rel="stylesheet" type="text/css" />
    <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.4.2/jquery.min.js" type="text/javascript"></script>
    <script src="/javascripts/jquery.cookie.js" type="text/javascript"></script>
    <script src="/javascripts/jquery.hoverIntent.minified.js" type="text/javascript"></script>
    <script src="/javascripts/jquery.dcjqaccordion.2.7.min.js" type="text/javascript"></script>
    <script type="text/javascript">
                    $(document).ready(function($){
					$('#accordion-1').dcAccordion({
						eventType: 'click',
						autoClose: true,
						saveState: true,
						disableLink: false,
						speed: 'fast',
						classActive: 'test',
						showCount: false
					});
					});
        </script>
    <link href="/stylesheets/grey.css" rel="stylesheet" type="text/css" /> 
    <!-- End left-navigation code -->
    <script src="/javascripts/all.js" type="text/javascript"></script>
    <link href='http://www.gopivotal.com/misc/favicon.ico' rel='shortcut icon'>
    <script type="text/javascript">
    if (window.location.host === 'docs.gopivotal.com') {
        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-39702075-1']);
        _gaq.push(['_setDomainName', 'gopivotal.com']);
        _gaq.push(['_trackPageview']);

        (function() {
          var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
          ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
          var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    }
  </script>
</head>

<body class="pivotalcf pivotalcf_getstarted pivotalcf_getstarted_index">
  <div class="viewport">
    <div class="mobile-navigation--wrapper mobile-only">
      <div class="navigation-drawer--container">
        <div class="navigation-item-list">
          <div class="navbar-link active">
            <a href="http://gopivotal.com">
              Home
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
          <div class="navbar-link">
            <a href="http://gopivotal.com/paas">
              PaaS
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
          <div class="navbar-link">
            <a href="http://gopivotal.com/big-data">
              Big Data
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
          <div class="navbar-link">
            <a href="http://gopivotal.com/agile">
              Agile
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
          <div class="navbar-link">
            <a href="http://gopivotal.com/support">
              Help &amp; Support
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
          <div class="navbar-link">
            <a href="http://gopivotal.com/products">
              Products
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
          <div class="navbar-link">
            <a href="http://gopivotal.com/solutions">
              Solutions
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
          <div class="navbar-link">
            <a href="http://gopivotal.com/partners">
              Partners
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
        </div>
      </div>
      <div class="mobile-nav">
        <div class="nav-icon js-open-nav-drawer">
          <i class="icon-reorder"></i>
        </div>
        <div class="header-center-icon">
          <a href="http://gopivotal.com">
            <div class="icon icon-pivotal-logo-mobile"></div>
          </a>
        </div>
      </div>
    </div>

    <div class='wrap'>
      <script src="//use.typekit.net/clb0qji.js" type="text/javascript"></script>
      <script type="text/javascript">
          try {
              Typekit.load();
          } catch (e) {
          }
      </script>
      <script type="text/javascript">
          document.domain = "gopivotal.com";
      </script>

	<script type="text/javascript">
	  WebFontConfig = {
	    google: { families: [ 'Source+Sans+Pro:300italic,400italic,600italic,300,400,600:latin' ] }
	  };
	  (function() {
	    var wf = document.createElement('script');
	    wf.src = ('https:' == document.location.protocol ? 'https' : 'http') +
	      '://ajax.googleapis.com/ajax/libs/webfont/1/webfont.js';
	    wf.type = 'text/javascript';
	    wf.async = 'true';
	    var s = document.getElementsByTagName('script')[0];
	    s.parentNode.insertBefore(wf, s);
	  })(); </script>

      <div id="search-dropdown-box">
        <div class="search-dropdown--container js-search-dropdown">
          <div class="container-fluid">
            <div class="close-menu-large"><img src="http://www.gopivotal.com/sites/all/themes/gopo13/images/icon-close.png" /></div>
            <div class="search-form--container">
              <div class="form-search">
                <div class='gcse-search'></div>
                <script src="http://www.google.com/jsapi" type="text/javascript"></script>
                <script src="//javascripts/cse.js" type="text/javascript"></script>
              </div>
            </div>
          </div>
        </div>
      </div>

      <header class="navbar desktop-only" id="nav">
        <div class="navbar-inner">
            <div class="container-fluid">
                <div class="pivotal-logo--container">
                    <a class="pivotal-logo" href="http://gopivotal.com"><span></span></a>
                </div>

                <ul class="nav pull-right">
                    <li class="navbar-link">
                        <a href="http://www.gopivotal.com/paas" id="paas-nav-link">PaaS</a>
                    </li>
                    <li class="navbar-link">
                        <a href="http://www.gopivotal.com/big-data" id="big-data-nav-link">BIG DATA</a>
                    </li>
                    <li class="navbar-link">
                        <a href="http://www.gopivotal.com/agile" id="agile-nav-link">AGILE</a>
                    </li>
                    <li class="navbar-link">
                        <a href="http://www.gopivotal.com/oss" id="oss-nav-link">OSS</a>
                    </li>
                    <li class="nav-search">
                        <a class="js-search-input-open" id="click-to-search"><span></span></a>
                    </li>
                </ul>
            </div>
            <a href="http://www.gopivotal.com/contact">
                <img id="get-started" src="http://www.gopivotal.com/sites/all/themes/gopo13/images/get-started.png">
            </a>
        </div>
      </header>
      <div class="main-wrap">
        <div class="container-fluid">

          <!-- Google CSE Search Box -->
          <div id='docs-search'>
              <gcse:search></gcse:search>
          </div>
          
          <div id='all-docs-link'>
            <a href="http://docs.gopivotal.com/">All Documentation</a>
          </div>
          
          <div class="container">
            <div id="sub-nav" class="nav-container">              
              
              <!-- Collapsible left-navigation-->
				<ul class="accordion"  id="accordion-1">
					<!-- REPLACE <li/> NODES-->
                                  <li>
                <a href="index.html">Home</a></br>
                        </li>
                        <li>
                <a href="PivotalHD.html">Pivotal HD</a>

                            <ul>
                    <li>
                <a href="PHDEnterprise2.0.1ReleaseNotes.html">PHD Enterprise 2.0.1 Release Notes</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PHDInstallationandAdministration.html">PHD Installation and Administration</a>

                            <ul>
                    <li>
                <a href="OverviewofPHD.html">Overview of PHD</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="InstallationOverview.html">Installation Overview</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PHDInstallationChecklist.html">PHD Installation Checklist</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="InstallingPHDUsingtheCLI.html">Installing PHD Using the CLI</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="UpgradeChecklist.html">Upgrade Checklist</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="UpgradingPHDUsingtheCLI.html">Upgrading PHD Using the CLI</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="AdministeringPHDUsingtheCLI.html">Administering PHD Using the CLI</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PHDFAQFrequentlyAskedQuestions.html">PHD FAQ (Frequently Asked Questions)</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PHDTroubleshooting.html">PHD Troubleshooting</a>

                    </li>
            </ul>
            </li>
            </ul>
                    <ul>
                    <li>
                <a href="StackandToolsReference.html">Stack and Tools Reference</a>

                            <ul>
                    <li>
                <a href="OverviewofApacheStackandPivotalComponents.html">Overview of Apache Stack and Pivotal Components</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="ManuallyInstallingPivotalHD2.0Stack.html">Manually Installing Pivotal HD 2.0 Stack</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="ManuallyUpgradingPivotalHDStackfrom1.1.1to2.0.html">Manually Upgrading Pivotal HD Stack from 1.1.1 to 2.0</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PivotalHadoopEnhancements.html">Pivotal Hadoop Enhancements</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="Security.html">Security</a>

                    </li>
            </ul>
            </li>
            </ul>
            </li>
                        <li>
                <a href="PivotalCommandCenter.html">Pivotal Command Center</a>

                            <ul>
                    <li>
                <a href="PCC2.2.1ReleaseNotes.html">PCC 2.2.1 Release Notes</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PCCUserGuide.html">PCC User Guide</a>

                            <ul>
                    <li>
                <a href="PCCOverview.html">PCC Overview</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PCCInstallationChecklist.html">PCC Installation Checklist</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="InstallingPCC.html">Installing PCC</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="UsingPCC.html">Using PCC</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="CreatingaYUMEPELRepository.html">Creating a YUM EPEL Repository</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="CommandLineReference.html">Command Line Reference</a>

                    </li>
            </ul>
            </li>
            </ul>
            </li>
                        <li>
                <a href="PivotalHAWQ.html">Pivotal HAWQ</a>

                            <ul>
                    <li>
                <a href="HAWQ1.2.0.1ReleaseNotes.html">HAWQ 1.2.0.1 Release Notes</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQInstallationandUpgrade.html">HAWQ Installation and Upgrade</a>

                            <ul>
                    <li>
                <a href="PreparingtoInstallHAWQ.html">Preparing to Install HAWQ</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="InstallingHAWQ.html">Installing HAWQ</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="InstallingtheHAWQComponents.html">Installing the HAWQ Components</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="UpgradingHAWQandComponents.html">Upgrading HAWQ and Components</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQConfigurationParameterReference.html">HAWQ Configuration Parameter Reference</a>

                    </li>
            </ul>
            </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQAdministration.html">HAWQ Administration</a>

                            <ul>
                    <li>
                <a href="HAWQOverview.html">HAWQ Overview</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQQueryProcessing.html">HAWQ Query Processing</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="UsingHAWQtoQueryData.html">Using HAWQ to Query Data</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="ConfiguringClientAuthentication.html">Configuring Client Authentication</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="KerberosAuthentication.html">Kerberos Authentication</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="ExpandingtheHAWQSystem.html">Expanding the HAWQ System</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQInputFormatforMapReduce.html">HAWQ InputFormat for MapReduce</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQFilespacesandHighAvailabilityEnabledHDFS.html">HAWQ Filespaces and High Availability Enabled HDFS</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="SQLCommandReference.html">SQL Command Reference</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="ManagementUtilityReference.html">Management Utility Reference</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="ClientUtilityReference.html">Client Utility Reference</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQServerConfigurationParameters.html">HAWQ Server Configuration Parameters</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQEnvironmentVariables.html">HAWQ Environment Variables</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQDataTypes.html">HAWQ Data Types</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="SystemCatalogReference.html">System Catalog Reference</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="hawq_toolkitReference.html">hawq_toolkit Reference</a>

                    </li>
            </ul>
            </li>
            </ul>
                    <ul>
                    <li>
                <a href="PivotalExtensionFrameworkPXF.html">Pivotal Extension Framework (PXF)</a>

                            <ul>
                    <li>
                <a href="PXFInstallationandAdministration.html">PXF Installation and Administration</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PXFExternalTableandAPIReference.html">PXF External Table and API Reference</a>

                    </li>

              </ul>
                                    
            </div><!--end of sub-nav-->
            
            <h3 class="title-container">Administering PHD Using the CLI</h3>
            <div class="content">
              <!-- Python script replaces main content -->
			  <div id ="main"><div style="visibility:hidden; height:2px;">Pivotal Product Documentation : Administering PHD Using the CLI</div><div class="wiki-content group" id="main-content">
<p>This section describes the administrative actions that can be performed via Pivotal Command Center's command line interface (CLI).</p><p><style type="text/css">/*<![CDATA[*/
div.rbtoc1398914612616 {padding: 0px;}
div.rbtoc1398914612616 ul {list-style: disc;margin-left: 0px;}
div.rbtoc1398914612616 li {margin-left: 0px;padding-left: 0px;}

/*]]>*/</style><div class="toc-macro rbtoc1398914612616">
<ul class="toc-indentation">
<li><a href="#AdministeringPHDUsingtheCLI-ManagingaCluster">Managing a Cluster</a>
<ul class="toc-indentation">
<li><a href="#AdministeringPHDUsingtheCLI-StartingaCluster">Starting a Cluster</a></li>
<li><a href="#AdministeringPHDUsingtheCLI-StoppingaCluster">Stopping a Cluster</a></li>
<li><a href="#AdministeringPHDUsingtheCLI-RestartingaCluster">Restarting a Cluster</a></li>
<li><a href="#AdministeringPHDUsingtheCLI-ReconfiguringaCluster">Reconfiguring a Cluster</a></li>
<li><a href="#AdministeringPHDUsingtheCLI-Add/RemoveServices">Add / Remove Services</a></li>
<li><a href="#AdministeringPHDUsingtheCLI-AddHoststoCluster">Add Hosts to Cluster</a></li>
<li><a href="#AdministeringPHDUsingtheCLI-RetrievingConfigurationaboutaDeployedCluster">Retrieving Configuration about a Deployed Cluster</a></li>
<li><a href="#AdministeringPHDUsingtheCLI-ListingClusters">Listing Clusters</a></li>
<li><a href="#AdministeringPHDUsingtheCLI-ExpandingaCluster">Expanding a Cluster</a></li>
<li><a href="#AdministeringPHDUsingtheCLI-ShrinkingaCluster">Shrinking a Cluster</a></li>
<li><a href="#AdministeringPHDUsingtheCLI-DecommissioningNodes">Decommissioning Nodes</a></li>
<li><a href="#AdministeringPHDUsingtheCLI-HighAvailability">High Availability</a></li>
<li><a href="#AdministeringPHDUsingtheCLI-Security">Security</a></li>
<li><a href="#AdministeringPHDUsingtheCLI-UninstallingaCluster">Uninstalling a Cluster</a></li>
</ul>
</li>
<li><a href="#AdministeringPHDUsingtheCLI-ManagingHAWQ">Managing HAWQ</a>
<ul class="toc-indentation">
<li><a href="#AdministeringPHDUsingtheCLI-InitializingHAWQ">Initializing HAWQ</a></li>
<li><a href="#AdministeringPHDUsingtheCLI-StartingHAWQ">Starting HAWQ</a></li>
<li><a href="#AdministeringPHDUsingtheCLI-StoppingHAWQ">Stopping HAWQ</a></li>
<li><a href="#AdministeringPHDUsingtheCLI-ModifyingHAWQUserConfiguration">Modifying HAWQ User Configuration</a></li>
<li><a href="#AdministeringPHDUsingtheCLI-ExpandingHAWQ">Expanding HAWQ</a></li>
</ul>
</li>
<li><a href="#AdministeringPHDUsingtheCLI-ManagingRolesandHosts">Managing Roles and Hosts</a>
<ul class="toc-indentation">
<li><a href="#AdministeringPHDUsingtheCLI-ManagingLocally">Managing Locally</a></li>
<li><a href="#AdministeringPHDUsingtheCLI-ManagingRemotely">Managing Remotely</a></li>
</ul>
</li>
<li><a href="#AdministeringPHDUsingtheCLI-PivotalHDServicesReference">Pivotal HD Services Reference</a>
<ul class="toc-indentation">
<li><a href="#AdministeringPHDUsingtheCLI-OverridingDirectoryPermissions">Overriding Directory Permissions</a></li>
<li><a href="#AdministeringPHDUsingtheCLI-PivotalHDUsersandGroups">Pivotal HD Users and Groups</a></li>
<li><a href="#AdministeringPHDUsingtheCLI-PivotalHDPorts">Pivotal HD Ports</a></li>
</ul>
</li>
</ul>
</div></p><p><span class="confluence-anchor-link" id="AdministeringPHDUsingtheCLI-ManagingACluster"></span></p><h2 id="AdministeringPHDUsingtheCLI-ManagingaCluster">Managing a Cluster</h2><h3 id="AdministeringPHDUsingtheCLI-StartingaCluster">Starting a Cluster</h3><p>You can use the <code>start</code> command to start all the configured services of the cluster, to start individual services configured for the cluster, and to start individual roles on a specific set of hosts.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">icm_client start --help
Usage: /usr/bin/icm_client start [options]

Options:
  -h, --help            show this help message and exit
  -v, --verbose         increase output verbosity
  -l CLUSTERNAME, --clustername=CLUSTERNAME
                        the name of the cluster on which the operation is
                        performed
  -s SERVICES, --service=SERVICES
                        service to be started
  -f, --force           forcibly start cluster (even if install is incomplete)
  -r ROLES, --role=ROLES
                        The name of the role which needs to be started
  -o HOSTFILE, --hostfile=HOSTFILE
                        The absolute path for the file containing host names
                        for the role which needs to be started
</pre>
</div></div><p>The following table describes the list of values for the HDFS, MapRed, ZooKeeper, HBase, and HAWQ services:</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh"><p>Option</p></th><th class="confluenceTh"><p>Description</p></th></tr><tr><td class="confluenceTd"><p><code>start</code></p></td><td class="confluenceTd"><p>Starts all configured cluster services in the right topological order based on service dependencies.</p></td></tr><tr><td class="confluenceTd"><p><code>-s</code></p></td><td class="confluenceTd"><p>Starts the specified service and all services it depends on in the right topological order. The supported services are hdfs, yarn, zookeeper, hbase, hive, hawq, pig, and mahout.</p></td></tr><tr><td class="confluenceTd"><p><code>-r</code></p></td><td class="confluenceTd"><p>Starts only the specified role on a specific set of hosts. Hosts can be specified using the -o option.</p></td></tr><tr><td class="confluenceTd"><p><code>-f</code></p></td><td class="confluenceTd"><p>Forces the cluster to start even if the installation is incomplete.</p></td></tr></tbody></table></div><p>The first time the cluster is started, Pivotal HD implicitly initializes the cluster. For subsequent invocations of the <code>start</code> command, the cluster is not initialized.</p><p> </p><p>Cluster initialization includes the following:</p><ul><li>Namenode format</li><li>Create directories on the local filesystem of cluster nodes and on the hdfs with the correct permission overrides. See the <a href="#AdministeringPHDUsingtheCLI-OverridingDirectoryPermissions">Overriding Directory Permissions</a> section.</li><li>Create HDFS directories for additional services, such as HBase, if these are included in the configured services.</li></ul> <div class="aui-message warning shadowed information-macro">
<p class="title">Notes</p>
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<p>Refer to the "Verifying the Cluster Nodes for Pivotal HD" section to make sure the cluster services are up and running.</p><p>Make sure you back up all the data prior to installing or starting a new cluster on nodes that have pre-existing data on the configured mount points.</p>
</div>
</div>
<p>For example:<br/> Cluster level start:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[gpadmin]# icm_client start -l CLUSTERNAME
</pre>
</div></div><p>Service level start:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[gpadmin]# icm_client start -l CLUSTERNAME -s hdfs
</pre>
</div></div><p>Role level start:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[gpadmin]# icm_client start -l CLUSTERNAME -r datanode -o hostfile
</pre>
</div></div><h3 id="AdministeringPHDUsingtheCLI-StoppingaCluster">Stopping a Cluster</h3><p>You can use the <code>stop</code> command to stop an entire cluster, to stop a single service, and to stop a single role on a specific set of hosts on which it is configured.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[gpadmin]# icm_client stop -h
Usage: icm_client stop [options]

Options:
  -h, --help            Show this help message and exit
  -v, --verbose         Increase output verbosity
  -l CLUSTERNAME, --clustername=CLUSTERNAME
                        The name of the cluster on which the operation is
                        performed
  -s SERVICES, --service=SERVICES
                        Service to be stopped
  -r ROLES, --role=ROLES
                        The name of the role which needs to be stopped
  -o HOSTFILE, --hostfile=HOSTFILE
                        The absolute path for the file containing host names
                        for the role that needs to be stopped
</pre>
</div></div><p>The following table describes the list of values for the HDFS, MapRed, ZooKeeper, HBase, and HAWQ services.</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh"><p>Option</p></th><th class="confluenceTh"><p>Description</p></th></tr><tr><td class="confluenceTd"><p><code>stop</code></p></td><td class="confluenceTd"><p>Stops all configured cluster services in the right topological order based on service dependencies.</p></td></tr><tr><td class="confluenceTd"><p><code>-s</code></p></td><td class="confluenceTd"><p>Stops the specified service and all the dependent services in the right topological order. The supported services are hdfs, yarn, zookeeper, hbase, hive, hawq, pig, and mahout.</p></td></tr><tr><td class="confluenceTd"><p><code>-r</code></p></td><td class="confluenceTd"><p>Stops the specified role on a specific set of hosts. Hosts can be specified using the -o option.</p></td></tr></tbody></table></div><p>For example:<br/> Cluster level stop:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[gpadmin]# icm_client stop -l CLUSTERNAME
</pre>
</div></div><p>Service level stop:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[gpadmin]# icm_client stop -l CLUSTERNAME -s hdfs
</pre>
</div></div><p>Role level stop:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[gpadmin]# icm_client stop -l CLUSTERNAME -r datanode -o hostfile
</pre>
</div></div><h3 id="AdministeringPHDUsingtheCLI-RestartingaCluster">Restarting a Cluster</h3><p>You can use the <code>-restart</code> command to stop, then restart a cluster.</p><p>See stopping and starting a cluster, above, for more details about the stop/start operations.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[gpadmin]#  icm_client restart -h
Usage: /usr/bin/icm_client restart [options]

Options:
  -h, --help            Show this help message and exit
  -v, --verbose         Increase output verbosity
  -l CLUSTERNAME, --clustername=CLUSTERNAME
                        The name of the cluster on which the operation is
                        performed
  -s SERVICES, --service=SERVICES
                        The service to be restarted
  -f, --force           Forcibly start cluster (even if install is incomplete)
  -r ROLES, --role=ROLES
                        The name of the role which needs to be started
  -o HOSTFILE, --hostfile=HOSTFILE
                        The absolute path for the file containing host names
                        for the role which needs to be started
</pre>
</div></div><p><span class="confluence-anchor-link" id="AdministeringPHDUsingtheCLI-Reconfiguring"></span></p><h3 id="AdministeringPHDUsingtheCLI-ReconfiguringaCluster">Reconfiguring a Cluster</h3><p>Run the <code>reconfigure </code>command to update specific configuration for an existing cluster.</p> <div class="aui-message warning shadowed information-macro">
<p class="title">Caution</p>
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<p>Running the <code>reconfigure </code>command on a secure cluster will disable security.</p>
</div>
</div>
<p>Some cluster specific configurations cannot be updated:</p> <div class="aui-message warning shadowed information-macro">
<p class="title">Important</p>
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<ul><li>Reconfiguring the topology of a cluster (host to role mapping) is not allowed. For example: changing the NameNode to a different node or adding new set of datanodes to a cluster</li><li>Properties based on hostnames: For example, <code>fs.defaultFS</code>, <code>dfs.namenode</code>. and the <code>http-address</code>.</li><li>Properties with directory paths as values.</li></ul>
</div>
</div>
<p>The following table lists properties that can only be changed with a <code>--force</code> option.</p> <div class="aui-message warning shadowed information-macro">
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<ul><li>You are expected to take care of all the necessary prerequisites prior to making changes to any of the following properties using the force flag</li><li>Incorrect provisioning can make the cluster get into an inconsistent/unusable state</li></ul>
</div>
</div>
<div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh"><p>Property Name</p></th><th class="confluenceTh"><p>Configuration File</p></th></tr><tr><td class="confluenceTd"><p><code>datanode.disk.mount.points</code></p></td><td class="confluenceTd"><p><code>clusterConfig.xml</code></p></td></tr><tr><td class="confluenceTd"><p><code>namenode.disk.mount.points</code></p></td><td class="confluenceTd"><p><code>clusterConfig.xml</code></p></td></tr><tr><td class="confluenceTd"><p><code>secondary.namenode.disk.mount.points</code></p></td><td class="confluenceTd"><p><code>clusterConfig.xml</code></p></td></tr><tr><td class="confluenceTd"><p><code>hawq.master.directory</code></p></td><td class="confluenceTd"><p><code>clusterConfig.xml</code></p></td></tr><tr><td class="confluenceTd"><p><code>hawq.segment.directory</code></p></td><td class="confluenceTd"><p><code>clusterConfig.xml</code></p></td></tr><tr><td class="confluenceTd" colspan="1"><code>zookeeper.data.dir</code></td><td class="confluenceTd" colspan="1"><code>clusterConfig.xml</code></td></tr></tbody></table></div><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">icm_client reconfigure -h
Usage: /usr/bin/icm_client reconfigure [options]

Options:
  -h, --help            show this help message and exit
  -l CLUSTERNAME, --clustername=CLUSTERNAME
                        the name of the cluster on which the operation is
                        performed
  -c CONFDIR, --confdir=CONFDIR
                        Directory path where cluster configuration is stored
  -s, --noscanhosts     Do not verify cluster nodes.
  -p, --nopreparehosts  Do not preparehosts as part of deploying the cluster.
  -j JDKPATH, --java=JDKPATH
                        Location of Sun Java JDK RPM (Ex: jdk-
                        7u15-linux-x64.rpm). Ignored if -p is specified
  -t, --ntp             Synchronize system clocks using NTP. Optionally takes
                        NTP server as argument. Defaults to pool.ntp.org
                        (requires external network access). Ignored if -p is
                        specified
  -d, --selinuxoff      Disable SELinux. Ignored if -p is specified
  -i, --iptablesoff     Disable iptables. Ignored if -p is specified
  -y SYSCONFIGDIR, --sysconf=SYSCONFIGDIR
                        [Only if HAWQ is part of the deploy] Directory
                        location of the custom conf files (sysctl.conf and
                        limits.conf) which will be appended to
                        /etc/sysctl.conf and /etc/limits.conf on slave nodes.
                        Default: /usr/lib/gphd/gphdmgr/hawq_sys_config/.
                        Ignored if -p is specified
  -f, --force           Forcibly reconfigure the cluster (allows changes to
                        any servicesConfigGlobals property)</pre>
</div></div><p><strong>To reconfigure an existing cluster:</strong></p><ol><li>Stop the cluster:<br/> <code> icm_client stop -l CLUSTERNAME</code></li><li>Fetch the configurations for the cluster in a local directory:<br/> <code>icm_client fetch-configuration -l CLUSTERNAME -o LOCALDIR</code></li><li>Edit the configuration files in the cluster configuration directory (<code>LOCALDIR</code>).</li><li>Reconfigure the cluster:<br/> <code>icm_client reconfigure -l CLUSTERNAME -c LOCALDIR</code></li></ol><p> </p><p>Following an upgrade or reconfiguration, you need to synchronize the configuration files, as follows:<strong> <br/> </strong></p><ol><li>Fetch the new templates that come with the upgraded software by running <code>icm_client fetch-template</code>.</li><li>Retrieve the existing configuration from database using <code>icm_client fetch-configuration</code>.</li><li>Synchronize the new configurations (<code>hdfs/hadoop-env</code>) from the template directory to the existing cluster configuration directory.</li><li>Upgrade or reconfigure service by specifying the cluster configuration directory with updated contents.</li></ol><h3 id="AdministeringPHDUsingtheCLI-Add/RemoveServices">Add / Remove Services</h3><p>Services can be added  / removed using <code>icm_client reconfigure</code> command.</p><ul><li>Edit the <code>clusterConfig.xml</code> file to add or remove services from the service list in <code>services</code> tag</li><li>Edit <code>hostRoleMapping</code> section to add or remove hosts for the specific services configured</li><li>Edit the <code>servicesConfigGlobals</code> if required for the specific service added</li><li>Follow the steps for <a href="#AdministeringPHDUsingtheCLI-ReconfiguringaCluster">Reconfiguring a Cluster</a>.</li><li>As in a new deployment you can use the <code>-p</code> or <code>-s</code> option to disable scanhosts or preparehosts on the newly added hosts</li><li>If you want to prepare the new hosts with java or if you want to disable iptables or SELinux, follow the instructions for installing Java mentioned in the Deploying a cluster section of this document</li></ul> <div class="aui-message warning shadowed information-macro">
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<p>Removing a specific service using the <code>icm_client reconfigure</code> command does not remove rpms from the nodes. The rpms are only removed when the Cluster is uninstalled</p>
</div>
</div>
<h3 id="AdministeringPHDUsingtheCLI-AddHoststoCluster">Add Hosts to Cluster</h3><p>If you plan to add hosts as part of adding a new service, perform the following:</p><ul><li>Prepare the new hosts using the <code>icm_client preparehosts</code> command</li><li>Refer to <em>Add / Remove Services</em> section</li></ul><p>If you plan to add/remove hosts as part of an existing service in the cluster do the following:</p> <div class="aui-message warning shadowed information-macro">
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<p>You can only add or remove hosts for slave roles (refer to <em>Expanding a Cluster</em> section for the list of slave roles). You cannot make host changes for any other role.</p>
</div>
</div>
<ul><li>Prepare the new hosts using the <code>icm_client preparehosts</code> command</li><li>You can add the new hosts to the corresponding slave roles in the <code>hostRoleMapping</code> section in <code>clusterConfig.xml<br/> </code></li><li>Follow the steps for <a href="#AdministeringPHDUsingtheCLI-ReconfiguringaCluster">Reconfiguring a Cluster</a></li></ul> <div class="aui-message warning shadowed information-macro">
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<p>You cannot add one service and remove another at the same time. You have to perform these as two separate steps; however you can add multiple services OR remove multiple services at the same time.</p>
</div>
</div>
<p> </p><h3 id="AdministeringPHDUsingtheCLI-RetrievingConfigurationaboutaDeployedCluster">Retrieving Configuration about a Deployed Cluster</h3><p>Run the <code>fetch-configuration</code> command to fetch the configurations for an existing cluster and store them in a local file system directory.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">icm_client fetch-configuration -h
Usage: icm_client fetch-configuration [options]

Options:
  -h, --help            show this help message and exit
  -o OUTDIR, --outdir=OUTDIR
                        Directory path to store the cluster configuration
                        template files
  -l CLUSTERNAME, --clustername=CLUSTERNAME
                        Name of the deployed cluster whose configurations need
                        to be fetched
</pre>
</div></div><p><strong>Sample Usage</strong></p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">icm_client fetch-configuration -l CLUSTERNAME -o LOCALDIR</pre>
</div></div><h3 id="AdministeringPHDUsingtheCLI-ListingClusters">Listing Clusters</h3><p>Run the <code>list </code>command to see a list of all the installed clusters:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[gpadmin]# icm_client list --help
Usage: icm_client list [options]

Options:
  -h, --help     show this help message and exit
  -v, --verbose  increase output verbosity
</pre>
</div></div><p><strong>Sample Usage</strong>:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">icm_client list</pre>
</div></div><p><span class="confluence-anchor-link" id="AdministeringPHDUsingtheCLI-ExpandCluster"></span></p><h3 id="AdministeringPHDUsingtheCLI-ExpandingaCluster">Expanding a Cluster</h3> <div class="aui-message warning shadowed information-macro">
<p class="title">Notes</p>
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<ul><li>Make sure you run <code>preparehosts</code> against the new slave hosts prior to adding them to the cluster. (See the <code>preparehosts</code> command example in the "Preparing the Cluster for Pivotal HD" section.)</li><li><span style="color: rgb(51,51,51);">If security is enabled on the cluster; you will have to re-enable it after adding a node.</span></li></ul>
</div>
</div>
<p>Run the <code>add-slaves </code>command to add additional slave hosts to an existing cluster. All the slave roles for <strong><em>existing </em></strong>cluster services will be installed on the new cluster hosts.</p><p>The following table indicates the services and their corresponding slave roles. Services not included in this list are not allowed for expansion (or shrinking).</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh"><p>Service Name</p></th><th class="confluenceTh"><p>Slave</p></th></tr><tr><td class="confluenceTd"><p><code>hdfs</code></p></td><td class="confluenceTd"><p><code>datanode</code></p></td></tr><tr><td class="confluenceTd"><p><code>yarn</code></p></td><td class="confluenceTd"><p><code>yarn-nodemanager<br/> </code></p></td></tr><tr><td class="confluenceTd"><p><code>hbase</code></p></td><td class="confluenceTd"><p><code>hbase-regionserver</code></p></td></tr><tr><td class="confluenceTd"><p><code>hawq</code></p></td><td class="confluenceTd"><p><code>hawq-segment</code></p></td></tr></tbody></table></div><p>If you only want to install an individual component on a node, you should do this by manually editing the <code>clusterConfig.xml</code> file, then running the <code>reconfigure</code> command (see <a href="#AdministeringPHDUsingtheCLI-ReconfiguringaCluster">Reconfiguring a Cluster</a>).</p><p> </p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">icm_client add-slaves --help
Usage: /usr/bin/icm_client add-slaves [options]

Options:
  -h, --help            show this help message and exit
  -l CLUSTERNAME, --clustername=CLUSTERNAME
                        the name of the cluster on which the operation is
                        performed
  -f HOSTFILE, --hostfile=HOSTFILE
                        file containing new-line separated list of hosts that
                        are going to be added.
  -s, --noscanhosts     Do not verify cluster nodes.
  -j JAVAHOME, --java_home=JAVAHOME
                        JAVA_HOME path to verify on cluster nodes
  -p, --nopreparehosts  Do not preparehosts as part of deploying the cluster.
  -k JDKPATH, --java=JDKPATH
                        Location of Sun Java JDK RPM (Ex: jdk-
                        7u15-linux-x64.rpm). Ignored if -p is specified
  -t, --ntp             Synchronize system clocks using NTP. Optionally takes
                        NTP server as argument. Defaults to pool.ntp.org
                        (requires external network access). Ignored if -p is
                        specified
  -d, --selinuxoff      Disable SELinux for the newly added nodes. Ignored if
                        -p is specified
  -i, --iptablesoff     Disable iptables for the newly added nodes. Ignored if
                        -p is specified
  -y SYSCONFIGDIR, --sysconf=SYSCONFIGDIR
                        [Only if HAWQ is part of the deploy] Directory
                        location of the custom conf files (sysctl.conf and
                        limits.conf) which will be appended to
                        /etc/sysctl.conf and /etc/limits.conf of the newly
                        addded slave nodes. Default:
                        /usr/lib/gphd/gphdmgr/hawq_sys_config/. Ignored if -p
                        is specified</pre>
</div></div><p><strong>Sample Usage:</strong></p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">icm_client add-slaves -l CLUSTERNAME -f slave_hostfile</pre>
</div></div><p> </p><p>Make sure you start datanode and yarn nodemanager on the newly added slave hosts.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">icm_client start -l CLUSTERNAME -r datanode -o hostfile
icm_client start -l CLUSTERNAME -r yarn-nodemanager -o hostfile
</pre>
</div></div> <div class="aui-message warning shadowed information-macro">
<p class="title">Important</p>
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<ul><li>If HBase is configured, start hbase-regionservers as well.</li><li>Don't expect data blocks to be distributed to the newly added slave nodes immediately.</li></ul>
</div>
</div>
<div class="aui-message warning shadowed information-macro">
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<p>If HAWQ is configured, refer to the <em>Expanding HAWQ</em> section</p>
</div>
</div>
<div class="aui-message warning shadowed information-macro">
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<p>Hive does not have any slave roles, and therefore cannot be provisioned for an expansion.</p>
</div>
</div>
<p><span class="confluence-anchor-link" id="AdministeringPHDUsingtheCLI-ShrinkCluster"></span></p><h3 id="AdministeringPHDUsingtheCLI-ShrinkingaCluster">Shrinking a Cluster</h3> <div class="aui-message warning shadowed information-macro">
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<p>Make sure you decommission the slave hosts (refer to the next section) prior to removing them to avoid potential data loss.</p>
</div>
</div>
<p> </p><p>Run the <code>remove-slaves</code> command lets the user to remove slave hosts from an existing cluster. All the slave roles for the existing cluster services will be removed from the given hosts.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">icm_client remove-slaves --help
Usage: /usr/bin/icm_client remove-slaves [options]

Options:
  -h, --help            show this help message and exit
  -l CLUSTERNAME, --clustername=CLUSTERNAME
                        the name of the cluster on which the operation is
                        performed
  -f HOSTFILE, --hostfile=HOSTFILE
                        file containing new-line separated list of hosts that
                        are going to be removed.
       
</pre>
</div></div><p><br class="atl-forced-newline"/> <strong>Sample Usage</strong>:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">icm_client remove-slaves -l CLUSTERNAME -f hostfile
</pre>
</div></div><h3 id="AdministeringPHDUsingtheCLI-DecommissioningNodes">Decommissioning Nodes</h3><p>Decommissioning is required to prevent potential loss of data blocks when you shutdown/remove slave hosts form a cluster. This is not an instant process since it requires replication of potentially a large number of blocks to other cluster nodes.</p><p>The following are the manual steps to decommission slave hosts (datanodes,nodemanagers) from a cluster.</p><ul><li>On the NameNode host machine<ul><li>Edit the <code> /etc/gphd/hadoop/conf/dfs.exclude </code> file and add the datanode hostnames to be removed (separated by newline character). Make sure you use the FQDN for each hostname.</li><li><p>Execute the dfs refresh command</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[gpadmin] sudo -u hdfs hdfs dfsadmin –refreshNodes
</pre>
</div></div></li></ul></li><li>On the Yarn Resource Manager host machine<ul><li>Edit <code>/etc/gphd/hadoop/conf/yarn.exclude </code> file and add the node manager hostnames to be removed (separated by newline character). Make sure you use the FQDN for each hostname.</li><li><p>Execute the yarn refresh command</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[gpadmin] sudo -u hdfs yarn rmadmin -refreshNodes
</pre>
</div></div></li></ul></li><li>Check Decommission status<ul><li>Monitor decommission progress with name-node Web UI <code> <span class="nolink">http://NAMENODE_FQDN:50070</span> </code> and navigate to Decommissioning Nodes page</li><li>Check whether the admin state has changed to Decommission In Progress for the DataNodes being decommissioned. When all the DataNodes report their state as Decommissioned then all the blocks have been replicated.</li></ul></li><li>Shut down the decommissioned nodes<ul><li>Stop datanode and yarn node manager on the targeted slaves to be removed</li></ul></li></ul><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[gpadmin] icm_client stop -l CLUSTERNAME -r datanode -o hostfile
[gpadmin] icm_client stop -l CLUSTERNAME -r yarn-nodemanager -o hostfile
</pre>
</div></div> <div class="aui-message warning shadowed information-macro">
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<p>For HBase regionservers you can proceed with shutting down the region servers on the slave hosts to be removed. It is preferable to use <code>graceful_stop</code> script that hbase provides if load balancer is disabled.</p>
</div>
</div>
<p><span class="confluence-anchor-link" id="AdministeringPHDUsingtheCLI-EnablingHA"></span></p><h3 id="AdministeringPHDUsingtheCLI-HighAvailability">High Availability</h3><h4 id="AdministeringPHDUsingtheCLI-EnableHA"><span class="confluence-anchor-link" id="AdministeringPHDUsingtheCLI-EnableHA"></span></h4><h4 id="AdministeringPHDUsingtheCLI-EnablingHighAvailabilityonaCluster" style="text-align: left;">Enabling High Availability on a Cluster</h4><ul style="text-align: left;"><li>High availability is disabled by default.</li><li>Currently we only support Quorum Journal based storage for high availability.</li><li>PCC 2.1 is the first version to support HA. If you are running an earlier version, download and import the latest version of Pivotal Command Center (PCC) (see <a href="InstallingPHDUsingtheCLI.html">Installing PHD Using the CLI</a> for details)</li></ul> <div class="aui-message warning shadowed information-macro">
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<p>Before you enable HA for any cluster, make sure you take into consideration our recommended <a href="InstallingPHDUsingtheCLI.html#InstallingPHDUsingtheCLI-HABestPractices">HA Best Practices</a>.</p>
</div>
</div>
<p style="text-align: left;">To enable HA for a new cluster; follow the instructions provided in the <em>High Availability</em> section of <a href="InstallingPHDUsingtheCLI.html">Installing PHD Using the CLI</a>.</p><p style="text-align: left;">To enable HA for an existing cluster, see below.</p><ol style="text-align: left;"><li><p>Stop the cluster:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">icm_client stop -l CLUSTERNAME</pre>
</div></div></li><li><p>For HAWQ users, stop HAWQ.<br/>From the HAWQ master, as <code>gpadmin</code>, run the following:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">/etc/init.d/hawq stop</pre>
</div></div></li><li>Backup the Namenode data. Copy <code><span style="color: rgb(34,34,34);">{dfs.namenode.name.dir}/</span></code><span style="color: rgb(34,34,34);">current</span> to a backup directory.<br/><br/></li><li><p>Fetch the configurations for the cluster in a local directory:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">icm_client fetch-configuration -l CLUSTERNAME -o LOCALDIR</pre>
</div></div></li><li>Edit <code>clusterConfig.xml</code> as follows:<br/><p>Comment out <code>secondarynamenode</code> role in <code>hdfs</code> service</p><p>Uncomment <code>standbynamenode</code> and <code>journalnode</code> roles in <code>hdfs</code> service</p><p>Uncomment <code>nameservices</code>, <code>namenode1id</code>, <code>namenode2id</code>, <code>journalpath</code>, and <code>journalport</code> entries in <code>serviceConfigGlobals<br/><br/></code></p></li><li><p>Edit <code>hdfs/hdfs-site.xml</code> as follows:<br/>Uncomment the following properties:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">&lt;property&gt; 
  &lt;name&gt;dfs.nameservices&lt;/name&gt; 
  &lt;value&gt;${nameservices}&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
  &lt;name&gt;dfs.ha.namenodes.${nameservices}&lt;/name&gt; 
  &lt;value&gt;${namenode1id},${namenode2id}&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
  &lt;name&gt;dfs.namenode.rpc-address.${nameservices}.${namenode1id}&lt;/name&gt; 
  &lt;value&gt;${namenode}:8020&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
  &lt;name&gt;dfs.namenode.rpc-address.${nameservices}.${namenode2id}&lt;/name&gt; 
  &lt;value&gt;${standbynamenode}:8020&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
  &lt;name&gt;dfs.namenode.http-address.${nameservices}.${namenode1id}&lt;/name&gt; 
  &lt;value&gt;${namenode}:50070&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
  &lt;name&gt;dfs.namenode.http-address.${nameservices}.${namenode2id}&lt;/name&gt; 
  &lt;value&gt;${standbynamenode}:50070&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
  &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; 
  &lt;value&gt;qjournal://${journalnode}/${nameservices}&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
  &lt;name&gt;dfs.client.failover.proxy.provider.${nameservices}&lt;/name&gt; 
  &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
  &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; 
  &lt;value&gt;
  sshfence
  shell(/bin/true)
  &lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt;
  &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;
  &lt;value&gt;/home/hdfs/.ssh/id_rsa&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt; 
  &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; 
  &lt;value&gt;${journalpath}&lt;/value&gt; 
&lt;/property&gt; 

&lt;!-- Namenode Auto HA related properties --&gt; 
&lt;property&gt;
   &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;
   &lt;value&gt;true&lt;/value&gt;
 &lt;/property&gt;
&lt;!-- END Namenode Auto HA related properties --&gt;</pre>
</div></div><p>Comment the following properties</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">&lt;property&gt;
  &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
  &lt;value&gt;${secondarynamenode}:50090&lt;/value&gt;
  &lt;description&gt;
    The secondary namenode http server address and port.
  &lt;/description&gt;
&lt;/property&gt;</pre>
</div></div></li><li><p>Edit <code>yarn/yarn-site.xml</code> as follows:<code><br/></code>Set the following property/value:<code><br/></code></p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">&lt;property&gt;
    &lt;name&gt;mapreduce.job.hdfs-servers&lt;/name&gt;
    &lt;value&gt;hdfs://${nameservices}&lt;/value&gt;
&lt;/property&gt;
</pre>
</div></div></li><li><p>Edit <code>hdfs/core-site.xml</code> as follows:</p><p>Set the following property/value:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">&lt;property&gt;
  &lt;name&gt;fs.defaultFS&lt;/name&gt;
  &lt;value&gt;hdfs://${nameservices}&lt;/value&gt; 
  &lt;description&gt;The name of the default file system.  A URI whose
  scheme and authority determine the FileSystem implementation.  The
  uri's scheme determines the config property (fs.SCHEME.impl) naming
  the FileSystem implementation class.  The uri's authority is used to
  determine the host, port, etc. for a filesystem.&lt;/description&gt;
&lt;/property&gt;</pre>
</div></div><p>Then uncomment following property:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">&lt;property&gt;
   &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;
   &lt;value&gt;${zookeeper-server}:${zookeeper.client.port}&lt;/value&gt;
 &lt;/property&gt;</pre>
</div></div></li><li><p>Edit <code>hbase/hbase-site.xml</code> as follows:<br/>Set the following property/value:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">&lt;property&gt;
    &lt;name&gt;hbase.rootdir&lt;/name&gt;
    &lt;value&gt;hdfs://${nameservices}/apps/hbase/data&lt;/value&gt;
    &lt;description&gt;The directory shared by region servers and into
    which HBase persists.  The URL should be 'fully-qualified'
    to include the filesystem scheme.  For example, to specify the
    HDFS directory '/hbase' where the HDFS instance's namenode is
    running at namenode.example.org on port 9000, set this value to:
    hdfs://namenode.example.org:9000/hbase.  By default HBase writes
    into /tmp.  Change this configuration else all data will be lost
    on machine restart.
    &lt;/description&gt;
&lt;/property&gt;</pre>
</div></div></li><li><p>To enable HA for HAWQ, comment out the default <code>DFS_URL</code> property and uncomment <code>DFS_URL</code> in <code>hawq/gpinitsystem_config</code> as follows:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">#DFS_URL=${namenode}:${dfs.port}/hawq_data
#### For HA uncomment the following line
DFS_URL=${nameservices}/hawq_data</pre>
</div></div></li><li><p>Add the following properties to <code>hawq/hdfs-client.xml</code>:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">	&lt;property&gt;
		&lt;name&gt;dfs.nameservices&lt;/name&gt;
		&lt;value&gt;${nameservices}&lt;/value&gt;
	&lt;/property&gt;
	
	&lt;property&gt;
		&lt;name&gt;dfs.ha.namenodes.${nameservices}&lt;/name&gt;
		&lt;value&gt;${namenode1id},${namenode2id}&lt;/value&gt;
	&lt;/property&gt;
	
	&lt;property&gt;
		&lt;name&gt;dfs.namenode.rpc-address.${nameservices}.${namenode1id}&lt;/name&gt;
		&lt;value&gt;${namenode}:8020&lt;/value&gt;
	&lt;/property&gt;
	
	&lt;property&gt;
		&lt;name&gt;dfs.namenode.rpc-address.${nameservices}.${namenode2id}&lt;/name&gt;
		&lt;value&gt;${standbynamenode}:8020&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.namenode.http-address.${nameservices}.${namenode1id}&lt;/name&gt;
		&lt;value&gt;${namenode}:50070&lt;/value&gt;
	&lt;/property&gt;
	
	&lt;property&gt;
		&lt;name&gt;dfs.namenode.http-address.${nameservices}.${namenode2id}&lt;/name&gt;
		&lt;value&gt;${standbynamenode}:50070&lt;/value&gt;
	&lt;/property&gt;
	
	&lt;property&gt;
		&lt;name&gt;dfs.client.failover.proxy.provider.${nameservices}&lt;/name&gt;
		&lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;
	&lt;/property&gt;</pre>
</div></div></li><li><span style="color: rgb(34,34,34);">On the standby Namenode, move <code>{dfs.namenode.name.dir}/</code></span><span style="color: rgb(34,34,34);"><code>current</code> to a backup directory</span> (or delete).<br/><br/></li><li><p>Reconfigure the cluster:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">icm_client reconfigure -l CLUSTERNAME -c LOCALDIR</pre>
</div></div></li><li><p>Start the cluster:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">icm_client start -l CLUSTERNAME</pre>
</div></div> <div class="aui-message warning shadowed information-macro">
<p class="title">Caution</p>
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<p>Running the <code>reconfigure </code>command on a secure cluster disables security in PHD-1.1.0.0 and PHD-1.1.1.0</p>
</div>
</div>
</li><li>Update the HIVE Metastore:<br/>Hive metastore contains references to <code>hdfs</code> path with <code><span style="text-decoration: none;">namenode:port</span> </code>in the url. This needs to be updated to use the nameservices so HIVE scripts can work when ever NameNode failure happens.<br/><strong>Note</strong>: Make sure metastore is not running and is backed up to a persistent store before running the update commands.<br/><br/><ol><li>Login to host configured as <code>hive-metastore</code>.<br/><br/></li><li><p>Display the current NameNode and hdfspath for hive warehouse directory:<br/><code>/usr/lib/gphd/hive/bin/metatool -listFSRoot<br/><br/></code></p></li><li><p>Run the following command:<br/><code>/usr/lib/gphd/hive/bin/metatool -updateLocation hdfs://&lt;nameservices&gt; hdfs://&lt;current_namenode&gt;:&lt;dfs_port&gt;</code><br/><br/>Where <code>nameservices</code> is the logical name used for the nameservices in a HA enabled cluster and <code>current_namenode</code> is the hostname of the NameNode on the cluster before reconfiguring to enable HA.</p> <div class="aui-message warning shadowed information-macro">
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<p>When specifying the <code>nameservices</code>, do not use underscores ('_'), for example, <code>phd_cluster</code>.</p>
</div>
</div>
</li></ol></li><li><p>Restart HAWQ services for your configuration changes to take effect. <br/>From the HAWQ master, as <code>gpadmin</code>, run the following:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">/etc/init.d/hawq start</pre>
</div></div></li></ol><h4 id="AdministeringPHDUsingtheCLI-DisableHA" style="text-align: left;"><span class="confluence-anchor-link" id="AdministeringPHDUsingtheCLI-DisableHA"></span></h4><h4 id="AdministeringPHDUsingtheCLI-DisablingHighAvailabilityonaCluster" style="text-align: left;">Disabling High Availability on a Cluster</h4> <div class="aui-message hint shadowed information-macro">
<p class="title">Important</p>
<span class="aui-icon icon-hint">Icon</span>
<div class="message-content">
<p> <span>You must disable high availability before upgrading a cluster.</span></p>
</div>
</div>
<p style="text-align: left;">To disable high availability:</p><ol style="text-align: left;"><li><p>Synchronize the active and standby Namenode data. On the Namenode, run:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">sudo -u hdfs hdfs dfsadmin -safemode enter
sudo -u hdfs hdfs dfsadmin -saveNamespace</pre>
</div></div></li><li><p>Stop the cluster.  On the Admin node, run:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">icm_client stop -l CLUSTERNAME</pre>
</div></div></li><li><p>For HAWQ users, stop HAWQ:</p><p>From the HAWQ master, as <code>gpadmin</code>, run the following:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">/etc/init.d/hawq stop</pre>
</div></div></li><li><p>Back up the Namenode data. On both the active and standby Namenode copy <code><span style="color: rgb(34,34,34);">{dfs.namenode.name.dir}/</span></code><span style="color: rgb(34,34,34);">current</span> to a backup directory.</p></li><li><p>Fetch the configurations for the cluster in a local directory:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">icm_client fetch-configuration -l CLUSTERNAME -o LOCALDIR</pre>
</div></div></li><li>Edit <code>clusterConfig.xml</code> as follows:<br/><p>Uncomment out <code>secondarynamenode</code> role in <code>hdfs</code> service</p><p>Comment <code>standbynamenode</code> and <code>journalnode</code> roles in <code>hdfs</code> service</p><p>Comment <code>nameservices</code>, <code>namenode1id</code>, <code>namenode2id</code>, <code>journalpath</code>, and <code>journalport</code> entries in <code>serviceConfigGlobals<br/><br/></code></p></li><li><p>Edit <code>hdfs/hdfs-site.xml</code> as follows:<br/>Comment the following properties:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">&lt;property&gt; 
  &lt;name&gt;dfs.nameservices&lt;/name&gt; 
  &lt;value&gt;${nameservices}&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
  &lt;name&gt;dfs.ha.namenodes.${nameservices}&lt;/name&gt; 
  &lt;value&gt;${namenode1id},${namenode2id}&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
  &lt;name&gt;dfs.namenode.rpc-address.${nameservices}.${namenode1id}&lt;/name&gt; 
  &lt;value&gt;${namenode}:8020&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
  &lt;name&gt;dfs.namenode.rpc-address.${nameservices}.${namenode2id}&lt;/name&gt; 
  &lt;value&gt;${standbynamenode}:8020&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
  &lt;name&gt;dfs.namenode.http-address.${nameservices}.${namenode1id}&lt;/name&gt; 
  &lt;value&gt;${namenode}:50070&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
  &lt;name&gt;dfs.namenode.http-address.${nameservices}.${namenode2id}&lt;/name&gt; 
  &lt;value&gt;${standbynamenode}:50070&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
  &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; 
  &lt;value&gt;qjournal://${journalnode}/${nameservices}&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
  &lt;name&gt;dfs.client.failover.proxy.provider.${nameservices}&lt;/name&gt; 
  &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
  &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; 
  &lt;value&gt;
  sshfence
  shell(/bin/true)
  &lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt;
  &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;
  &lt;value&gt;/home/hdfs/.ssh/id_rsa&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt; 
  &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; 
  &lt;value&gt;${journalpath}&lt;/value&gt; 
&lt;/property&gt; 

&lt;!-- Namenode Auto HA related properties --&gt; 
&lt;property&gt;
   &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;
   &lt;value&gt;true&lt;/value&gt;
 &lt;/property&gt;
&lt;!-- END Namenode Auto HA related properties --&gt;</pre>
</div></div><p>Uncomment the following properties</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">&lt;property&gt;
  &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
  &lt;value&gt;${secondarynamenode}:50090&lt;/value&gt;
  &lt;description&gt;
    The secondary namenode http server address and port.
  &lt;/description&gt;
&lt;/property&gt;</pre>
</div></div></li><li><p>Edit <code>yarn/yarn-site.xml</code></p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">&lt;property&gt;
    &lt;name&gt;mapreduce.job.hdfs-servers&lt;/name&gt;
    &lt;value&gt;hdfs://${namenode}:${dfs.port}&lt;/value&gt;
&lt;/property&gt;
</pre>
</div></div></li><li><p>Edit <code>hdfs/core-site.xml</code> as follows:</p><p>Set the following property key value:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">&lt;property&gt;
  &lt;name&gt;fs.defaultFS&lt;/name&gt;
  &lt;value&gt;hdfs://${namenode}:${dfs.port}&lt;/value&gt; 
  &lt;description&gt;The name of the default file system.  A URI whose
  scheme and authority determine the FileSystem implementation.  The
  uri's scheme determines the config property (fs.SCHEME.impl) naming
  the FileSystem implementation class.  The uri's authority is used to
  determine the host, port, etc. for a filesystem.&lt;/description&gt;
&lt;/property&gt;</pre>
</div></div><p>Comment following property:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">&lt;property&gt;
   &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;
   &lt;value&gt;${zookeeper-server}:${zookeeper.client.port}&lt;/value&gt;
 &lt;/property&gt;</pre>
</div></div></li><li><p>Edit <code>hbase/hbase-site.xml</code> as follows:<br/>Set the following property key value:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">&lt;property&gt;
    &lt;name&gt;hbase.rootdir&lt;/name&gt;
    &lt;value&gt;hdfs://${namenode}:${dfs.port}/apps/hbase/data&lt;/value&gt;
    &lt;description&gt;The directory shared by region servers and into
    which HBase persists.  The URL should be 'fully-qualified'
    to include the filesystem scheme.  For example, to specify the
    HDFS directory '/hbase' where the HDFS instance's namenode is
    running at namenode.example.org on port 9000, set this value to:
    hdfs://namenode.example.org:9000/hbase.  By default HBase writes
    into /tmp.  Change this configuration else all data will be lost
    on machine restart.
    &lt;/description&gt;
&lt;/property&gt;</pre>
</div></div></li><li><p>To disable HA for HAWQ, uncomment the default <code>DFS_URL</code> property and comment out <code>DFS_URL</code> in <code>hawq/gpinitsystem_config</code> as follows:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">DFS_URL=${namenode}:${dfs.port}/hawq_data
#### For Non-HA comment the following line
#DFS_URL=${nameservices}/hawq_data</pre>
</div></div></li><li><p>Comment the following properties to <code>hawq/hdfs-client.xml</code>:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">	&lt;property&gt;
		&lt;name&gt;dfs.nameservices&lt;/name&gt;
		&lt;value&gt;${nameservices}&lt;/value&gt;
	&lt;/property&gt;
	
	&lt;property&gt;
		&lt;name&gt;dfs.ha.namenodes.${nameservices}&lt;/name&gt;
		&lt;value&gt;${namenode1id},${namenode2id}&lt;/value&gt;
	&lt;/property&gt;
	
	&lt;property&gt;
		&lt;name&gt;dfs.namenode.rpc-address.${nameservices}.${namenode1id}&lt;/name&gt;
		&lt;value&gt;${namenode}:8020&lt;/value&gt;
	&lt;/property&gt;
	
	&lt;property&gt;
		&lt;name&gt;dfs.namenode.rpc-address.${nameservices}.${namenode2id}&lt;/name&gt;
		&lt;value&gt;${standbynamenode}:8020&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.namenode.http-address.${nameservices}.${namenode1id}&lt;/name&gt;
		&lt;value&gt;${namenode}:50070&lt;/value&gt;
	&lt;/property&gt;
	
	&lt;property&gt;
		&lt;name&gt;dfs.namenode.http-address.${nameservices}.${namenode2id}&lt;/name&gt;
		&lt;value&gt;${standbynamenode}:50070&lt;/value&gt;
	&lt;/property&gt;
	
	&lt;property&gt;
		&lt;name&gt;dfs.client.failover.proxy.provider.${nameservices}&lt;/name&gt;
		&lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;
	&lt;/property&gt;</pre>
</div></div></li><li><p>Run the following command to reconfigure the cluster with your new configuration file:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;"> icm_client reconfigure -l CLUSTERNAME -c LOCALDIR</pre>
</div></div></li><li><p>Start the cluster:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">icm_client start -l CLUSTERNAME</pre>
</div></div></li><li>Update the HIVE Metastore:<br/>Hive metastore contains references to <code>hdfs</code> path with <code>nameservices </code>in the url. This needs to be updated to use the <span style="text-decoration: none;">namenode:port</span>.<br/><strong>Note</strong>: Make sure metastore is not running and is backed up to a persistent store before running the update commands.<br/><ol><li>Login to host configured as <code>hive-metastore</code>.<br/><br/></li><li><p>Display the current NameNode and hdfspath for hive warehouse directory:<br/><code>/usr/lib/gphd/hive/bin/metatool -listFSRoot<br/><br/></code></p><p>Run the following command:<br/><code>/usr/lib/gphd/hive/bin/metatool -updateLocation hdfs://&lt;current_namenode&gt;:&lt;dfs_port&gt; hdfs://&lt;nameservices&gt;</code><br/><br/>Where <code>nameservices</code> is the logical name used for the nameservices in a HA enabled cluster and <code>current_namenode</code> is the hostname of the NameNode on the cluster after reconfiguring to disable HA.</p> <div class="aui-message warning shadowed information-macro">
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<p>When specifying the <code>nameservices</code>, do not use underscores ('_'), for example, <code>phd_cluster</code>.</p>
</div>
</div>
<p><code> </code></p></li></ol></li><li><p>For HAWQ users, restart HAWQ services for your configuration changes to take effect. <br/>From the HAWQ master, as <code>gpadmin</code>, run the following:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">/etc/init.d/hawq start</pre>
</div></div></li></ol><h4 id="AdministeringPHDUsingtheCLI-HAAdminCommandReference" style="text-align: left;">HAAdmin Command Reference</h4><ul style="text-align: left;"><li><code>hdfs haadmin</code> prints help for all subcommands and options. <code>serviceid </code>is the logical name configured for each NameNode, as <code>namenode1id</code> and <code>namenode2id</code>, in <code>clusterConfig.xml</code></li><li>Check state of a given NameNode:<em> <br/></em></li></ul><p style="margin-left: 60.0px;text-align: left;"><code>hdfs haadmin -getServiceState &lt;serviceid&gt; Ex : hdfs haadmin -getServiceState nn1</code></p><ul style="text-align: left;"><li>Transition a given NameNode to standby:<em> <br/></em></li></ul><p style="margin-left: 60.0px;text-align: left;"><code>hdfs haadmin -transitionToStandby &lt;serviceid&gt;</code> <em><br/></em></p><p style="margin-left: 60.0px;text-align: left;">For example:</p><p style="margin-left: 60.0px;text-align: left;"><code>hdfs haadmin -transitionToStandby  nn1</code></p><ul style="text-align: left;"><li>Transition a given NameNode to active:</li></ul><p style="margin-left: 60.0px;text-align: left;">hdfs haadmin -transitionToActive &lt;serviceid&gt;</p><p style="margin-left: 60.0px;text-align: left;">For example:</p><p style="margin-left: 60.0px;text-align: left;"><code>hdfs haadmin -transitionToActive  nn1</code></p><ul style="text-align: left;"><li>Failover between two NameNode: </li></ul><p style="margin-left: 60.0px;text-align: left;"><code>hdfs haadmin --failover &lt;serviceid&gt; &lt;serviceid&gt;</code></p><p style="margin-left: 60.0px;text-align: left;">For example:</p><p style="margin-left: 60.0px;text-align: left;"><code>hdfs haadmin --failover nn1 nn2</code> </p><h3 id="AdministeringPHDUsingtheCLI-Security">Security</h3><p>PHD clusters can configured to use Kerberos authentication.</p><p>Kerberos is a network authentication protocol that provides strong authentication for client/server applications using secret-key cryptography.</p><h4 id="AdministeringPHDUsingtheCLI-EnablingKerberosAuthentication">Enabling Kerberos Authentication</h4><p>You must install and configure Kerberos to enable security in Pivotal HD 1.1.x. and higher. Complete instructions are provided in the <em>PHD Stack and Tools Reference Guide</em>.</p><h4 id="AdministeringPHDUsingtheCLI-DisableKerberos"><span class="confluence-anchor-link" id="AdministeringPHDUsingtheCLI-DisableKerberos"></span></h4><h4 id="AdministeringPHDUsingtheCLI-DisablingKerberosAuthentication">Disabling Kerberos Authentication</h4><p>You need to disable Security before upgrading the cluster. To disable security do the following:</p><ol><li><p>Stop the cluster</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[gpadmin]# icm_client stop -l &lt;CLUSTER_NAME&gt;</pre>
</div></div></li><li><p>If you have HBase installed and HBase-to-Zookeeper communication is secured (true in most cases), do the following steps.Tables created while HBase is secure have ACLs set on them which only allow SASL authenticated users to modify them. In order to operate in non-secure mode, you must do the following. You can skip these steps if you don't have HBase installed.</p><p> </p><ol><li><p>Start just the Zookeeper service. </p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[gpadmin]# icm_client start -l &lt;CLUSTER_NAME&gt; -s zookeeper</pre>
</div></div></li><li>On HBase master:<ol><li><p>Run Zookeeper CLI: </p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[gpadmin]# sudo -u hbase hbase zkcli</pre>
</div></div></li><li><p>Check if there are any regions in transition. Output <code>[]</code> means there are NO regions in tranistion at the moment. and you don't need to set ACL on this sub znode.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[zk: node2.phddev.local:2181,node1.phddev.local:2181,node3.phddev.local:2181(CONNECTED) 0] ls /hbase/region-in-transition
[]</pre>
</div></div><p>If there are regions in transition, either wait for them to finish (start cluster again) or set ACL to make then controllable by world. Do this for all the regions. <br/>For example, if you see a region like 156781230:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[zk: node2.phddev.local:2181,node1.phddev.local:2181,node3.phddev.local:2181(CONNECTED) 1] setAcl /hbase/region-in-tranistion/156781230 world:anyone:cdrwa</pre>
</div></div></li><li><p>Check if there are unassigned regions. If there are any, set ACL to be controllable by world:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[zk: node2.phddev.local:2181,node1.phddev.local:2181,node3.phddev.local:2181(CONNECTED) 2] ls /hbase/unassigned
[123456789]
[zk: node2.phddev.local:2181,node1.phddev.local:2181,node3.phddev.local:2181(CONNECTED) 3] setAcl /hbase/unassigned/123456789 world:anyone:cdrwa</pre>
</div></div></li><li><p class="p1">Do this for all the tables where ACL is set to anything other than <strong><code>world:anyone:cdrwa</code></strong> else they won't be readable while security is disabled.</p> <div class="aui-message hint shadowed information-macro">
<span class="aui-icon icon-hint">Icon</span>
<div class="message-content">
<p><span class="aui-icon icon-hint"> </span>If you're only disabling security temporarily for upgrade and intend to enable it again after upgrade, you may skip setting ACLs on tables.</p>
</div>
</div>
<p> </p><p> </p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[zk: node2.phddev.local:2181,node1.phddev.local:2181,node3.phddev.local:2181(CONNECTED) 4] ls /hbase/table
[hbase:meta, hbase:namespace, testtable]
[zk: node2.phddev.local:2181,node1.phddev.local:2181,node3.phddev.local:2181(CONNECTED) 5] getAcl /hbase/table/hbase:meta
'world,'anyone
:cdrwa
[zk: node2.phddev.local:2181,node1.phddev.local:2181,node3.phddev.local:2181(CONNECTED) 6] getAcl /hbase/table/testtable
'world,'anyone
:r
'sasl,'hbase
:cdrwa
# Here is testtable is not world writable and has SASL enabled. If you want to use this table while in non-secure mode, do the following.
[zk: node2.phddev.local:2181,node1.phddev.local:2181,node3.phddev.local:2181(CONNECTED) 7] setAcl /hbase/table/testtable world:anyone:cdrwa
 
# Verify ACL has been set
[zk: node2.phddev.local:2181,node1.phddev.local:2181,node3.phddev.local:2181(CONNECTED) 8] getAcl /hbase/table/testtable
'world,'anyone
:cdrwa</pre>
</div></div> <div class="aui-message warning shadowed information-macro">
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<p class="p1">Alternatively, you may also remove the znode /<code>hbase</code> or any of its sub-znodes such as <code>/hbase/table</code> as they get re-created on HBase service restart. Also, this should only be done if HBase-master and HBase-regionserver were shutdown properly and there is no transient state yet to be synced back. </p><p class="p1"><strong>You must use this option with extreme caution and only if you're having trouble starting HBase service. Careless use may cause data loss.</strong></p><p class="p1">To remove a znode, for example<code>/hbase/table</code>, run the following</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[zk: node2.phddev.local:2181,node1.phddev.local:2181,node3.phddev.local:2181(CONNECTED) 9] rmr /hbase/table</pre>
</div></div>
</div>
</div>
</li><li><p>Quit the zookeeper CLI on HBase master node. You can disconnect from HBase master now.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[zk: node2.phddev.local:2181,node1.phddev.local:2181,node3.phddev.local:2181(CONNECTED) 10] quit</pre>
</div></div></li></ol></li><li><p>Stop the Zookeeper service from ICM Admin node. </p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[gpadmin]# icm_client stop -l test -s zookeeper</pre>
</div></div></li></ol></li><li><p>You now need to remove security related changes from other service configuration files and scripts. You can use <code>icm_client reconfigure</code> for this purpose. Make sure it runs successfully on all nodes before proceeding further. Perform the following steps on ICM Admin node.</p><ol><li><p>Fetch the current configuration in a directory <code>SecureConfiguration</code> </p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[gpadmin]# icm_client fetch-configuration -o SecureConfiguration</pre>
</div></div></li><li>Copy <code>SecureConfiguration</code> to <code>NonSecureConfiguration</code></li><li><p>Change to <code>NonSecureConfiguration</code> directory and make the following modifications to disable security-related changes:</p> <div class="aui-message warning shadowed information-macro">
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<p>In general, while removing properties you may ignore and proceed further if it's already missing as it may happen depending on how the cluster was secured originally. Similarly, while editing properties if it already has recommended value, you may safely proceed further.</p>
</div>
</div>
<p><strong><br/></strong></p></li><ol><li><p>Remove the following from <code>hdfs/core-site.xml</code> (If present. Ignore if they're not present which may be the case in clusters secured without ICM's help)</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeHeader panelHeader pdl" style="border-bottom-width: 1px;"><b>hdfs/core-site.xml</b></div><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">&lt;property&gt;
  &lt;name&gt;hadoop.security.authentication&lt;/name&gt;
  &lt;value&gt;kerberos&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;hadoop.security.authorization&lt;/name&gt;
  &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
 
 
&lt;!-- THE PROPERTY BELOW IS OPTIONAL: IT ENABLES ON WIRE RPC ENCRYPTION --&gt;
 
&lt;property&gt;
  &lt;name&gt;hadoop.rpc.protection&lt;/name&gt;
  &lt;value&gt;privacy&lt;/value&gt;
&lt;/property&gt;</pre>
</div></div></li><li><p>Remove the following from <code>hdfs/hdfs-site.xml</code>. (If present. Ignore if they're not present which may be the case in clusters secured without ICM's help) </p><div class="code panel pdl" style="border-width: 1px;"><div class="codeHeader panelHeader pdl" style="border-bottom-width: 1px;"><b>hdfs/hdfs-site.xml</b></div><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">&lt;property&gt;
  &lt;name&gt;dfs.block.access.token.enable&lt;/name&gt;
  &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
 
&lt;!-- name node secure configuration info --&gt;
 
&lt;property&gt;
  &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt;
  &lt;value&gt;/etc/security/phd/keytab/hdfs.service.keytab&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt;
  &lt;value&gt;hdfs/_HOST@REALM&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;dfs.namenode.kerberos.http.principal&lt;/name&gt;
  &lt;value&gt;HTTP/_HOST@REALM&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt;
  &lt;value&gt;HTTP/_HOST@REALM&lt;/value&gt;
&lt;/property&gt;
 
&lt;!-- (optional) secondary name node secure configuration info --&gt;
 
&lt;property&gt;
  &lt;name&gt;dfs.secondary.namenode.keytab.file&lt;/name&gt;
  &lt;value&gt;/etc/security/phd/keytab/hdfs.service.keytab&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;dfs.secondary.namenode.kerberos.principal&lt;/name&gt;
  &lt;value&gt;hdfs/_HOST@REALM&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;dfs.secondary.namenode.kerberos.http.principal&lt;/name&gt;
  &lt;value&gt;HTTP/_HOST@REALM&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;dfs.secondary.namenode.kerberos.internal.spnego.principal&lt;/name&gt;
  &lt;value&gt;HTTP/_HOST@REALM&lt;/value&gt;
&lt;/property&gt;

&lt;!-- If HA is configured --&gt;
&lt;property&gt;
  &lt;name&gt;dfs.journalnode.keytab.file&lt;/name&gt;
  &lt;value&gt;/etc/security/phd/keytab/hdfs.keytab&lt;/value&gt; &lt;!-- path to the HDFS keytab --&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;dfs.journalnode.kerberos.principal&lt;/name&gt;
  &lt;value&gt;hdfs/_HOST@REALM.COM&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;dfs.journalnode.kerberos.internal.spnego.principal&lt;/name&gt;
  &lt;value&gt;HTTP/_HOST@REALM.COM&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;dfs.datanode.kerberos.principal&lt;/name&gt;
  &lt;value&gt;hdfs/_HOST@REALM&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;dfs.datanode.kerberos.http.principal&lt;/name&gt;
  &lt;value&gt;HTTP/_HOST@REALM&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;dfs.datanode.keytab.file&lt;/name&gt;
  &lt;value&gt;/etc/security/phd/keytab/hdfs.service.keytab&lt;/value&gt;
&lt;/property&gt;
  
&lt;property&gt;
  &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;
  &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;dfs.web.authentication.kerberos.principal&lt;/name&gt;
  &lt;value&gt;HTTP/_HOST@REALM&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;dfs.web.authentication.kerberos.keytab&lt;/name&gt;
  &lt;value&gt;/etc/security/phd/keytab/hdfs.service.keytab&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;dfs.encrypt.data.transfer&lt;/name&gt;
  &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;dfs.encrypt.data.transfer.algorithm&lt;/name&gt;
  &lt;value&gt;rc4&lt;/value&gt;
  &lt;description&gt;may be "rc4" or "3des" - 3des has a significant performance impact&lt;/description&gt;
&lt;/property&gt;
 
&lt;!-- If hive is configured --&gt;
&lt;property&gt;
  &lt;name&gt;hadoop.proxyuser.hive.hosts&lt;/name&gt;
  &lt;value&gt;*&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;hadoop.proxyuser.hive.groups&lt;/name&gt;
  &lt;value&gt;*&lt;/value&gt;
&lt;/property&gt;


&lt;!-- If oozie is configured --&gt;
&lt;property&gt;
  &lt;name&gt;hadoop.proxyuser.oozie.hosts&lt;/name&gt;
  &lt;value&gt;*&lt;/value&gt;
&lt;/property&gt; 
&lt;property&gt;
  &lt;name&gt;hadoop.proxyuser.oozie.groups&lt;/name&gt;
  &lt;value&gt;*&lt;/value&gt;
&lt;/property&gt;</pre>
</div></div></li><li><p>Edit the following properties in <code>hdfs/hdfs-site.xml</code> to values as described below:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeHeader panelHeader pdl" style="border-bottom-width: 1px;"><b>hdfs/hdfs-site.xml</b></div><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">&lt;!-- For PHD-1.1.1.0 or PHD-1.1.0.0, set this to false --&gt;
&lt;property&gt;
  &lt;name&gt;dfs.client.read.shortcircuit&lt;/name&gt;
  &lt;value&gt;false&lt;/value&gt;
&lt;/property&gt;
 
OR 
&lt;!-- For PHD greater than or equal to 2.0, set this to true --&gt;
&lt;property&gt;
  &lt;name&gt;dfs.client.read.shortcircuit&lt;/name&gt;
  &lt;value&gt;false&lt;/value&gt;
&lt;/property&gt;
 
&lt;!-- Following properties should have these values --&gt;
&lt;property&gt;
  &lt;name&gt;dfs.datanode.data.dir.perm&lt;/name&gt;
  &lt;value&gt;700&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;dfs.datanode.address&lt;/name&gt;
  &lt;value&gt;0.0.0.0:50010&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;dfs.datanode.http.address&lt;/name&gt;
  &lt;value&gt;0.0.0.0:50075&lt;/value&gt;
&lt;/property&gt;</pre>
</div></div></li><li><p>Edit <code>hdfs/hadoop-policy.xml</code>. Search for all instances of <code>&lt;value&gt;</code> and replace all instances of <strong><code>hdfs</code></strong> with <strong><code>${HADOOP_HDFS_USER}</code></strong> and <strong><code>yarn</code></strong> with <strong><code>${HADOOP_YARN_USER}</code></strong>. Some of the known instances are:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeHeader panelHeader pdl" style="border-bottom-width: 1px;"><b>hdfs/hadoop-policy.xml</b></div><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">  &lt;property&gt;
    &lt;name&gt;security.refresh.usertogroups.mappings.protocol.acl&lt;/name&gt;
    &lt;value&gt;${HADOOP_HDFS_USER}&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;security.refresh.policy.protocol.acl&lt;/name&gt;
    &lt;value&gt;${HADOOP_HDFS_USER}&lt;/value&gt;
  &lt;/property&gt;
  
  &lt;property&gt;
    &lt;name&gt;security.qjournal.service.protocol.acl&lt;/name&gt;
    &lt;value&gt;${HADOOP_HDFS_USER}&lt;/value&gt;
  &lt;/property&gt;
  
  &lt;!-- YARN Protocols --&gt;
  &lt;property&gt;
    &lt;name&gt;security.resourcetracker.protocol.acl&lt;/name&gt;
    &lt;value&gt;${HADOOP_YARN_USER}&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;security.admin.protocol.acl&lt;/name&gt;
    &lt;value&gt;${HADOOP_YARN_USER}&lt;/value&gt;
  &lt;/property&gt;</pre>
</div></div></li><li><p>Remove the following from <code>yarn/yarn-site.xml</code>. (If present. Please ignore if they're not present which may be the case in clusters secured without ICM's help)</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeHeader panelHeader pdl" style="border-bottom-width: 1px;"><b>yarn/yarn-site.xml</b></div><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">&lt;property&gt;
  &lt;name&gt;yarn.resourcemanager.principal&lt;/name&gt;
  &lt;value&gt;yarn/_HOST@REALM&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;yarn.resourcemanager.keytab&lt;/name&gt;
  &lt;value&gt;/etc/security/phd/keytab/yarn.service.keytab&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;yarn.nodemanager.principal&lt;/name&gt;
  &lt;value&gt;yarn/_HOST@REALM&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;yarn.nodemanager.keytab&lt;/name&gt;
  &lt;value&gt;/etc/security/phd/keytab/yarn.service.keytab&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;yarn.nodemanager.container-executor.class&lt;/name&gt;
  &lt;value&gt;org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;yarn.nodemanager.linux-container-executor.group&lt;/name&gt;
  &lt;value&gt;yarn&lt;/value&gt;
&lt;/property&gt;
  
&lt;property&gt;
  &lt;name&gt;yarn.web-proxy.keytab&lt;/name&gt;
  &lt;value&gt;/etc/security/phd/keytab/yarn.service.keytab&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;yarn.web-proxy.principal&lt;/name&gt;
  &lt;value&gt;yarn/_HOST@REALM&lt;/value&gt;
&lt;/property&gt;</pre>
</div></div></li><li><p>Remove the following from <code>yarn/mapred-site.xml</code> </p><div class="code panel pdl" style="border-width: 1px;"><div class="codeHeader panelHeader pdl" style="border-bottom-width: 1px;"><b>yarn/mapred-site.xml</b></div><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">&lt;property&gt;
  &lt;name&gt;mapreduce.jobhistory.keytab&lt;/name&gt;
  &lt;value&gt;/etc/security/phd/keytab/mapred.service.keytab&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;mapreduce.jobhistory.principal&lt;/name&gt;
  &lt;value&gt;mapred/_HOST@REALM&lt;/value&gt;
&lt;/property&gt;</pre>
</div></div></li><li><p>Edit <code>yarn/container-executor.cfg</code>. </p><div class="code panel pdl" style="border-width: 1px;"><div class="codeHeader panelHeader pdl" style="border-bottom-width: 1px;"><b>yarn/container-executor.cfg</b></div><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">#configured value of yarn.nodemanager.linux-container-executor.group
yarn.nodemanager.linux-container-executor.group=
#comma separated list of users who can not run applications
banned.users=
#Prevent other super-users
min.user.id=1000</pre>
</div></div></li><li><p>Remove the following from <code>yarn/container-executor.cfg</code> </p><div class="code panel pdl" style="border-width: 1px;"><div class="codeHeader panelHeader pdl" style="border-bottom-width: 1px;"><b>yarn/container-executor.cfg</b></div><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">yarn.nodemanager.local-dirs=/data/1/yarn/nm-local-dir
yarn.nodemanager.log-dirs=/data/1/yarn/userlogs</pre>
</div></div></li><li><p>Remove the following from <code>zookeeper/zoo.cfg</code> </p><div class="code panel pdl" style="border-width: 1px;"><div class="codeHeader panelHeader pdl" style="border-bottom-width: 1px;"><b>zookeeper/zoo.cfg</b></div><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">authProvider.1=org.apache.zookeeper.server.auth.SASLAuthenticationProvider
jaasLoginRenew=3600000
 
kerberos.removeHostFromPrincipal=true
kerberos.removeRealmFromPrincipal=true</pre>
</div></div></li><li><p>For PHD-2.0.0.0 and higher, edit <code>zookeeper/java.env</code> to remove <code>-<span style="color: rgb(0,51,102);">Djava.security.auth.login.config<span>=/etc/gphd/zookeeper/conf/jaas.conf</span></span></code> from JVMFLAGS</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeHeader panelHeader pdl" style="border-bottom-width: 1px;"><b>zookeeper/java.env</b></div><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">export JVMFLAGS="-Xmx2048m"</pre>
</div></div></li><li><p>Remove the following from <code>hbase/hbase-site.xml</code> </p><div class="code panel pdl" style="border-width: 1px;"><div class="codeHeader panelHeader pdl" style="border-bottom-width: 1px;"><b>hbase/hbase-site.xml</b></div><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">&lt;property&gt;
  &lt;name&gt;hbase.security.authentication&lt;/name&gt;
  &lt;value&gt;kerberos&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;hbase.security.authorization&lt;/name&gt;
  &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;hbase.rpc.engine&lt;/name&gt;
  &lt;value&gt;org.apache.hadoop.hbase.security.access.AccessController&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;hbase.coprocessor.master.classes&lt;/name&gt;
  &lt;value&gt;org.apache.hadoop.hbase.security.access.AccessController, org.apache.hadoop.hbase.security.token.TokenProvider&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;hbase.coprocessor.region.classes&lt;/name&gt;
  &lt;value&gt;org.apache.hadoop.hbase.security.access.AccessController, org.apache.hadoop.hbase.security.token.TokenProvider&lt;/value&gt;
&lt;/property&gt;
 
&lt;!-- HBase secure region server configuration --&gt;
&lt;property&gt;
  &lt;name&gt;hbase.regionserver.kerberos.principal&lt;/name&gt;
  &lt;value&gt;hbase/_HOST@REALM&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;hbase.regionserver.keytab.file&lt;/name&gt;
  &lt;value&gt;/etc/security/phd/keytab/hbase.service.keytab&lt;/value&gt;
&lt;/property&gt;
 
&lt;!-- HBase secure master configuration --&gt;
&lt;property&gt;
  &lt;name&gt;hbase.master.kerberos.principal&lt;/name&gt;
  &lt;value&gt;hbase/_HOST@REALM&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;hbase.master.keytab.file&lt;/name&gt;
  &lt;value&gt;/etc/security/phd/keytab/hbase.service.keytab&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;hbase.rest.keytab.file&lt;/name&gt;
  &lt;value&gt;path-to-rest-users-keytab&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;hbase.rest.kerberos.principal&lt;/name&gt;
  &lt;value&gt;rest-users-principal-name&lt;/value&gt;
&lt;/property&gt;</pre>
</div></div></li><li><p>Remove the following from <code>hbase/hbase-env.sh</code></p><div class="code panel pdl" style="border-width: 1px;"><div class="codeHeader panelHeader pdl" style="border-bottom-width: 1px;"><b>hbase/hbase-env.sh</b></div><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">export HBASE_OPTS="$HBASE_OPTS -Djava.security.auth.login.config=/etc/gphd/hbase/conf/jaas.conf"</pre>
</div></div></li><li><p>Remove the following from <code>hive/hive-site.xml</code> </p><div class="code panel pdl" style="border-width: 1px;"><div class="codeHeader panelHeader pdl" style="border-bottom-width: 1px;"><b>hive/hive-site.xml</b></div><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">&lt;property&gt;
  &lt;name&gt;hive.server2.authentication&lt;/name&gt;
  &lt;value&gt;KERBEROS&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;hive.server2.authentication.kerberos.principal&lt;/name&gt;
  &lt;value&gt;hive/_HOST@REALM&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;hive.server2.authentication.kerberos.keytab&lt;/name&gt;
  &lt;value&gt;/etc/security/phd/keytab/hive.keytab&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;hive.server2.enable.impersonation&lt;/name&gt;
  &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;hive.server2.enable.doAs&lt;/name&gt;
  &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;hive.metastore.sasl.enabled&lt;/name&gt;
  &lt;value&gt;true&lt;/value&gt;
  &lt;description&gt;If true, the metastore thrift interface will be secured with SASL. Clients
   must authenticate with Kerberos.&lt;/description&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;hive.security.authorization.enabled&lt;/name&gt;
  &lt;value&gt;true&lt;/value&gt;
  &lt;description&gt;enable or disable the hive client authorization&lt;/description&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;hive.security.authorization.createtable.owner.grants&lt;/name&gt;
  &lt;value&gt;ALL&lt;/value&gt;
  &lt;description&gt;the privileges automatically granted to the owner whenever a table gets created.
   An example like "select,drop" will grant select and drop privilege to the owner of the table.
   You may change this value if you desire lower privileges on create.&lt;/description&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;hive.metastore.kerberos.keytab.file&lt;/name&gt;
  &lt;value&gt;/etc/security/phd/keytab/hive.keytab&lt;/value&gt;
  &lt;description&gt;The path to the Kerberos Keytab file containing the metastore thrift
   server's service principal.&lt;/description&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;hive.metastore.kerberos.principal&lt;/name&gt;
  &lt;value&gt;hive-metastore/_HOST@REALM&lt;/value&gt;
  &lt;description&gt;The service principal for the metastore thrift server. The special string _HOST will be replaced automatically with the correct host name.&lt;/description&gt;
&lt;/property&gt;</pre>
</div></div></li><li><p>If present, remove the following from <code>hawq/hdfs-client.xml</code> </p><div class="code panel pdl" style="border-width: 1px;"><div class="codeHeader panelHeader pdl" style="border-bottom-width: 1px;"><b>hawq/hdfs-client.xml</b></div><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">&lt;property&gt;
  &lt;name&gt;hadoop.security.authentication&lt;/name&gt;
  &lt;value&gt;kerberos&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
  &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt;
  &lt;value&gt;HDFS_NAMENODE_PRINCIPAL&lt;/value&gt;
&lt;/property&gt;</pre>
</div></div></li><li><p>Remove the following from <code>hawq/gpinitsystem_config</code> </p><div class="code panel pdl" style="border-width: 1px;"><div class="codeHeader panelHeader pdl" style="border-bottom-width: 1px;"><b>hawq/gpinitsystem_config</b></div><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">KERBEROS_KEYFILE=/path/to/keytab/file
ENABLE_SECURE_FILESYSTEM=on</pre>
</div></div></li></ol><li><p>Run ICM <code>reconfigure</code> using <code>NonSecureConfiguration</code> we just modifed to push these changes to cluster nodes:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[gpadmin]# icm_client reconfigure -l &lt;CLUSTER_NAME&gt; -c NonSecureConfiguration</pre>
</div></div></li></ol></li><li><p>With Cluster services still stopped, <strong>co</strong><strong>mment</strong> the following lines (if present; ignore otherwise) in <code>/etc/default/hadoop-hdfs-datanode</code>  on <strong>ALL</strong> DataNodes. </p><div class="code panel pdl" style="border-width: 1px;"><div class="codeHeader panelHeader pdl" style="border-bottom-width: 1px;"><b>/etc/default/hadoop-hdfs-datanode on DataNode</b></div><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;"># secure operation stuff -- comment the following lines, if present and not commented. Ignore if a property is missing.
export HADOOP_SECURE_DN_USER=hdfs
export HADOOP_SECURE_DN_LOG_DIR=${HADOOP_LOG_DIR}/hdfs
export HADOOP_PID_DIR=/var/run/gphd/hadoop-hdfs/
export HADOOP_SECURE_DN_PID_DIR=${HADOOP_PID_DIR}</pre>
</div></div></li><li><p>For PHD-1.1.1.0 and lower, remove <code>/etc/gphd/zookeeper/conf/java.env</code> from all zookeeper-server nodes (if present). We recommend that you back-up the file before removing.</p></li><li>Remove security from any manually installed service following the reverse of instructions to enable them.</li><li><p>Start the Cluster. At this point, security should be disabled and you may run test commands to validate data is still accessible in non-secure mode. </p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[gpadmin]# icm_client start -l &lt;CLUSTER_NAME&gt;</pre>
</div></div></li></ol><h3 id="AdministeringPHDUsingtheCLI-UninstallingaCluster">Uninstalling a Cluster</h3><p>You must run the stop command to stop running clusters before running the <code>uninstall </code>command. You must also ensure that HAWQ has been stopped before uninstall.</p><p>You will be prompted as to whether you want to preserve the history metrics of the cluster; the default behavior is to preserve the history.</p><p> </p> <div class="aui-message warning shadowed information-macro">
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<p>Running the <code>uninstall </code>will not delete <code>dfs.data.dir</code>, <code>dfs.name.dir</code>, <code>dfs.mapred.dir</code> and <code>dfs.checkpoint.dir</code> directories. This is intentional behavior and preserves user data.</p>
</div>
</div>
<div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[gpadmin]# icm_client uninstall -h
Usage: icm_client uninstall [options]

Options:
  -h, --help            Show this help message and exit
  -v, --verbose         Increase output verbosity
  -l CLUSTERNAME, --clustername=CLUSTERNAME
                        The name of the cluster to be uninstalled
</pre>
</div></div><p><strong>Sample Usage</strong></p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">icm_client uninstall -l CLUSTERNAME</pre>
</div></div> <div class="aui-message warning shadowed information-macro">
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<p>If you had HAWQ installed as part of the cluster, you will have to manually reset the <code>limits.conf</code> and <code>sysctl.conf</code> files on the HAWQ nodes before you can reuse those nodes again.</p>
</div>
</div>
<p> </p><p><span class="confluence-anchor-link" id="AdministeringPHDUsingtheCLI-ManagingHAWQ"></span></p><h2 id="AdministeringPHDUsingtheCLI-ManagingHAWQ">Managing HAWQ</h2><p>Starting and stopping HAWQ can only be initiated directly on the HAWQ Master. More information about HAWQ can be found in the <em>Pivotal HAWQ 1.x Installation Guide</em> and the <em>Pivotal ADS 1.x Administrator Guide</em>.</p><h3 id="AdministeringPHDUsingtheCLI-InitializingHAWQ">Initializing HAWQ</h3><p>You must initialize HAWQ only once after the cluster has started and specifically after the HDFS is up and running:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[gpadmin]# source /usr/local/hawq/greenplum_path.sh
[gpadmin]# /etc/init.d/hawq init
</pre>
</div></div><p>Running the<code> init</code> command, completes the following:</p><ul><li>Initializes the HAWQ master and the segment hosts.</li><li>Starts the HAWQ master, segments, and the underlying postgres database.</li><li>Exchanges SSH keys between the Master and Segment nodes.</li></ul> <div class="aui-message warning shadowed information-macro">
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<ul><li>This operation takes a few minutes to complete.</li><li>If you need to initialize the HAWQ standby master refer to the <em>Pivotal HAWQ Installation Guide</em> for instructions</li></ul>
</div>
</div>
<p>If you have a HAWQ Standby master in your cluster configuration, initialize that by running the following:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;"># gpinitstandby -s &lt;HAWQ STANDBY MASTER FQDN&gt;</pre>
</div></div><h3 id="AdministeringPHDUsingtheCLI-StartingHAWQ">Starting HAWQ</h3><p>Run the <code>start</code> command to start up the HAWQ master and all the segments hosts including the postgres database.</p><p>Note that this is implicitly done as part of the HAWQ Initialization.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[gpadmin]# /etc/init.d/hawq start
</pre>
</div></div><h3 id="AdministeringPHDUsingtheCLI-StoppingHAWQ">Stopping HAWQ</h3><p>Run the <code>stop</code> command to stop the hawq master, segments hosts, and the postgres database on the HAWQ master.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[gpadmin]# /etc/init.d/hawq stop
</pre>
</div></div><h3 id="AdministeringPHDUsingtheCLI-ModifyingHAWQUserConfiguration">Modifying HAWQ User Configuration</h3><p>If you are using Pivotal Command Center, you must modify your HAWQ user configuration file.</p><p>This is because the Admin host is not part of the HAWQ cluster. Modifying the <code>pg_hba.conf </code>file on the HAWQ Master host, gives the Admin host the ability to remote query HAWQ .</p><ol><li>Logon to the HAWQ Master as user <code>gpadmin</code>.</li><li>In the <code>$MASTER_DATA_DIRECTORY/pg_hba.conf </code>(the location of the HAWQ Master Directory is defined in the <code>&lt;hawq.master.directory&gt;</code> section of the <code>clusterConfig.xml</code> file used for deployment of the Cluster.<br/> Find the entry:<br/> <code>host all gpadmin &lt;master_host_ip&gt;/32 trust</code> <br/> Change the subnet entry depending on your network configuration:<br/> <code>host all gpadmin &lt;master_host_ip&gt;/24 trust</code></li><li><p>Restart HAWQ</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">/etc/init.d/hawq restart
</pre>
</div></div></li></ol><p>Run the following command to test HAWQ from the Admin host:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">$ sudo -u gpadmin psql -h &lt;HAWQ MASTER NODE&gt; -p &lt;HAWQ PORT&gt; -U gpadmin postgres -c "select * from pg_stat_activity;"
</pre>
</div></div><h3 id="AdministeringPHDUsingtheCLI-ExpandingHAWQ">Expanding HAWQ</h3><p>HAWQ Segments can be expanded.</p><p>Before you expand a HAWQ segment you need to add slaves to the cluster by either:</p><ul><li>Running the <code>add-slaves</code> command (see <a href="#AdministeringPHDUsingtheCLI-ExpandingaCluster">Expanding a Cluster</a>)</li><li>Manually editing the <code>hawq-segments</code> section of the <code>clusterConfig.xml</code> file, then running the <code>reconfigure</code> command (see <a href="#AdministeringPHDUsingtheCLI-ReconfiguringaCluster">Reconfiguring a Cluster</a>)</li></ul><p>Once you have added the slaves, you can then expand HAWQ using the <code>gpexpand</code> command; refer to the <em>HAWQ Administration Guide - Expanding the HAWQ System </em>for details.</p><h2 id="AdministeringPHDUsingtheCLI-ManagingRolesandHosts">Managing Roles and Hosts</h2><p>Pivotal HD supports starting or stopping entire clusters or individual roles on a selected hosts. If you want to start and stop the roles manually follow these steps:</p><p>You have the following options when managing cluster and individual roles:</p><ul><li style="list-style-type: none;background-image: none;"><ul><li>Managing locally</li><li>Managing from the Admin Node</li></ul></li></ul><h3 id="AdministeringPHDUsingtheCLI-ManagingLocally">Managing Locally</h3><p>You can manage the service role on the target host locally. For example, to restart datanode:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">node100:gpadmin# ssh gpadmin@node100
gpadmin# sudo service hadoop-hdfs-namenode restart
</pre>
</div></div><h3 id="AdministeringPHDUsingtheCLI-ManagingRemotely">Managing Remotely</h3><p>You can manage the service role remotely across one of the target hosts. For example, to restart datanode:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">node100.gpadmin# massh node100 verbose 'sudo service hadoop-hdfs-datanode restart'
</pre>
</div></div><p>To restart all the datanodes remotely:</p><p>Create a newline separated file named <code>hostfile</code> that contains all the datanodes to <em>start</em>, <em>stop</em>, <em>restart</em>, or <em>check</em> status.</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">gpadmin# massh hostfile verbose 'sudo service hadoop-hdfs-datanode restart'
</pre>
</div></div><p style="margin-left: 30.0px;"><span class="confluence-anchor-link" id="AdministeringPHDUsingtheCLI-pivotalhdservicescripts"></span></p><p><strong>Pivotal HD Services Scripts</strong></p><p>The following table shows the service commands to <em>start</em>, <em>stop</em>, <em>restart</em>, or <em>check</em> status for each service role,.</p><div class="table-wrap"><table class="confluenceTable"><tbody style="margin-left: 30.0px;"><tr style="margin-left: 30.0px;"><th class="confluenceTh" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Role Name</p></th><th class="confluenceTh" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Service Command</p></th></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Namenode</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">sudo service hadoop-hdfs-namenode {starts|stop|status|restart}</pre>
</div></div></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Secondary NameNode</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">sudo service hadoop-hdfs-secondarynamenode {starts|stop|status|restart}</pre>
</div></div></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Datanode</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">sudo service hadoop-hdfs-datanode {starts|stop|status|restart}</pre>
</div></div></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Resource Manager</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">sudo service hadoop-yarn-resourcemanager {starts|stop|status|restart}</pre>
</div></div></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Node Manager</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">sudo service hadoop-yarn-nodemanager {starts|stop|status|restart}</pre>
</div></div></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">History Server</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">sudo service hadoop-mapreduce-historyserver {starts|stop|status|restart}</pre>
</div></div></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Zookeeper Server</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">sudo service zookeeper-server {starts|stop|status|restart}</pre>
</div></div></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">HBase Master</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">sudo service hbase-master {starts|stop|status|restart}</pre>
</div></div></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">HBase Region Server</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">sudo service hbase-regionserver {starts|stop|status|restart}</pre>
</div></div></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">HAWQ Master</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">sudo /etc/init.d/hawq {starts|stop|status|restart}</pre>
</div></div></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" colspan="1" style="margin-left: 30.0px;">Quorum Journal node</td><td class="confluenceTd" colspan="1"><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">sudo /etc/init.d/hadoop-hdfs-journalnode {start|stop|status|restart}</pre>
</div></div></td></tr></tbody></table></div><h2 id="AdministeringPHDUsingtheCLI-PivotalHDServicesReference">Pivotal HD Services Reference</h2><p style="margin-left: 30.0px;"><span class="confluence-anchor-link" id="AdministeringPHDUsingtheCLI-OverridingDirectoryPermissions"></span></p><p style="margin-left: 30.0px;"><span class="confluence-anchor-link" id="AdministeringPHDUsingtheCLI-OverridingDirectoryPermissions2"></span></p><h3 id="AdministeringPHDUsingtheCLI-OverridingDirectoryPermissions">Overriding Directory Permissions</h3><p>The following table shows the list of directories that Pivotal HD overrides with specific ownership and permissions.</p><p>Directories not mentioned in the below list follow standard Apache ownership and permission convention.</p><h4 id="AdministeringPHDUsingtheCLI-OntheLocalFilesystem" style="margin-left: 30.0px;">On the Local Filesystem</h4><div class="table-wrap"><table class="confluenceTable"><tbody style="margin-left: 30.0px;"><tr style="margin-left: 30.0px;"><th class="confluenceTh" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Service</p></th><th class="confluenceTh" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Directory</p></th><th class="confluenceTh" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Location</p></th><th class="confluenceTh" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Owner</p></th><th class="confluenceTh" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Permissions</p></th></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><strong>HDFS</strong></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>hadoop.tmp.dir</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">All hadoop nodes</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>hdfs:hadoop</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">777</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p> </p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>dfs.namenode.name.dir</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Namenode</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>hdfs:hadoop</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">700</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p> </p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>dfs.datanode.data.dir</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Datanodes</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>hdfs:hadoop</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">770</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p> </p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>dfs.namenode.checkpointdir</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Secondary Namenode</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>hdfs:hadoop</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">700</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" colspan="1"> </td><td class="confluenceTd" colspan="1" style="margin-left: 30.0px;"><em>dfs.journalnode.edits.dir<br/> </em></td><td class="confluenceTd" colspan="1">Journal Node</td><td class="confluenceTd" colspan="1">hdfs:hadoop</td><td class="confluenceTd" colspan="1">755</td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><strong>YARN</strong></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>mapreduce.cluster.local.dir</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">All yarn nodes</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>mapred:hadoop</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">755</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p> </p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>mapreduce.cluster.temp.dir</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">All yarn nodes</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>mapred:hadoop</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">755</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p> </p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>yarn.nodemanager.local-dirs</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Node Managers</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>yarn:yarn</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">755</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p> </p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>yarn.nodemanager.log-dirs</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Node Managers</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>yarn:yarn</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">755</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><strong>ZooKeeper</strong></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>dataDir (/var/lib/zookeeper)</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Zookeeper Servers</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>zookeeper:zookeeper</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">775</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p> </p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>dataDir/myid</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Zookeeper Servers</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>gpadmin</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">644</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><strong>HAWQ</strong></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>MASTER_DIRECTORY</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">HAWQ Master &amp; Standby</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>gpadmin:hadoop</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">755</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p> </p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>DATA_DIRECTORY</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">HAWQ Segments</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>gpadmin:hadoop</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">755</p></td></tr></tbody></table></div><h4 id="AdministeringPHDUsingtheCLI-OnHDFS" style="margin-left: 30.0px;">On HDFS</h4><div class="table-wrap"><table class="confluenceTable"><tbody style="margin-left: 30.0px;"><tr style="margin-left: 30.0px;"><th class="confluenceTh" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Service</p></th><th class="confluenceTh" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Directory</p></th><th class="confluenceTh" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Owner</p></th><th class="confluenceTh" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Permissions</p></th></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><strong>HDFS</strong></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>hadoop.tmp.dir</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>hdfs:hadoop</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">777</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p> </p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>/tmp</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>hdfs:hadoop</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">777</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p> </p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>mapreduce.jobtracker.system.dir</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>mapred:hadoop</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">700</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p> </p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>yarn.app.mapreduce.am.staging-dir (/user)</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>mapred:hadoop</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">777</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p> </p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>mapreduce.jobhistory.intermediate-done-dir (/user/history/done)</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>mapred:hadoop</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">777</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p> </p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>mapreduce.jobhistory.done-dir (/user/history/done)</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>mapred:hadoop</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">777</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p> </p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>yarn.nodemanager.remote-app-log-dir</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>mapred:hadoop</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">755</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><strong>HBase</strong></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>hbase directory (/apps/hbase/data)</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>hdfs:hadoop</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">775</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><strong>HAWQ</strong></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>hawq directory (/hawq_data)</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;"><em>hdfs:hadoop</em></p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">755</p></td></tr></tbody></table></div><h3 id="AdministeringPHDUsingtheCLI-PivotalHDUsersandGroups">Pivotal HD Users and Groups</h3><div class="table-wrap"><table class="confluenceTable"><tbody style="margin-left: 30.0px;"><tr style="margin-left: 30.0px;"><th class="confluenceTh" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Service</p></th><th class="confluenceTh" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Users</p></th><th class="confluenceTh" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Group</p></th><th class="confluenceTh" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Login</p></th></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">PHD</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">gpadmin</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">gpadmin</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Yes</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">HDFS</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">hdfs</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">hadoop</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Yes</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">MapReduce</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">mapred</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">hadoop</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Yes</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Hbase</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">hbase</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">hadoop</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">No</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Hive</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">hive</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">hadoop</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">No</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Zookeeper</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">zookeeper</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">zookeeper</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">No</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Yarn</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">yarn</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">yarn</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">No</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">PHD, HAWQ</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">postgres</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">postgres</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Yes</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Puppet</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">puppet</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">puppet</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">No</p></td></tr></tbody></table></div><p style="margin-left: 30.0px;"> </p><h3 id="AdministeringPHDUsingtheCLI-PivotalHDPorts">Pivotal HD Ports</h3><p>If you are running a firewall, ensure that the following ports are open</p><div class="table-wrap"><table class="confluenceTable"><tbody style="margin-left: 30.0px;"><tr style="margin-left: 30.0px;"><th class="confluenceTh" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Service</p></th><th class="confluenceTh" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Port</p></th></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">ssh</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">22</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">NameNode</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">8020 (Apache 9000)</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">NameNode Web UI</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">50070, 50470 (https)</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Secondary NameNode</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">50090</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">DataNode Communication</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">50010</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">DataNode IPC</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">50020</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">DataNode HTTP Address</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">50075</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">ResourceManager Web UI</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">8042,8088</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">ResourceManager</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">8030,8031,8032,8033</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">MapReduce Shuffle Port</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">7070</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Job History Server</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">10020</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Job History Web UI</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">19888</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">JobTracker</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">(Apache 9001)</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">JobTracker Web UI</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">(Apache 50030)</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">TaskTracker</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">(Apache 50060)</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Puppet</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">443,8140,61613</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">Jetty</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">8080</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">HBase Master</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">60000</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">HBase Master UI</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">60010</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">HBase RegionServer</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">60020</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">HBase RegionServer Web UI</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">60030</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">ZooKeeper Client</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">2181</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">ZooKeeper Leader</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">3888</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">ZooKeeper Peers</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">2888</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">HAWQ Master</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">8432</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">HAWQ Port Base</p></td><td class="confluenceTd" style="margin-left: 30.0px;"><p style="margin-left: 30.0px;">40000</p></td></tr><tr style="margin-left: 30.0px;"><td class="confluenceTd" colspan="1"><p style="margin-left: 30.0px;">Quorum Journal node port</p></td><td class="confluenceTd" colspan="1"><p style="margin-left: 30.0px;">8485</p></td></tr></tbody></table></div>
</div></div>
            </div><!-- end of content-->
            
            
          </div><!-- end of container -->
        </div><!--end of container-fluid-->
      </div><!--end of main-wrap-->

      <div class="site-footer desktop-only">
          <div class="container-fluid">
              <div class="site-footer-links">
                  <span class="version"><a href='/'>Pivotal Documentation</a></span>
                  <span>&copy;
                      <script>
                          var d = new Date();
                          document.write(d.getFullYear());
                      </script>
                      <a href='http://gopivotal.com'>Pivotal Software</a> Inc. All Rights Reserved.
                  </span>
              </div>
          </div>
      </div>

      <script type="text/javascript">
          (function() {
              var didInit = false;
              function initMunchkin() {
                  if(didInit === false) {
                      didInit = true;
                      Munchkin.init('625-IUJ-009');
                  }
              }
              var s = document.createElement('script');
              s.type = 'text/javascript';
              s.async = true;
              s.src = document.location.protocol + '//munchkin.marketo.net/munchkin.js';
              s.onreadystatechange = function() {
                  if (this.readyState == 'complete' || this.readyState == 'loaded') {
                      initMunchkin();
                  }
              };
              s.onload = initMunchkin;
              document.getElementsByTagName('head')[0].appendChild(s);
          })();
      </script>
  </div><!--end of viewport-->
  <div id="scrim"></div>
</body>
</html>