
<!doctype html>
<html>
<head>
  <meta charset="utf-8">

  <!-- Always force latest IE rendering engine or request Chrome Frame -->
  <meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible">

  <!-- REPLACE X WITH PRODUCT NAME -->
  <title>Upgrading PHD Using the CLI | Pivotal Docs</title>
    <!-- Local CSS stylesheets -->
    <link href="/stylesheets/master.css" media="screen,print" rel="stylesheet" type="text/css" />
    <link href="/stylesheets/breadcrumbs.css" media="screen,print" rel="stylesheet" type="text/css" />
    <link href="/stylesheets/search.css" media="screen,print" rel="stylesheet" type="text/css" />
    <link href="/stylesheets/portal-style.css" media="screen,print" rel="stylesheet" type="text/css" />
    <link href="/stylesheets/printable.css" media="print" rel="stylesheet" type="text/css" /> 
    <!-- Confluence HTML stylesheet -->
    <link href="/stylesheets/site-conf.css" media="screen,print" rel="stylesheet"  type="text/css" /> 
    <!-- Left-navigation code -->
    <!-- http://www.designchemical.com/lab/jquery-vertical-accordion-menu-plugin/examples/# -->
    <link href="/stylesheets/dcaccordion.css" rel="stylesheet" type="text/css" />
    <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.4.2/jquery.min.js" type="text/javascript"></script>
    <script src="/javascripts/jquery.cookie.js" type="text/javascript"></script>
    <script src="/javascripts/jquery.hoverIntent.minified.js" type="text/javascript"></script>
    <script src="/javascripts/jquery.dcjqaccordion.2.7.min.js" type="text/javascript"></script>
    <script type="text/javascript">
                    $(document).ready(function($){
					$('#accordion-1').dcAccordion({
						eventType: 'click',
						autoClose: true,
						saveState: true,
						disableLink: false,
						speed: 'fast',
						classActive: 'test',
						showCount: false
					});
					});
        </script>
    <link href="/stylesheets/grey.css" rel="stylesheet" type="text/css" /> 
    <!-- End left-navigation code -->
    <script src="/javascripts/all.js" type="text/javascript"></script>
    <link href='http://www.gopivotal.com/misc/favicon.ico' rel='shortcut icon'>
    <script type="text/javascript">
    if (window.location.host === 'docs.gopivotal.com') {
        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-39702075-1']);
        _gaq.push(['_setDomainName', 'gopivotal.com']);
        _gaq.push(['_trackPageview']);

        (function() {
          var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
          ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
          var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    }
  </script>
</head>

<body class="pivotalcf pivotalcf_getstarted pivotalcf_getstarted_index">
  <div class="viewport">
    <div class="mobile-navigation--wrapper mobile-only">
      <div class="navigation-drawer--container">
        <div class="navigation-item-list">
          <div class="navbar-link active">
            <a href="http://gopivotal.com">
              Home
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
          <div class="navbar-link">
            <a href="http://gopivotal.com/paas">
              PaaS
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
          <div class="navbar-link">
            <a href="http://gopivotal.com/big-data">
              Big Data
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
          <div class="navbar-link">
            <a href="http://gopivotal.com/agile">
              Agile
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
          <div class="navbar-link">
            <a href="http://gopivotal.com/support">
              Help &amp; Support
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
          <div class="navbar-link">
            <a href="http://gopivotal.com/products">
              Products
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
          <div class="navbar-link">
            <a href="http://gopivotal.com/solutions">
              Solutions
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
          <div class="navbar-link">
            <a href="http://gopivotal.com/partners">
              Partners
              <i class="icon-chevron-right pull-right"></i>
            </a>
          </div>
        </div>
      </div>
      <div class="mobile-nav">
        <div class="nav-icon js-open-nav-drawer">
          <i class="icon-reorder"></i>
        </div>
        <div class="header-center-icon">
          <a href="http://gopivotal.com">
            <div class="icon icon-pivotal-logo-mobile"></div>
          </a>
        </div>
      </div>
    </div>

    <div class='wrap'>
      <script src="//use.typekit.net/clb0qji.js" type="text/javascript"></script>
      <script type="text/javascript">
          try {
              Typekit.load();
          } catch (e) {
          }
      </script>
      <script type="text/javascript">
          document.domain = "gopivotal.com";
      </script>

	<script type="text/javascript">
	  WebFontConfig = {
	    google: { families: [ 'Source+Sans+Pro:300italic,400italic,600italic,300,400,600:latin' ] }
	  };
	  (function() {
	    var wf = document.createElement('script');
	    wf.src = ('https:' == document.location.protocol ? 'https' : 'http') +
	      '://ajax.googleapis.com/ajax/libs/webfont/1/webfont.js';
	    wf.type = 'text/javascript';
	    wf.async = 'true';
	    var s = document.getElementsByTagName('script')[0];
	    s.parentNode.insertBefore(wf, s);
	  })(); </script>

      <div id="search-dropdown-box">
        <div class="search-dropdown--container js-search-dropdown">
          <div class="container-fluid">
            <div class="close-menu-large"><img src="http://www.gopivotal.com/sites/all/themes/gopo13/images/icon-close.png" /></div>
            <div class="search-form--container">
              <div class="form-search">
                <div class='gcse-search'></div>
                <script src="http://www.google.com/jsapi" type="text/javascript"></script>
                <script src="//javascripts/cse.js" type="text/javascript"></script>
              </div>
            </div>
          </div>
        </div>
      </div>

      <header class="navbar desktop-only" id="nav">
        <div class="navbar-inner">
            <div class="container-fluid">
                <div class="pivotal-logo--container">
                    <a class="pivotal-logo" href="http://gopivotal.com"><span></span></a>
                </div>

                <ul class="nav pull-right">
                    <li class="navbar-link">
                        <a href="http://www.gopivotal.com/paas" id="paas-nav-link">PaaS</a>
                    </li>
                    <li class="navbar-link">
                        <a href="http://www.gopivotal.com/big-data" id="big-data-nav-link">BIG DATA</a>
                    </li>
                    <li class="navbar-link">
                        <a href="http://www.gopivotal.com/agile" id="agile-nav-link">AGILE</a>
                    </li>
                    <li class="navbar-link">
                        <a href="http://www.gopivotal.com/oss" id="oss-nav-link">OSS</a>
                    </li>
                    <li class="nav-search">
                        <a class="js-search-input-open" id="click-to-search"><span></span></a>
                    </li>
                </ul>
            </div>
            <a href="http://www.gopivotal.com/contact">
                <img id="get-started" src="http://www.gopivotal.com/sites/all/themes/gopo13/images/get-started.png">
            </a>
        </div>
      </header>
      <div class="main-wrap">
        <div class="container-fluid">

          <!-- Google CSE Search Box -->
          <div id='docs-search'>
              <gcse:search></gcse:search>
          </div>
          
          <div id='all-docs-link'>
            <a href="http://docs.gopivotal.com/">All Documentation</a>
          </div>
          
          <div class="container">
            <div id="sub-nav" class="nav-container">              
              
              <!-- Collapsible left-navigation-->
				<ul class="accordion"  id="accordion-1">
					<!-- REPLACE <li/> NODES-->
                                  <li>
                <a href="index.html">Home</a></br>
                        </li>
                        <li>
                <a href="PivotalHD.html">Pivotal HD</a>

                            <ul>
                    <li>
                <a href="PHDEnterprise2.0.1ReleaseNotes.html">PHD Enterprise 2.0.1 Release Notes</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PHDInstallationandAdministration.html">PHD Installation and Administration</a>

                            <ul>
                    <li>
                <a href="OverviewofPHD.html">Overview of PHD</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="InstallationOverview.html">Installation Overview</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PHDInstallationChecklist.html">PHD Installation Checklist</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="InstallingPHDUsingtheCLI.html">Installing PHD Using the CLI</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="UpgradeChecklist.html">Upgrade Checklist</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="UpgradingPHDUsingtheCLI.html">Upgrading PHD Using the CLI</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="AdministeringPHDUsingtheCLI.html">Administering PHD Using the CLI</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PHDFAQFrequentlyAskedQuestions.html">PHD FAQ (Frequently Asked Questions)</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PHDTroubleshooting.html">PHD Troubleshooting</a>

                    </li>
            </ul>
            </li>
            </ul>
                    <ul>
                    <li>
                <a href="StackandToolsReference.html">Stack and Tools Reference</a>

                            <ul>
                    <li>
                <a href="OverviewofApacheStackandPivotalComponents.html">Overview of Apache Stack and Pivotal Components</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="ManuallyInstallingPivotalHD2.0Stack.html">Manually Installing Pivotal HD 2.0 Stack</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="ManuallyUpgradingPivotalHDStackfrom1.1.1to2.0.html">Manually Upgrading Pivotal HD Stack from 1.1.1 to 2.0</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PivotalHadoopEnhancements.html">Pivotal Hadoop Enhancements</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="Security.html">Security</a>

                    </li>
            </ul>
            </li>
            </ul>
            </li>
                        <li>
                <a href="PivotalCommandCenter.html">Pivotal Command Center</a>

                            <ul>
                    <li>
                <a href="PCC2.2.1ReleaseNotes.html">PCC 2.2.1 Release Notes</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PCCUserGuide.html">PCC User Guide</a>

                            <ul>
                    <li>
                <a href="PCCOverview.html">PCC Overview</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PCCInstallationChecklist.html">PCC Installation Checklist</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="InstallingPCC.html">Installing PCC</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="UsingPCC.html">Using PCC</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="CreatingaYUMEPELRepository.html">Creating a YUM EPEL Repository</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="CommandLineReference.html">Command Line Reference</a>

                    </li>
            </ul>
            </li>
            </ul>
            </li>
                        <li>
                <a href="PivotalHAWQ.html">Pivotal HAWQ</a>

                            <ul>
                    <li>
                <a href="HAWQ1.2.0.1ReleaseNotes.html">HAWQ 1.2.0.1 Release Notes</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQInstallationandUpgrade.html">HAWQ Installation and Upgrade</a>

                            <ul>
                    <li>
                <a href="PreparingtoInstallHAWQ.html">Preparing to Install HAWQ</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="InstallingHAWQ.html">Installing HAWQ</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="InstallingtheHAWQComponents.html">Installing the HAWQ Components</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="UpgradingHAWQandComponents.html">Upgrading HAWQ and Components</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQConfigurationParameterReference.html">HAWQ Configuration Parameter Reference</a>

                    </li>
            </ul>
            </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQAdministration.html">HAWQ Administration</a>

                            <ul>
                    <li>
                <a href="HAWQOverview.html">HAWQ Overview</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQQueryProcessing.html">HAWQ Query Processing</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="UsingHAWQtoQueryData.html">Using HAWQ to Query Data</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="ConfiguringClientAuthentication.html">Configuring Client Authentication</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="KerberosAuthentication.html">Kerberos Authentication</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="ExpandingtheHAWQSystem.html">Expanding the HAWQ System</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQInputFormatforMapReduce.html">HAWQ InputFormat for MapReduce</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQFilespacesandHighAvailabilityEnabledHDFS.html">HAWQ Filespaces and High Availability Enabled HDFS</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="SQLCommandReference.html">SQL Command Reference</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="ManagementUtilityReference.html">Management Utility Reference</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="ClientUtilityReference.html">Client Utility Reference</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQServerConfigurationParameters.html">HAWQ Server Configuration Parameters</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQEnvironmentVariables.html">HAWQ Environment Variables</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="HAWQDataTypes.html">HAWQ Data Types</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="SystemCatalogReference.html">System Catalog Reference</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="hawq_toolkitReference.html">hawq_toolkit Reference</a>

                    </li>
            </ul>
            </li>
            </ul>
                    <ul>
                    <li>
                <a href="PivotalExtensionFrameworkPXF.html">Pivotal Extension Framework (PXF)</a>

                            <ul>
                    <li>
                <a href="PXFInstallationandAdministration.html">PXF Installation and Administration</a>

                    </li>
            </ul>
                    <ul>
                    <li>
                <a href="PXFExternalTableandAPIReference.html">PXF External Table and API Reference</a>

                    </li>

              </ul>
                                    
            </div><!--end of sub-nav-->
            
            <h3 class="title-container">Upgrading PHD Using the CLI</h3>
            <div class="content">
              <!-- Python script replaces main content -->
			  <div id ="main"><div style="visibility:hidden; height:2px;">Pivotal Product Documentation : Upgrading PHD Using the CLI</div><div class="wiki-content group" id="main-content">
<p>This section describes how to upgrade Pivotal HD using Pivotal Command Center's command line interface (CLI).</p><p>See the <a href="UpgradeChecklist.html">Upgrade Checklist</a> for a quick summary of the prerequisites and installation steps.</p><p><style type="text/css">/*<![CDATA[*/
div.rbtoc1398914611698 {padding: 0px;}
div.rbtoc1398914611698 ul {list-style: disc;margin-left: 0px;}
div.rbtoc1398914611698 li {margin-left: 0px;padding-left: 0px;}

/*]]>*/</style><div class="toc-macro rbtoc1398914611698">
<ul class="toc-indentation">
<li><a href="#UpgradingPHDUsingtheCLI-Prerequisites">Prerequisites</a></li>
<li><a href="#UpgradingPHDUsingtheCLI-UpgradeInstructions">Upgrade Instructions</a></li>
<li><a href="#UpgradingPHDUsingtheCLI-UpgradeSyntax">Upgrade Syntax</a></li>
<li><a href="#UpgradingPHDUsingtheCLI-ChangedConfigurationParametersandFiles">Changed Configuration Parameters and Files</a></li>
</ul>
</div></p><p><span class="confluence-anchor-link" id="UpgradingPHDUsingtheCLI-Prerequisites"></span></p><h2 id="UpgradingPHDUsingtheCLI-Prerequisites">Prerequisites</h2><ul><li><strong>PADS file location:</strong> Make note of the path to the extracted pre-upgrade PADS tar ball. If you don't remember, you can just download it again and untar it.</li><li><strong>Backup Data:</strong> We recommend you backup any critical data before performing any upgrades.</li><li><strong>Backup Service Configuration Files: </strong> Services that were manually installed on an existing cluster are not upgraded by a CLI upgrade. After the PHD upgrade, you need to manually reconfigure these services to work with the upgraded PHD.  Backup the configuration files for these services.  See the <em>Pivotal HD Enterprise Stack Tool and Reference Guide</em> for the locations of these configuration files.</li><li><strong>Oracle JDK 1.7</strong>. <span>Ensure that you are running Oracle JAVA JDK version 1.7.0_xx (minimum 1.7.0.15) as the default JDK on the Admin node.<br/> </span></li></ul> <div class="aui-message warning shadowed information-macro">
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<p>This is a new requirement; prior to PHD 2.0, JDK 1.6 was also supported.</p>
</div>
</div>
<p>As <code>gpadmin</code>, run:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">$ java -version
java version "1.7.0_15"
Java(TM) SE Runtime Environment (build 1.7.0_15-b03)
Java HotSpot(TM) 64-Bit Server VM (build 23.7-b01, mixed mode)</pre>
</div></div><ul><li><p><strong>Compact HBase Tables</strong> <br/>Compact all tables on the existing HBase 0.94 cluster<code>:<br/> </code>For example: to compact table<code> t1</code>, login to the HBase shell, then run:<br/> <code> major_compact 't1'</code></p> <div class="aui-message warning shadowed information-macro">
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<p>HBase 0.96 only supports HFileV2 format and major table compaction rewrites HFileV1 to HfileV2.  Skipping this step may lead to data loss.</p>
</div>
</div>
</li><li><p><strong>Remove GemFireXD</strong> <span style="background-color: transparent;line-height: 1.4285715;"> </span></p></li></ul><p style="margin-left: 30.0px;"><span style="background-color: transparent;line-height: 1.4285715;">The PHD 2.0 upgrade does not support an upgrade of the GemFireXD beta service. </span></p><p style="margin-left: 30.0px;">You will have to remove the GemFireXD beta service prior to PHD upgrade; followed by a fresh install of GemFireXD.  Data migration from GemFireXD beta is not supported.</p><p style="margin-left: 30.0px;">To remove GemFireXD, run the following:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">vim icmconf/clusterConfig.xml # Remove gfxd from &lt;services&gt;
icm_client reconfigure -c icmconf -l test</pre>
</div></div><p style="margin-left: 30.0px;"><span style="background-color: transparent;line-height: 1.4285715;"> Note that you will see the following error if you attempt to upgrade a cluster with GemFireXD installed.</span></p><div class="code panel pdl" style="border-width: 1px;">
<div class="codeHeader panelHeader pdl hide-border-bottom" style="border-bottom-width: 1px;">
<b class=" code-title">Gemfire Upgrade Error Example</b>
<span class="collapse-source expand-control"><span class="expand-control-icon icon"> </span><span class="expand-control-text">Expand source</span></span>
</div>
<div class="codeContent panelContent pdl hide-toolbar">
<pre class="theme: Confluence; brush: bash; collapse: true; gutter: false" style="font-size:12px;">-bash-4.1$ icm_client upgrade -l test -s phd
Please ensure you've backed up manually installed service configurations (not installed by icm_client) if any. Do you wish to proceed with the PHD upgrade ? . (Press 'y' to continue, any other key to quit): y
Please enter the root password for the cluster nodes:
PCC creates a gpadmin user on the newly added cluster nodes (if any). Please enter a non-empty password to be used for the gpadmin user:
Starting upgrade

Return Code : 6000
Message : Upgrade Cluster Error
Details :
Cluster Hosts :
        Operation Code : UPGRADE_FAILURE
        Operation Error : GEMFIRE XD must not be present if upgrading
        Log File : /var/log/gphd/gphdmgr/gphdmgr-webservices.log

[====================================================================================================] 100%
Results:
centos64-5... [Success]
centos64-4... [Success]
centos64-3... [Success]
centos64-2... [Success]
Details at /var/log/gphd/gphdmgr/gphdmgr-webservices.log
[ERROR] Cluster upgrade failed
-</pre>
</div>
</div><p>Once you've completed your PHD Upgrade, reinstall GemFireXD as a fresh install.  See <a href="InstallingPHDUsingtheCLI.html#InstallingPHDUsingtheCLI-GemFireXD">Configuring GemFireXD</a> for details.</p><h2 id="UpgradingPHDUsingtheCLI-UpgradeInstructions">Upgrade Instructions</h2><p>Follow the instructions below to upgrade your PHD system.</p><ol><li><strong><span class="confluence-anchor-link" id="UpgradingPHDUsingtheCLI-VerifyState"></span>Verify the current state of the cluster<br/></strong><ol class="_mce_tagged_br"><li>Using the Pivotal Command Center user interface, check to see if any services are down. If any service is down or is running with errors, address those issues before upgrading.</li><li>On one of the HDFS nodes, as <code>gpadmin</code>, run:<br/><code>sudo - u hdfs hdfs dfsadmin -report</code><br/>An example of the output is below.<br/>Make sure that there are no <code>Under replicated blocks</code>, <code>Blocks with corrupt replicas</code>, or <code>Missing blocks</code>. Make sure there are no dead or decommissioned nodes.<code><br/></code>If you have decommissioned data nodes, removed then from the cluster using the <code>icm_client remove-slaves</code> command (see <a href="AdministeringPHDUsingtheCLI.html#AdministeringPHDUsingtheCLI-ShrinkCluster">Shrinking a Cluster</a>). You can always add them back after you have completed the upgrade procedure (see <a href="AdministeringPHDUsingtheCLI.html#AdministeringPHDUsingtheCLI-ExpandCluster">Expanding a Cluster</a>).<code><br/></code>If you have dead data nodes,either remove then or bring them back up.<code><br/></code></li><li>Run <code>fsck</code> and ensure that the filesystem is healthy, for example there are no corrupt files. An example of the output is below.<br/><p><strong>dfsadmin report example</strong></p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">sudo -u hdfs hdfs dfsadmin -report
Configured Capacity: 93657587712 (87.23 GB)
Present Capacity: 81391808512 (75.80 GB)
DFS Remaining: 81391706112 (75.80 GB)
DFS Used: 102400 (100 KB)
DFS Used%: 0.00%
Under replicated blocks: 0
Blocks with corrupt replicas: 0
Missing blocks: 0
-------------------------------------------------
Datanodes available: 1 (1 total, 0 dead)
Live datanodes:
Name: 192.168.2.203:50010 (rhel64-3.localdomain)
Hostname: rhel64-3.localdomain
Decommission Status : Normal
Configured Capacity: 93657587712 (87.23 GB)
DFS Used: 102400 (100 KB)
Non DFS Used: 12265779200 (11.42 GB)
DFS Remaining: 81391706112 (75.80 GB)
DFS Used%: 0.00%
DFS Remaining%: 86.90%
Last contact: Fri Apr 25 18:39:22 UTC 2014</pre>
</div></div><p><strong>fsck example</strong></p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">sudo -u hdfs hdfs fsck /
Connecting to namenode via http://rhel64-3:50070
FSCK started by hdfs (auth:SIMPLE) from /192.168.2.202 for path / at Fri Apr 25 20:56:52 UTC 2014
...Status: HEALTHY
Total size: 366 B
Total dirs: 20
Total files: 3
Total symlinks: 0
Total blocks (validated): 3 (avg. block size 122 B)
Minimally replicated blocks: 3 (100.0 %)
Over-replicated blocks: 0 (0.0 %)
Under-replicated blocks: 0 (0.0 %)
Mis-replicated blocks: 0 (0.0 %)
Default replication factor: 1
Average block replication: 1.0
Corrupt blocks: 0
Missing replicas: 0 (0.0 %)
Number of data-nodes: 1
Number of racks: 1
FSCK ended at Fri Apr 25 20:56:52 UTC 2014 in 211 milliseconds

The filesystem under path '/' is HEALTHY</pre>
</div></div> <div class="aui-message problem shadowed information-macro">
<span class="aui-icon icon-problem">Icon</span>
<div class="message-content">
<p>If you cannot get a cluster into a healthy state contact Pivotal Support before continuing with your upgrade.</p>
</div>
</div>
</li></ol></li><li><strong><span class="confluence-anchor-link" id="UpgradingPHDUsingtheCLI-BackupHive"></span>Backup the Hive metastore</strong><br/>Hive does not provide rollback options so we recommend that you take a snapshot of the metastore DB before starting the upgrade.<br/><ol class="_mce_tagged_br"><li>As <code>gpadmin</code>, login to the machine running the hive metastore database</li><li><p>Use the following command to backup the metastore database.  It will backup the metastore database to file <code><code>hive_metastore_1.backup</code></code></p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">pg_dump -U hive -p 10432 metastore &gt; hive_metastore_1.backup</pre>
</div></div></li></ol></li><li><strong>Revert to Non-HA (if applicable)</strong>: <br/><span>You cannot upgrade a cluster with High Availability enabled. Revert your cluster to non-HA before proceeding with an upgrade. </span> <span> </span><br/>See <a href="AdministeringPHDUsingtheCLI.html#AdministeringPHDUsingtheCLI-DisableHA">Disabling HA</a> for details.<strong><br/><br/></strong></li><li><strong>Revert to Non-Secure (if applicable):</strong><br/>You cannot upgrade a cluster with security enabled. Revert your cluster to non-secure before proceeding with an upgrade. <br/>See <a href="AdministeringPHDUsingtheCLI.html#AdministeringPHDUsingtheCLI-DisableKerberos">Disabling Security</a> for details.<strong><br/><br/></strong></li><li><strong>Remove HAWQ Standby Master:<br/> </strong>If you have a HAWQ Standby Master, you need to remove it before you start the upgrade.  As <code>gpadmin</code>, do the following:<br/><ol><li>Source the <code>greenplum_path.s</code>h file:<br/><code>$ source /user/local/hawq/greenplum.path.sh</code></li><li><p>Remove the HAWQ Standby Master by running:</p><code>$ gpinitstandby -r</code><br/>For more details, refer to the <em>HAWQ Installation and Upgrade Guide</em>.</li></ol></li><li><span class="confluence-anchor-link" id="UpgradingPHDUsingtheCLI-StopServices"></span><strong>Stop Services:</strong><ol><li>As <code>gpadmin</code>, stop HAWQ on the HAWQ master:<br/><code>$ /etc/init.d/hawq stop </code></li><li>As <code>gpadmin</code>, stop all PHD services:<br/><code>$ icm_client stop -l &lt;CLUSTER NAME&gt;</code></li><li>As <code>root</code>, stop PCC:<br/><code>$ service commander stop<br/>  </code></li></ol></li><li><strong> <span class="confluence-anchor-link" id="UpgradingPHDUsingtheCLI-ExtractPCC"></span>Import and upgrade PCC:</strong><br/><ol><li>Download the new PCC file from<span class="confluence-link"> </span><a class="external-link" href="https://network.gopivotal.com/" rel="nofollow"><span class="confluence-link">Pivotal Network</span></a>.</li><li>Copy the new PCC tar file to your installation directory on the admin node, for example: <br/><code>$ scp ./PCC-2.2.x.<strong> <em>version.build.os</em> </strong>.x86_64.tar.gz host:/root/phd/ </code></li><li>Login as <code>root</code> and untar to that directory:<br/><code>$ cd /root/phd </code><br class="atl-forced-newline"/><code>$ tar --no-same-owner -zxvf PCC-2.2.x.<strong> <em>version.build.os</em> </strong>.x86_64.tar.gz</code></li><li>As <code>root</code>, run the PCC installation script from the directory where it is installed: <br class="atl-forced-newline"/><code>$ ./install</code></li></ol> <div class="aui-message warning shadowed information-macro">
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<p>There is no need to specify that this is an upgrade; the install utility (<code>./install</code>) detects whether it is a fresh install or an upgrade.</p>
</div>
</div>
<div class="aui-message hint shadowed information-macro">
<span class="aui-icon icon-hint">Icon</span>
<div class="message-content">
<p>The rest of the upgrade procedure is performed by the <code>gpadmin</code> user.  Switch to that user now.</p>
</div>
</div>
</li><li><strong> <span class="confluence-anchor-link" id="UpgradingPHDUsingtheCLI-SelfUpgrade"></span>CLI Self-Upgrade:</strong><br/> As <code>gpadmin</code>, run the following command to upgrade the CLI:<br/><code>$ icm_client self-upgrade</code><br/>Note that this command may return very quickly. This does not indicate any problems and you can continue with the upgrade.<br/><br/></li><li><p><strong> <span class="confluence-anchor-link" id="UpgradingPHDUsingtheCLI-ImportPADS"></span>Import new HAWQ package:</strong></p><ol><li><p>Download and extract the new PADS (HAWQ) package from <span class="confluence-link"> </span><a class="external-link" href="https://network.gopivotal.com/" rel="nofollow"><span class="confluence-link">Pivotal Network</span></a>.</p></li><li><p>Run:</p><p><code>   $ icm_client import -s &lt; PATH TO EXTRACTED PADS TAR BALL  &gt;<br/> </code></p></li></ol></li><li><p><strong> <span class="confluence-anchor-link" id="UpgradingPHDUsingtheCLI-UpgradeHAWQ"></span>Upgrade HAWQ:<br/> </strong><strong><strong><br/> </strong> </strong></p> <div class="aui-message warning shadowed information-macro">
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<p>This section is only applicable if you installed Pivotal ADS (HAWQ) using PHD's CLI; if you installed Pivotal ADS manually, refer to the <em>HAWQ Installation and Upgrade Guide</em> for manual upgrade instructions.</p>
</div>
</div>
<p> </p><ol><li><p>To upgrade PADS (HAWQ), as <code>gpadmin</code>, run:<br/><code> $ icm_client upgrade -l &lt;CLUSTERNAME&gt; -s pads -o &lt; PATH TO EXTRACTED OLD ADS TAR BALL &gt; -n &lt; PATH TO EXTRACTED NEW ADS TAR BALL &gt;<br/> </code></p></li><li><p>On the HAWQ master node run the following commands to migrate data: </p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: bash; gutter: false" style="font-size:12px;">su - gpadmin
source /usr/lib/gphd/hawq/greenplum_path.sh
gpmigrator &lt;old_HAWQHOME_path&gt; &lt;new_HAWQHOME_path&gt; # Look into ls -laF /usr/local and find the old and new homes.

# For example:
gpmigrator /usr/local/hawq-1.1.3.0/ /usr/local/hawq-1.2.0.0/ -d /data1/master/gpseg-1</pre>
</div></div> <div class="aui-message warning shadowed information-macro">
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<p>If you encounter errors migrating HAWQ data, refer to the <em>HAWQ Administrator Guide</em> for help.</p>
</div>
</div>
</li><li><p>Optional: You can delete the old HAWQ rpm file by running:<br/><code>$ yum erase &lt;HAWQ_OLD_RPM_NAME&gt; <br/> </code></p></li></ol></li><li><strong> <span class="confluence-anchor-link" id="UpgradingPHDUsingtheCLI-ImportPHD"></span>Import new PHD package:</strong><ol><li>Download and extract the new PHD package from <span class="confluence-link"> </span><a class="external-link" href="https://network.gopivotal.com/" rel="nofollow"><span class="confluence-link">Pivotal Network</span></a>.</li><li>Run:<br/><code>$ icm_client import -s &lt; PATH TO EXTRACTED PHD TAR BALL  &gt; <br/> </code></li></ol></li><li><strong> <strong> <span class="confluence-anchor-link" id="UpgradingPHDUsingtheCLI-UpgradePHD"></span>Upgrade PHD:<br/> </strong> </strong>If your cluster is configured with HAWQ, make sure you complete upgrading Pivotal ADS (see previous step), before proceeding with Pivotal HD upgrade.<br/>Only clusters running the following versions can be upgraded to use the PHD 2.0.x stack:<br/><p>PHD 1.1.1 and PHD 1.1<br/>PCC 2.1.1 and PCC 2.1<br/><br/>To upgrade PHD, as <code>gpadmin</code>, run:</p><p><code> $ icm_client upgrade -l &lt;CLUSTERNAME&gt; -s phd</code><br/><span>This upgrades the PHD stack on all cluster nodes.<br/></span></p><p><span>Note that all upgrade steps, including post-upgrade configuration steps described below, should be completed before you re-enable HA or security on a cluster.</span></p></li><li><strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <span class="confluence-anchor-link" id="UpgradingPHDUsingtheCLI-PostUpgrade"></span>Upgrade Configuration Files:<br/> </strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong>After upgrading the PHD stack, you need to upgrade your cluster configuration files:<strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <br/> </strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong><ol><li><p>Fetch the new templates that come with the upgraded stack by running <code>icm_client fetch-template</code>, for example: </p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">icm_client fetch-template -o ~/newTemplate</pre>
</div></div><p><code>newTemplate</code><em> </em> is the new template for the upgraded stack without any user customizations.<br/><br/></p></li><li><p><span> <span> <span> <span> <span> <span> <span>Retrieve the existing configuration from the database by running<code> </code> </span> </span> </span> </span> </span> </span> </span><code>icm_client fetch-configuration</code>, for example:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">icm_client fetch-configuration -o ~/origConfiguration -l &lt;CLUSTERNAME&gt;</pre>
</div></div><p><code>origConfiguration</code> is based on user-customized template from a previous installation.</p><p> </p></li><li><p> Identify the changes between the configurations by running the <code>diff</code> command, for example:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">diff -ruBw newTemplate/ origConfiguration/</pre>
</div></div><p>Then apply those changes to the <code>newTemplate</code> you retrieved.<code>  </code></p><p> </p> <div class="aui-message hint shadowed information-macro">
<p class="title">TIP</p>
<span class="aui-icon icon-hint">Icon</span>
<div class="message-content">
<div>To simplify the process (step c, above) of merging the existing PHD configuration with the <code>newTemplate</code>, follow these steps,</div><div>1. Overwrite<code> clusterConfig.xml</code> in <code>newTemplate</code> from the one from<code> origConfiguration</code> directory:</div><div><code>  $&gt; cp ~origConfiguration/clusterConfig.xml  ~newTemplate/ClusterConfig.xml</code></div><div>2. Change the value of <code>&lt;gphdStackVer&gt;</code> to PHD-2.0.1.0 in the <code>~newTemplate/clusterConfig.xml</code> </div><div>3. If you have explicitly modified any properties from PHD services configuration files, for example, <code>hdfs/hdfs-site.xml</code>, <code>yarn/yarn-site.xml</code> etc., then make the corresponding changes to these configuration files under  <code>~newTemplate/</code> directory.</div>
</div>
</div>
<p><code><br/></code></p></li><li><p>Upgrade service by specifying the cluster configuration directory as <code>~/newTemplate</code> with your updated contents:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: bash; gutter: false" style="font-size:12px;">icm_client reconfigure -c ~/newTemplate -l &lt;CLUSTERNAME&gt;</pre>
</div></div></li></ol></li><li><p><strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <span class="confluence-anchor-link" id="UpgradingPHDUsingtheCLI-UpgradeHDFS"></span>Upgrade HDFS:<br/> </strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong></p> <div class="aui-message warning shadowed information-macro">
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<p><span style="color: rgb(34,34,34);">If you are performing the upgrade on an EMC Data Computing Appliance (DCA) you need to make sure that the <code>gpadmin</code> user has read access to each of the subdirectories of the Nameode name directories. The location of the Namenode name directories is specified in the value of <code>dfs.namenode.name.dir</code> property in <code>/etc/gphd/hadoop/conf/hdfs-</code></span><span style="color: rgb(34,34,34);"><code>site.xml</code> on the Namenode. <br/></span></p><p><span style="color: rgb(34,34,34);">For example, if <code>/data/nn/dfs/name</code> is the Namenode directory, then the <code>gpadmin</code> user must have read access to <code>data</code>, <code>nn</code> , <code>dfs</code> and <code>name</code> directories.</span></p>
</div>
</div>
<p><br/>As <code>gpadmin</code>, on the Admin node, do the following:<strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <br/> </strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong></p><ol><li><p><span> <span>Backup Namenode metadata by running:<br/> </span> </span></p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">/usr/bin/python /usr/lib/gphd/gphdmgr/lib/client/HdfsUpgrader.py -l &lt;CLUSTER NAME&gt; -o backupNNMetadata -s 2.0.5_alpha_gphd_2_1_1_0 -t 2.2.0_gphd_3_0_0_0
 
# Source prefix would be 2.0.5_alpha_gphd_2_1_0_0 instead of 2.0.5_alpha_gphd_2_1_1_0 if you are upgrading from (PHD-1.1.0.0)</pre>
</div></div></li><li><p><span> <span>Run NameNode upgrade by running:</span><br/></span></p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">/usr/bin/python /usr/lib/gphd/gphdmgr/lib/client/HdfsUpgrader.py -l &lt;CLUSTER NAME&gt; -o nnupgrade -s 2.0.5_alpha_gphd_2_1_1_0 -t 2.2.0_gphd_3_0_0_0
# Source prefix would be 2.0.5_alpha_gphd_2_1_0_0 instead of 2.0.5_alpha_gphd_2_1_1_0 if you are upgrading from (PHD-1.1.0.0)</pre>
</div></div></li><li><p><span> <span>Run Data Node upgrade by running:</span><br/></span></p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">/usr/bin/python /usr/lib/gphd/gphdmgr/lib/client/HdfsUpgrader.py -l &lt;CLUSTER NAME&gt; -o dnupgrade -s 2.0.5_alpha_gphd_2_1_1_0 -t 2.2.0_gphd_3_0_0_0
# Source prefix would be 2.0.5_alpha_gphd_2_1_0_0 instead of 2.0.5_alpha_gphd_2_1_1_0 if you are upgrading from (PHD-1.1.0.0)</pre>
</div></div></li></ol></li><li><span class="confluence-anchor-link" id="UpgradingPHDUsingtheCLI-StopRestart"></span><strong> <strong>Restart the cluster:<br/> </strong> </strong><p><code>As </code><code>:<br/>$ icm_client restart -l &lt;CLUSTER_NAME&gt;</code></p><strong><br/> <br/> </strong></li><li><span class="confluence-anchor-link" id="UpgradingPHDUsingtheCLI-PostUpgradeHAWQ"></span><strong> <strong>Post-Upgrade HAWQ:<br/> </strong> </strong><ol><li>On the HAWQ master, as <code>gpadmin</code>:<br/>Check HAWQ status: <br/><code>$ /etc/init.d/hawq status</code><br/>If it is not running, start it by running:<code><code><br/>$ /etc/init.d/hawq start</code><br/> </code></li><li><p>If you were utilizing a standby HAWQ master, you should have removed it before the upgrade. It should now be reinitialized: <br/>On the HAWQ master, as <code>gpadmin</code>, run:</p><p><code>$ gpinitstandby -s &lt;standby_hostname&gt;<br/> </code><br/> For more details about these commands, refer to the <em>HAWQ Installation and Upgrade Guide</em>.</p></li></ol><strong> <br/> </strong></li><li><span> <span> <span> <strong> <span class="confluence-anchor-link" id="UpgradingPHDUsingtheCLI-FinalizeHDFS"></span>Finalize the HDFS upgrade:<br/> </strong>Before you continue you should run a few tests to make sure your data upgrade was successful, and then you can run <code>finalizeUpgrade</code>.</span> </span> </span><p>Once you have confirmed your cluster is working as expected, run the following command to finalize upgrade process:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">/usr/bin/python /usr/lib/gphd/gphdmgr/lib/client/HdfsUpgrader.py -l &lt;CLUSTER NAME&gt; -o finalizeUpgrade -s 2.0.5_alpha_gphd_2_1_1_0 -t 2.2.0_gphd_3_0_0_0</pre>
</div></div> <div class="aui-message problem shadowed information-macro">
<span class="aui-icon icon-problem">Icon</span>
<div class="message-content">
<p>HBase master will not start unless the HBase upgrade is finalized. Please ensure HDFS upgrade is finalized before finalizing HBase upgrade.</p>
</div>
</div>
</li><li><span> </span> <span> </span><strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <strong> <span class="confluence-anchor-link" id="UpgradingPHDUsingtheCLI-FinalizeHBase"></span>Finalize HBase Upgrade:</strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong> </strong><br/><br/><ol><li><p>Check for any HFileV1 data (only HFileV2 is supported after upgrade to HBase 0.96):<br/>On the hbase-master run:<br/><code>$ sudo -u hbase hbase upgrade -check</code><br/>If the return is:<br/><code>Count of HFileV1:0</code><br/>Continue with the upgrade.</p> <div class="aui-message warning shadowed information-macro">
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<p>As part of the prerequisites you should have already compacted all the tabels on the existing HBase cluster; this will have overwritten any HFileV1 data to HFileV2 format.</p>
</div>
</div>
</li><li>Make sure Zookeeper and HDFS are running but HBase is stopped, then run: </li></ol><p style="margin-left: 30.0px;"><code>      $ sudo -u hbase hbase upgrade -execute<br/> <br/> </code></p></li><li><p><strong> <strong> <strong> <strong> <span class="confluence-anchor-link" id="UpgradingPHDUsingtheCLI-Manual"></span>Reconfigure Manually Installed Services:<br/></strong></strong></strong></strong>Services that were manually installed on an existing cluster are not upgraded by a CLI upgrade. After the PHD upgrade, you need to manually reconfigure these services to work with the upgraded PHD.  Refer to the <em>Pivotal HD Enterprise Stack and Tool Reference Guide</em> for details.</p> <div class="aui-message warning shadowed information-macro">
<span class="aui-icon icon-warning">Icon</span>
<div class="message-content">
<p><span style="color: rgb(0,0,0);">Backing up the configuration files for these services is a prerequisite for this upgrade procedure.  See the </span><em>Pivotal HD Enterprise Stack Tool and Reference Guide</em><span style="color: rgb(0,0,0);"> for the locations of these configuration files.</span></p>
</div>
</div>
</li><li><strong>Re-enable HA:<br/></strong>See <a href="AdministeringPHDUsingtheCLI.html#AdministeringPHDUsingtheCLI-EnableHA">Enabling High Availability on a Cluster</a> for details.<strong><br/> <br/> </strong></li><li><strong>Re-Secure:</strong><br/>We provide instructions for manually enabling Kerberos authentication in the <em>PHD 2.0 Stack and Tools Reference Guide</em>.  We also can provide scripts to automate this process. To obtain these scripts and instructions how to use them, contact either your PHD Account Manager, or open up a service request with support at <a class="external-link" href="https://support.emc.com/" rel="nofollow">https://support.emc.com/</a> and ask for the PHD Secure Install Tools.</li></ol><p>Your cluster should now be upgraded. At this point you should check to see if all your services are running and your data is intact. <a href="InstallingPHDUsingtheCLI.html">Installing PHD Using the CLI</a> includes a section <em>Running Sample Programs</em> that provides instructions for testing the various services.</p><p> </p><p><span class="confluence-anchor-link" id="UpgradingPHDUsingtheCLI-UpgradeSyntax"></span></p><h2 id="UpgradingPHDUsingtheCLI-UpgradeSyntax">Upgrade Syntax</h2><p>For reference, the complete syntax for the <code>upgrade</code> command is as follows:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="theme: Confluence; brush: java; gutter: false" style="font-size:12px;">[gpadmin]# icm_client upgrade --help
Usage: /usr/bin/icm_client upgrade [options]

Options:
  -h, --help            show this help message and exit
  -l CLUSTERNAME, --clustername=CLUSTERNAME
                        the name of the cluster on which the operation is
                        performed
  -x, --noscanhosts     Do not verify cluster nodes.
  -s STACK, --stackname=STACK
                        stack to upgrade (phd or pads)
  -v VERSION, --version=VERSION
                        PHD Stack version, default is PHD-2.0.0.0 Stack
  -o OLDDIR, --old=OLDDIR
                        (Required for only for pads/hawq upgrade) Old PADS
                        Directory
  -n NEWDIR, --new=NEWDIR
                        (Required for only for pads/hawq upgrade) New PADS
                        Directory
  -p, --nopreparehosts  Do not prepare hosts as part of deploying the cluster
  -j JDKPATH, --java=JDKPATH
                        Location of Sun Java JDK RPM (Ex: jdk-
                        7u15-linux-x64.rpm). Ignored if -p is specified
  -t, --ntp             Synchronize system clocks using NTP. Optionally takes
                        NTP server as argument. Defaults to pool.ntp.org
                        (requires external network access). Ignored if -p is
                        specified
  -d, --selinuxoff      Disable SELinux. Ignored if -p is specified
  -i, --iptablesoff     Disable iptables. Ignored if -p is specified
  -y SYSCONFIGDIR, --sysconf=SYSCONFIGDIR
                        [Only if HAWQ is part of the deploy] Directory
                        location of the custom conf files (sysctl.conf and
                        limits.conf) which will be appended to
                        /etc/sysctl.conf and /etc/limits.conf on slave nodes.
                        Default: /usr/lib/gphd/gphdmgr/hawq_sys_config/.
                        Ignored if -p is specified
</pre>
</div></div><h2 id="UpgradingPHDUsingtheCLI-ChangedConfigurationParametersandFiles">Changed Configuration Parameters and Files</h2><p>The following information is provided solely as reference material; you do not need to make any changes to your configuration files beyond those you have already completed.</p><p>The following configuration parameters were changed in PHD 2.0 as described below:</p><h3 id="UpgradingPHDUsingtheCLI-core-site.xml">core-site.xml</h3><h4 id="UpgradingPHDUsingtheCLI-RemovedParameters">Removed Parameters</h4><p>The following parameters have been removed from core-site.xml:</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Name</div></th><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Default</div></th><th class="confluenceTh" colspan="1" style="text-align: left;"><div class="tablesorter-header-inner">Notes</div></th></tr><tr><td class="confluenceTd" style="text-align: left;">kfs.stream-buffer-size</td><td class="confluenceTd" style="text-align: left;">4096</td><td class="confluenceTd" colspan="1" style="text-align: left;">KFS is no longer supported, see<a class="external-link" href="https://issues.apache.org/jira/browse/HADOOP-8886" rel="nofollow" style="text-decoration: none;"> HADOOP-8886</a></td></tr><tr><td class="confluenceTd" style="text-align: left;">mapred.outdir.resolverClass</td><td class="confluenceTd" style="text-align: left;">org.apache.hadoop.mapreduce.DefaultPathResolver</td><td class="confluenceTd" colspan="1" style="text-align: left;"> </td></tr><tr><td class="confluenceTd" style="text-align: left;">kfs.client-write-packet-size</td><td class="confluenceTd" style="text-align: left;">65536</td><td class="confluenceTd" colspan="1" style="text-align: left;">KFS is no longer supported, see <a class="external-link" href="https://issues.apache.org/jira/browse/HADOOP-8886" rel="nofollow" style="text-decoration: none;">HADOOP-8886</a></td></tr><tr><td class="confluenceTd" style="text-align: left;">kfs.blocksize</td><td class="confluenceTd" style="text-align: left;">67108864</td><td class="confluenceTd" colspan="1" style="text-align: left;">KFS is no longer supported, see <a class="external-link" href="https://issues.apache.org/jira/browse/HADOOP-8886" rel="nofollow" style="text-decoration: none;">HADOOP-8886</a></td></tr><tr><td class="confluenceTd" style="text-align: left;">kfs.bytes-per-checksum</td><td class="confluenceTd" style="text-align: left;">512</td><td class="confluenceTd" colspan="1" style="text-align: left;">KFS is no longer supported, see <a class="external-link" href="https://issues.apache.org/jira/browse/HADOOP-8886" rel="nofollow" style="text-decoration: none;">HADOOP-8886</a></td></tr><tr><td class="confluenceTd" style="text-align: left;">kfs.replication</td><td class="confluenceTd" style="text-align: left;">3</td><td class="confluenceTd" colspan="1" style="text-align: left;">KFS is no longer supported, see <a class="external-link" href="https://issues.apache.org/jira/browse/HADOOP-8886" rel="nofollow" style="text-decoration: none;">HADOOP-8886</a></td></tr></tbody></table></div><h4 id="UpgradingPHDUsingtheCLI-NewParameters">New Parameters</h4><p>The following parameters have been added to <code>core-site.xml</code>:</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Name</div></th><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Default</div></th></tr><tr><td class="confluenceTd" style="text-align: left;">fs.client.resolve.remote.symlinks</td><td class="confluenceTd" style="text-align: left;">true</td></tr><tr><td class="confluenceTd" style="text-align: left;">nfs3.server.port</td><td class="confluenceTd" style="text-align: left;">2049</td></tr><tr><td class="confluenceTd" style="text-align: left;">nfs3.mountd.port</td><td class="confluenceTd" style="text-align: left;">4242</td></tr><tr><td class="confluenceTd" style="text-align: left;">hadoop.security.group.mapping.ldap.directory.search.timeout</td><td class="confluenceTd" style="text-align: left;">10000</td></tr><tr><td class="confluenceTd" style="text-align: left;">ipc.client.fallback-to-simple-auth-allowed</td><td class="confluenceTd" style="text-align: left;">false</td></tr></tbody></table></div><p> </p><h3 id="UpgradingPHDUsingtheCLI-yarn-site.xml">yarn-site.xml</h3><h4 id="UpgradingPHDUsingtheCLI-ChangedDefaults">Changed Defaults</h4><p>The following parameters in yarn-site.xml have new default values:</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Name</div></th><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Old Value</div></th><th class="confluenceTh" colspan="1" style="text-align: left;"><div class="tablesorter-header-inner">New Value</div></th></tr><tr><td class="confluenceTd" style="text-align: left;">yarn.nodemanager.aux-services</td><td class="confluenceTd" style="text-align: left;">mapreduce.shuffle</td><td class="confluenceTd" colspan="1" style="text-align: left;">mapreduce_shuffle</td></tr></tbody></table></div><h4 id="UpgradingPHDUsingtheCLI-NewNames">New Names</h4><p>The following parameters in yarn-site.xml have new names:</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Old Name</div></th><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">New Name</div></th><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Default Value</div></th></tr><tr><td class="confluenceTd" style="text-align: left;">yarn.resourcemanager.fs.rm-state-store.uri</td><td class="confluenceTd" style="text-align: left;">yarn.resourcemanager.fs.state-store.uri</td><td class="confluenceTd" style="text-align: left;">${hadoop.tmp.dir}/yarn/system/rmstore</td></tr><tr><td class="confluenceTd" style="text-align: left;">yarn.nodemanager.resource.cpu-cores</td><td class="confluenceTd" style="text-align: left;">yarn.nodemanager.resource.cpu-vcores</td><td class="confluenceTd" style="text-align: left;">8, See <a class="external-link" href="https://issues.apache.org/jira/browse/YARN-782" rel="nofollow" style="text-decoration: none;">YARN-782</a></td></tr><tr><td class="confluenceTd" colspan="1" style="text-align: left;">yarn.nodemanager.aux-services.<br/>mapreduce.shuffle.class</td><td class="confluenceTd" colspan="1" style="text-align: left;">yarn.nodemanager.aux-services.<br/>mapreduce_shuffle.class</td><td class="confluenceTd" colspan="1" style="text-align: left;">org.apache.hadoop.mapred.ShuffleHandler</td></tr><tr><td class="confluenceTd" colspan="1" style="text-align: left;">yarn.nodemanager.heartbeat.interval-ms</td><td class="confluenceTd" colspan="1" style="text-align: left;">yarn.resourcemanager.nodemanagers.<br/>heartbeat-interval-ms</td><td class="confluenceTd" colspan="1" style="text-align: left;">1000</td></tr><tr><td class="confluenceTd" colspan="1" style="text-align: left;">yarn.resourcemanager.am.max-retries</td><td class="confluenceTd" colspan="1" style="text-align: left;">yarn.resourcemanager.am.max-attempts</td><td class="confluenceTd" colspan="1" style="text-align: left;">1-&gt;2</td></tr></tbody></table></div><p> </p><h4 id="UpgradingPHDUsingtheCLI-RemovedParameters.1">Removed Parameters</h4><p>The following parameters have been removed from yarn-site.xml:</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Name</div></th><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Default Value</div></th><th class="confluenceTh" colspan="1" style="text-align: left;"><div class="tablesorter-header-inner">Note</div></th></tr><tr><td class="confluenceTd" style="text-align: left;">net.topology.with.nodegroup</td><td class="confluenceTd" style="text-align: left;">false</td><td class="confluenceTd" colspan="1" style="text-align: left;"><p>Introduced by hve patch.</p><p>Will be added when the patch is added again to hadoop 2.2.0</p></td></tr><tr><td class="confluenceTd" style="text-align: left;">yarn.dynamic.resource.memory.minimum.mb</td><td class="confluenceTd" style="text-align: left;">0</td><td class="confluenceTd" colspan="1" style="text-align: left;"><p>Introduced by hve patch.</p><p>Will be added when the patch is added again to hadoop 2.2.0</p></td></tr><tr><td class="confluenceTd" style="text-align: left;">yarn.dynamic.resource.vcores.maximum</td><td class="confluenceTd" style="text-align: left;">-1</td><td class="confluenceTd" colspan="1" style="text-align: left;"><p>Introduced by hve patch.</p><p>Will be added when the patch is added again to hadoop 2.2.0</p></td></tr><tr><td class="confluenceTd" style="text-align: left;">yarn.dynamic.resource.enable</td><td class="confluenceTd" style="text-align: left;">true</td><td class="confluenceTd" colspan="1" style="text-align: left;"><p>Introduced by hve patch.</p><p>Will be added when the patch is added again to hadoop 2.2.0</p></td></tr><tr><td class="confluenceTd" style="text-align: left;">yarn.dynamic.resource.memory.maximum.mb</td><td class="confluenceTd" style="text-align: left;">-1</td><td class="confluenceTd" colspan="1" style="text-align: left;"><p>Introduced by hve patch.</p><p>Will be added when the patch is added again to hadoop 2.2.0</p></td></tr><tr><td class="confluenceTd" style="text-align: left;">yarn.dynamic.resource.vcores.minimum</td><td class="confluenceTd" style="text-align: left;">0</td><td class="confluenceTd" colspan="1" style="text-align: left;"><p>Introduced by hve patch.</p><p>Will be added when the patch is added again to hadoop 2.2.0</p></td></tr><tr><td class="confluenceTd" style="text-align: left;">yarn.nodemanager.vcores-pcores-ratio</td><td class="confluenceTd" style="text-align: left;">2</td><td class="confluenceTd" colspan="1" style="text-align: left;">See <a class="external-link" href="https://issues.apache.org/jira/browse/YARN-782" rel="nofollow" style="text-decoration: none;">YARN-782</a></td></tr></tbody></table></div><h4 id="UpgradingPHDUsingtheCLI-NewParameters.1">New Parameters</h4><p>The following parameters have been added to yarn-site.xml:</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Name</div></th><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Default Value</div></th></tr><tr><td class="confluenceTd" style="text-align: left;">yarn.resourcemanager.connect.retry-interval.ms</td><td class="confluenceTd" style="text-align: left;">30000</td></tr><tr><td class="confluenceTd" style="text-align: left;">yarn.resourcemanager.connect.max-wait.ms</td><td class="confluenceTd" style="text-align: left;">900000</td></tr><tr><td class="confluenceTd" style="text-align: left;">yarn.client.nodemanager-client-async.thread-pool-max-size</td><td class="confluenceTd" style="text-align: left;">500</td></tr><tr><td class="confluenceTd" style="text-align: left;">yarn.resourcemanager.hostname</td><td class="confluenceTd" style="text-align: left;">0.0.0.0</td></tr><tr><td class="confluenceTd" style="text-align: left;">yarn.resourcemanager.scheduler.monitor.enable</td><td class="confluenceTd" style="text-align: left;">false</td></tr><tr><td class="confluenceTd" style="text-align: left;">yarn.http.policy</td><td class="confluenceTd" style="text-align: left;">HTTP_ONLY</td></tr><tr><td class="confluenceTd" style="text-align: left;">yarn.nodemanager.hostname</td><td class="confluenceTd" style="text-align: left;">0.0.0.0</td></tr><tr><td class="confluenceTd" style="text-align: left;">yarn.client.max-nodemanagers-proxies</td><td class="confluenceTd" style="text-align: left;">500</td></tr><tr><td class="confluenceTd" style="text-align: left;">yarn.resourcemanager.webapp.https.address</td><td class="confluenceTd" style="text-align: left;">0.0.0.0:8090</td></tr><tr><td class="confluenceTd" colspan="1" style="text-align: left;">yarn.nodemanager.resourcemanager.connect.wait.secs</td><td class="confluenceTd" colspan="1" style="text-align: left;">900</td></tr><tr><td class="confluenceTd" style="text-align: left;">yarn.client.app-submission.poll-interval</td><td class="confluenceTd" style="text-align: left;">1000</td></tr><tr><td class="confluenceTd" style="text-align: left;">yarn.resourcemanager.scheduler.monitor.policies</td><td class="confluenceTd" style="text-align: left;">org.apache.hadoop.yarn.server.resourcemanager.<br/>monitor.capacity.ProportionalCapacityPreemptionPolicy</td></tr><tr><td class="confluenceTd" style="text-align: left;">yarn.nodemanager.local-cache.max-files-per-directory</td><td class="confluenceTd" style="text-align: left;">8192</td></tr><tr><td class="confluenceTd" style="text-align: left;">yarn.nodemanager.resourcemanager.connect.retry_interval.secs</td><td class="confluenceTd" style="text-align: left;">30</td></tr></tbody></table></div><h3 id="UpgradingPHDUsingtheCLI-hdfs-site.xml">hdfs-site.xml</h3><h4 id="UpgradingPHDUsingtheCLI-ChangedDefaults.1">Changed Defaults</h4><p>The following parameters in hdfs-site.xml have new default values:</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Name</div></th><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Old Default Value</div></th><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">New Default Value</div></th></tr><tr><td class="confluenceTd" style="text-align: left;">dfs.namenode.checkpoint.txns</td><td class="confluenceTd" style="text-align: left;">40000</td><td class="confluenceTd" style="text-align: left;">1000000</td></tr><tr><td class="confluenceTd" style="text-align: left;">dfs.blocksize</td><td class="confluenceTd" style="text-align: left;">67108864</td><td class="confluenceTd" style="text-align: left;">134217728</td></tr></tbody></table></div><h4 id="UpgradingPHDUsingtheCLI-NewParameters.2">New Parameters</h4><p>The following parameters have been added to hdfs-site.xml</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Name</div></th><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Default Value</div></th></tr><tr><td class="confluenceTd" style="text-align: left;">dfs.namenode.retrycache.heap.percent</td><td class="confluenceTd" style="text-align: left;">0.03f</td></tr><tr><td class="confluenceTd" style="text-align: left;">dfs.client.write.exclude.nodes.cache.expiry.interval.millis</td><td class="confluenceTd" style="text-align: left;">600000</td></tr><tr><td class="confluenceTd" style="text-align: left;">dfs.namenode.retrycache.expirytime.millis</td><td class="confluenceTd" style="text-align: left;">600000</td></tr><tr><td class="confluenceTd" style="text-align: left;">dfs.image.transfer.timeout</td><td class="confluenceTd" style="text-align: left;">600000</td></tr><tr><td class="confluenceTd" style="text-align: left;">dfs.namenode.enable.retrycache</td><td class="confluenceTd" style="text-align: left;">true</td></tr><tr><td class="confluenceTd" style="text-align: left;">dfs.datanode.available-space-volume-choosing-<br/>policy.balanced-space-preference-fraction</td><td class="confluenceTd" style="text-align: left;">0.75f</td></tr><tr><td class="confluenceTd" style="text-align: left;">dfs.namenode.edits.noeditlogchannelflush</td><td class="confluenceTd" style="text-align: left;">false</td></tr><tr><td class="confluenceTd" style="text-align: left;">dfs.namenode.fs-limits.max-blocks-per-file</td><td class="confluenceTd" style="text-align: left;">1048576</td></tr><tr><td class="confluenceTd" style="text-align: left;">dfs.namenode.fs-limits.min-block-size</td><td class="confluenceTd" style="text-align: left;">1048576</td></tr><tr><td class="confluenceTd" style="text-align: left;">dfs.datanode.available-space-volume-choosing-<br/>policy.balanced-space-threshold</td><td class="confluenceTd" style="text-align: left;">10737418240</td></tr></tbody></table></div><h3 id="UpgradingPHDUsingtheCLI-mapred-site.xml">mapred-site.xml</h3><h4 id="UpgradingPHDUsingtheCLI-ChangedDefaults.2">Changed Defaults</h4><p>The following parameters in mapred-default.xml have new default values:</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Name</div></th><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Old Default Value</div></th><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">New Default Value</div></th></tr><tr><td class="confluenceTd" style="text-align: left;">mapreduce.shuffle.port</td><td class="confluenceTd" style="text-align: left;">8080</td><td class="confluenceTd" style="text-align: left;">13562</td></tr><tr><td class="confluenceTd" style="text-align: left;">yarn.app.mapreduce.client-am.ipc.max-retries</td><td class="confluenceTd" style="text-align: left;">1</td><td class="confluenceTd" style="text-align: left;">3</td></tr><tr><td class="confluenceTd" colspan="1" style="text-align: left;">mapreduce.application.classpath</td><td class="confluenceTd" colspan="1" style="text-align: left;">$HADOOP_MAPRED_HOME/share/<br/>hadoop/mapreduce/*,$HADOOP_MAPRED_HOME<br/>/share/hadoop/mapreduce/lib/*</td><td class="confluenceTd" colspan="1" style="text-align: left;">No default value</td></tr></tbody></table></div><h4 id="UpgradingPHDUsingtheCLI-NewParameters.3">New Parameters</h4><p>The following parameters have been added to mapred-site.xml:</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Name</div></th><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Default Value</div></th></tr><tr><td class="confluenceTd" style="text-align: left;">mapreduce.jobhistory.loadedjobs.cache.size</td><td class="confluenceTd" style="text-align: left;">5</td></tr><tr><td class="confluenceTd" style="text-align: left;">mapreduce.am.max-attempts</td><td class="confluenceTd" style="text-align: left;">2</td></tr><tr><td class="confluenceTd" style="text-align: left;">mapreduce.jobhistory.done-dir</td><td class="confluenceTd" style="text-align: left;">${yarn.app.mapreduce.am.staging-dir}/history/done</td></tr><tr><td class="confluenceTd" style="text-align: left;">mapreduce.jobhistory.cleaner.enable</td><td class="confluenceTd" style="text-align: left;">true</td></tr><tr><td class="confluenceTd" style="text-align: left;">mapreduce.jobhistory.datestring.cache.size</td><td class="confluenceTd" style="text-align: left;">200000</td></tr><tr><td class="confluenceTd" style="text-align: left;">mapreduce.jobhistory.max-age-ms</td><td class="confluenceTd" style="text-align: left;">604800000</td></tr><tr><td class="confluenceTd" style="text-align: left;">mapreduce.job.token.tracking.ids.enabled</td><td class="confluenceTd" style="text-align: left;">false</td></tr><tr><td class="confluenceTd" style="text-align: left;">mapreduce.jobhistory.joblist.cache.size</td><td class="confluenceTd" style="text-align: left;">20000</td></tr><tr><td class="confluenceTd" style="text-align: left;">mapreduce.jobhistory.move.thread-count</td><td class="confluenceTd" style="text-align: left;">3</td></tr><tr><td class="confluenceTd" style="text-align: left;">mapreduce.jobhistory.cleaner.interval-ms</td><td class="confluenceTd" style="text-align: left;">86400000</td></tr><tr><td class="confluenceTd" style="text-align: left;">mapreduce.jobhistory.client.thread-count</td><td class="confluenceTd" style="text-align: left;">10</td></tr><tr><td class="confluenceTd" style="text-align: left;">mapreduce.jobhistory.move.interval-ms</td><td class="confluenceTd" style="text-align: left;">180000</td></tr><tr><td class="confluenceTd" style="text-align: left;">mapreduce.jobhistory.minicluster.fixed.ports</td><td class="confluenceTd" style="text-align: left;">false</td></tr><tr><td class="confluenceTd" style="text-align: left;">mapreduce.jobhistory.http.policy</td><td class="confluenceTd" style="text-align: left;">HTTP_ONLY</td></tr><tr><td class="confluenceTd" style="text-align: left;">mapreduce.jobhistory.intermediate-done-dir</td><td class="confluenceTd" style="text-align: left;">${yarn.app.mapreduce.am.staging-dir}/<br/>history/done_intermediate</td></tr></tbody></table></div><h3 id="UpgradingPHDUsingtheCLI-httpfs-site.xml">httpfs-site.xml</h3><h4 id="UpgradingPHDUsingtheCLI-NewParameters.4">New Parameters</h4><p>The following parameters have been added to httpfs-site.xml:</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Name</div></th><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Default Value</div></th></tr><tr><td class="confluenceTd" style="text-align: left;">httpfs.user.provider.user.pattern</td><td class="confluenceTd" style="text-align: left;">^[A-Za-z_][A-Za-z0-9._-]*[$]?$</td></tr></tbody></table></div><h3 id="UpgradingPHDUsingtheCLI-capacity-scheduler.xml">capacity-scheduler.xml</h3><h4 id="UpgradingPHDUsingtheCLI-ChangedDefaults.3">Changed Defaults</h4><p>The following parameters in capacity-scheduler.xml have new default values:</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Name</div></th><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Old Default Value</div></th><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">New Default Value</div></th></tr><tr><td class="confluenceTd" style="text-align: left;">yarn.scheduler.capacity.resource-calculator</td><td class="confluenceTd" style="text-align: left;">org.apache.hadoop.yarn.server.<br/>resourcemanager.resource.<br/>DefaultResourceCalculator</td><td class="confluenceTd" style="text-align: left;">org.apache.hadoop.yarn.util.resource.<br/>DefaultResourceCalculator</td></tr></tbody></table></div><h3 id="UpgradingPHDUsingtheCLI-hbase-site.xml">hbase-site.xml</h3><h4 id="UpgradingPHDUsingtheCLI-ChangedDefaults.4">Changed Defaults</h4><p>The following parameters in hbase-site.xml have new default values:</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Name</div></th><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Old Default Value</div></th><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">New Default Value</div></th></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.client.pause</td><td class="confluenceTd" style="text-align: left;">1000</td><td class="confluenceTd" style="text-align: left;">100</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.client.retries.number</td><td class="confluenceTd" style="text-align: left;">10</td><td class="confluenceTd" style="text-align: left;">35</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.client.scanner.caching</td><td class="confluenceTd" style="text-align: left;">1</td><td class="confluenceTd" style="text-align: left;">100</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.hregion.majorcompaction</td><td class="confluenceTd" style="text-align: left;">86400000</td><td class="confluenceTd" style="text-align: left;">604800000</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.hstore.blockingStoreFiles</td><td class="confluenceTd" style="text-align: left;">7</td><td class="confluenceTd" style="text-align: left;">10</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.regionserver.checksum.verify</td><td class="confluenceTd" style="text-align: left;">false</td><td class="confluenceTd" style="text-align: left;">true</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.regionserver.global.memstore.lowerLimit</td><td class="confluenceTd" style="text-align: left;">0.35</td><td class="confluenceTd" style="text-align: left;">0.38</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.regionserver.handler.count</td><td class="confluenceTd" style="text-align: left;">10</td><td class="confluenceTd" style="text-align: left;">30</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.regionserver.hlog.reader.impl</td><td class="confluenceTd" style="text-align: left;">org.apache.hadoop.hbase.regionserver.<br/>wal.SequenceFileLogReader</td><td class="confluenceTd" style="text-align: left;">org.apache.hadoop.hbase.regionserver.<br/>wal.ProtobufLogReader</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.regionserver.hlog.writer.impl</td><td class="confluenceTd" style="text-align: left;">org.apache.hadoop.hbase.regionserver.<br/>wal.SequenceFileLogWriter</td><td class="confluenceTd" style="text-align: left;">org.apache.hadoop.hbase.regionserver.<br/>wal.ProtobufLogWriter</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.rootdir</td><td class="confluenceTd" style="text-align: left;"><span class="nolink">file:///tmp/hbase-${user.name}/hbase</span></td><td class="confluenceTd" style="text-align: left;">${hbase.tmp.dir}/hbase</td></tr><tr><td class="confluenceTd" style="text-align: left;">hfile.block.cache.size</td><td class="confluenceTd" style="text-align: left;">0.25</td><td class="confluenceTd" style="text-align: left;">0.4</td></tr><tr><td class="confluenceTd" style="text-align: left;">zookeeper.session.timeout</td><td class="confluenceTd" style="text-align: left;">180000</td><td class="confluenceTd" style="text-align: left;">90000</td></tr></tbody></table></div><h4 id="UpgradingPHDUsingtheCLI-NewNames.1">New Names</h4><p>The following parameters in hbase-site.xml have new names:</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Old Name</div></th><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">New Name</div></th><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Default Value</div></th></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.rpc.engine</td><td class="confluenceTd" style="text-align: left;">hbase.rpc.server.engine</td><td class="confluenceTd" style="text-align: left;">org.apache.hadoop.hbase.ipc.WritableRpcEngine -&gt; org.apache.hadoop.hbase.ipc.ProtobufRpcServerEngine</td></tr><tr><td class="confluenceTd" colspan="1" style="text-align: left;">io.storefile.bloom.cacheonwrite</td><td class="confluenceTd" colspan="1" style="text-align: left;">hfile.block.bloom.cacheonwrite</td><td class="confluenceTd" colspan="1" style="text-align: left;">false (See <a class="external-link" href="https://issues.apache.org/jira/browse/HBASE-5957" rel="nofollow" style="text-decoration: none;">HBASE-5957</a>)</td></tr></tbody></table></div><h4 id="UpgradingPHDUsingtheCLI-RemovedParameters.2">Removed Parameters</h4><p>The following parameters have been removed from hbase-site.xml:</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Name</div></th><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Default Value</div></th><th class="confluenceTh" colspan="1" style="text-align: left;"><div class="tablesorter-header-inner">Description</div></th></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.table.archive.directory</td><td class="confluenceTd" style="text-align: left;">.archive</td><td class="confluenceTd" colspan="1" style="text-align: left;">Removed due to <a class="external-link" href="https://issues.apache.org/jira/browse/HBASE-8195" rel="nofollow" style="text-decoration: none;">HBASE-8195</a></td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.regionserver.<br/>separate.hlog.for.meta</td><td class="confluenceTd" style="text-align: left;">false</td><td class="confluenceTd" colspan="1" style="text-align: left;"> </td></tr><tr><td class="confluenceTd" style="text-align: left;">dfs.support.append</td><td class="confluenceTd" style="text-align: left;">true</td><td class="confluenceTd" colspan="1" style="text-align: left;">HDFS now support append by default.</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.mapreduce.<br/>hfileoutputformat.blocksize</td><td class="confluenceTd" style="text-align: left;">65536</td><td class="confluenceTd" colspan="1" style="text-align: left;"> </td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.regionserver.nbreservationblocks</td><td class="confluenceTd" style="text-align: left;">4</td><td class="confluenceTd" colspan="1" style="text-align: left;"> </td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.regionserver.lease.period</td><td class="confluenceTd" style="text-align: left;">60000</td><td class="confluenceTd" colspan="1" style="text-align: left;"> </td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.hash.type</td><td class="confluenceTd" style="text-align: left;">murmur</td><td class="confluenceTd" colspan="1" style="text-align: left;"> </td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.regionserver.class</td><td class="confluenceTd" style="text-align: left;">org.apache.hadoop.hbase.<br/>ipc.HRegionInterface</td><td class="confluenceTd" colspan="1" style="text-align: left;"> </td></tr></tbody></table></div><h4 id="UpgradingPHDUsingtheCLI-NewParameters.5">New Parameters</h4><p>The following parameters have been added to hbase-site.xml:</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Name</div></th><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Default Value</div></th></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.client.scanner.timeout.period</td><td class="confluenceTd" style="text-align: left;">60000</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.storescanner.parallel.seek.enable</td><td class="confluenceTd" style="text-align: left;">false</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.thrift.htablepool.size.max</td><td class="confluenceTd" style="text-align: left;">1000</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.hstore.bytes.per.checksum</td><td class="confluenceTd" style="text-align: left;">16384</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.config.read.zookeeper.config</td><td class="confluenceTd" style="text-align: left;">false</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.master.loadbalancer.class</td><td class="confluenceTd" style="text-align: left;">org.apache.hadoop.hbase.master.<br/>balancer.StochasticLoadBalancer</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.rpc.shortoperation.timeout</td><td class="confluenceTd" style="text-align: left;">10000</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.snapshot.enabled</td><td class="confluenceTd" style="text-align: left;">true</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.hstore.checksum.algorithm</td><td class="confluenceTd" style="text-align: left;">CRC32</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.status.publisher.class</td><td class="confluenceTd" style="text-align: left;">org.apache.hadoop.hbase.master.<br/>ClusterStatusPublisher$MulticastPublisher</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.status.listener.class</td><td class="confluenceTd" style="text-align: left;">org.apache.hadoop.hbase.client.<br/>ClusterStatusListener$MulticastListener</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.security.authentication</td><td class="confluenceTd" style="text-align: left;">simple</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.master.catalog.timeout</td><td class="confluenceTd" style="text-align: left;">600000</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.hstore.compaction.kv.max</td><td class="confluenceTd" style="text-align: left;">10</td></tr><tr><td class="confluenceTd" style="text-align: left;">fail.fast.expired.active.master</td><td class="confluenceTd" style="text-align: left;">false</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.metrics.exposeOperationTimes</td><td class="confluenceTd" style="text-align: left;">true</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.client.localityCheck.threadPoolSize</td><td class="confluenceTd" style="text-align: left;">2</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.status.published</td><td class="confluenceTd" style="text-align: left;">false</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.status.multicast.address.ip</td><td class="confluenceTd" style="text-align: left;">226.1.1.3</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.dynamic.jars.dir</td><td class="confluenceTd" style="text-align: left;">${hbase.rootdir}/lib</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.hregion.majorcompaction.jitter</td><td class="confluenceTd" style="text-align: left;">0.50</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.status.multicast.address.port</td><td class="confluenceTd" style="text-align: left;">6100</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.lease.recovery.dfs.timeout</td><td class="confluenceTd" style="text-align: left;">64000</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.server.compactchecker.interval.multiplier</td><td class="confluenceTd" style="text-align: left;">1000</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.rpc.timeout</td><td class="confluenceTd" style="text-align: left;">60000</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.lease.recovery.timeout</td><td class="confluenceTd" style="text-align: left;">900000</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.storescanner.parallel.seek.threads</td><td class="confluenceTd" style="text-align: left;">10</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.regionserver.catalog.timeout</td><td class="confluenceTd" style="text-align: left;">600000</td></tr><tr><td class="confluenceTd" colspan="1" style="text-align: left;">hbase.ipc.client.tcpnodelay</td><td class="confluenceTd" colspan="1" style="text-align: left;">true</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.rest.filter.classes</td><td class="confluenceTd" style="text-align: left;">org.apache.hadoop.hbase.rest.filter.GzipFilter</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.ipc.client.fallback-to-simple-auth-allowed</td><td class="confluenceTd" style="text-align: left;">false</td></tr><tr><td class="confluenceTd" style="text-align: left;">hbase.table.lock.enable</td><td class="confluenceTd" style="text-align: left;">true</td></tr></tbody></table></div><h3 id="UpgradingPHDUsingtheCLI-hive-site.xml">hive-site.xml</h3><p>The following parameters have been added to hive-site.xml:</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Name</div></th><th class="confluenceTh" style="text-align: left;"><div class="tablesorter-header-inner">Default Value</div></th></tr><tr><td class="confluenceTd" style="text-align: left;">hive.default.rcfile.serde</td><td class="confluenceTd" style="text-align: left;">org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe</td></tr></tbody></table></div>
</div></div>
            </div><!-- end of content-->
            
            
          </div><!-- end of container -->
        </div><!--end of container-fluid-->
      </div><!--end of main-wrap-->

      <div class="site-footer desktop-only">
          <div class="container-fluid">
              <div class="site-footer-links">
                  <span class="version"><a href='/'>Pivotal Documentation</a></span>
                  <span>&copy;
                      <script>
                          var d = new Date();
                          document.write(d.getFullYear());
                      </script>
                      <a href='http://gopivotal.com'>Pivotal Software</a> Inc. All Rights Reserved.
                  </span>
              </div>
          </div>
      </div>

      <script type="text/javascript">
          (function() {
              var didInit = false;
              function initMunchkin() {
                  if(didInit === false) {
                      didInit = true;
                      Munchkin.init('625-IUJ-009');
                  }
              }
              var s = document.createElement('script');
              s.type = 'text/javascript';
              s.async = true;
              s.src = document.location.protocol + '//munchkin.marketo.net/munchkin.js';
              s.onreadystatechange = function() {
                  if (this.readyState == 'complete' || this.readyState == 'loaded') {
                      initMunchkin();
                  }
              };
              s.onload = initMunchkin;
              document.getElementsByTagName('head')[0].appendChild(s);
          })();
      </script>
  </div><!--end of viewport-->
  <div id="scrim"></div>
</body>
</html>